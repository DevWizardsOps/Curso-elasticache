# Lab 04 - Troubleshooting de Dados

LaboratÃ³rio focado na anÃ¡lise do data plane do Redis no ElastiCache na regiÃ£o **us-east-2**, desenvolvendo habilidades para identificar, analisar e resolver problemas relacionados a big keys, hot keys, estruturas inadequadas e padrÃµes problemÃ¡ticos que impactam performance.

## ğŸ“‹ Objetivos do LaboratÃ³rio

- Identificar big keys que causam bloqueios e latÃªncia
- Detectar hot keys responsÃ¡veis por hotspots e sobrecarga
- Analisar estruturas de dados inadequadas e ineficientes
- Diagnosticar problemas de TTL e expiraÃ§Ã£o de chaves
- Avaliar padrÃµes de acesso e distribuiÃ§Ã£o de dados
- Correlacionar problemas de dados com mÃ©tricas de performance
- Implementar estratÃ©gias de otimizaÃ§Ã£o de dados

## â±ï¸ DuraÃ§Ã£o Estimada: 60 minutos

## ğŸŒ RegiÃ£o AWS: us-east-2 (Ohio)

**IMPORTANTE:** Todos os recursos devem ser criados na regiÃ£o **us-east-2**. Verifique sempre a regiÃ£o no canto superior direito do Console AWS.

## ğŸ—ï¸ Estrutura do LaboratÃ³rio

```
lab04-troubleshooting-dados/
â”œâ”€â”€ README.md                    # Este guia (foco principal)
â”œâ”€â”€ scripts/                     # Scripts de referÃªncia (opcional)
â”‚   â”œâ”€â”€ create-data-cluster.sh
â”‚   â”œâ”€â”€ generate-big-keys.sh
â”‚   â”œâ”€â”€ simulate-hot-keys.sh
â”‚   â”œâ”€â”€ analyze-data-patterns.sh
â”‚   â””â”€â”€ cleanup-lab04.sh
â””â”€â”€ ferramentas/                 # Ferramentas de anÃ¡lise (opcional)
    â”œâ”€â”€ big-key-analyzer.py
    â”œâ”€â”€ hot-key-detector.sh
    â””â”€â”€ data-pattern-report.py
```

**IMPORTANTE:** Este laboratÃ³rio foca na anÃ¡lise manual via Redis CLI e ferramentas especÃ­ficas. Os scripts sÃ£o apenas para referÃªncia e simulaÃ§Ã£o de cenÃ¡rios.

## ğŸš€ PrÃ©-requisitos

- Conta AWS ativa configurada para regiÃ£o **us-east-2**
- AWS CLI configurado para regiÃ£o us-east-2
- Acesso Ã  instÃ¢ncia EC2 fornecida pelo instrutor (Bastion Host)
- Redis CLI instalado e funcional
- Conhecimento bÃ¡sico de estruturas de dados Redis
- **ID do Aluno:** VocÃª deve usar seu ID Ãºnico (ex: aluno01, aluno02, etc.)
- **Labs anteriores:** VPC, Subnet Group e Security Group jÃ¡ criados

## ğŸ·ï¸ ConvenÃ§Ã£o de Nomenclatura

Todos os recursos criados devem seguir o padrÃ£o:
- **Cluster de Dados:** `lab-data-$ID`
- **Security Groups:** Reutilizar `elasticache-lab-sg-$ID` dos labs anteriores

**Exemplo para aluno01:**
- Cluster: `lab-data-aluno01`
- Security Group: `elasticache-lab-sg-aluno01` (jÃ¡ existente)

## ğŸ“š ExercÃ­cios

### ExercÃ­cio 1: Preparar Ambiente com Dados Diversos (15 minutos)

**Objetivo:** Criar cluster e popular com diferentes tipos e tamanhos de dados

#### Passo 1: Verificar PrÃ©-requisitos

```bash
# Verificar Security Group dos labs anteriores
aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$ID" --region us-east-2
```

#### Passo 2: Criar Cluster de Dados via Console Web

1. Acesse **ElastiCache** no Console AWS
2. Na pÃ¡gina inicial, selecione **"Caches do Redis OSS"** â† **IMPORTANTE**
3. Selecione **"Cache de cluster"** (nÃ£o serverless)
4. Selecione **"Cache de cluster"** (configuraÃ§Ã£o manual, nÃ£o criaÃ§Ã£o fÃ¡cil)
5. Configure:
   - **Cluster mode:** Disabled
   - **Cluster info:**
     - **Name:** `lab-data-$ID`
     - **Description:** `Lab data troubleshooting cluster for $ID`
   - **Location:**
     - **AWS Cloud**
     - **Multi-AZ:** Disabled (para este lab)
     - **Failover automÃ¡tico:** Desabilitado (nÃ£o aplicÃ¡vel sem rÃ©plicas)
   - **Cluster settings:**
     - **Engine version:** 7.0
     - **Port:** 6379
     - **Node type:** **cache.t3.micro** (para demonstrar limitaÃ§Ãµes)
     - **Number of replicas:** 0
   - **Connectivity:**
     - **Network type:** IPv4
     - **Subnet group:** `elasticache-lab-subnet-group`
     - **Security groups:** Selecione seu SG `elasticache-lab-sg-$ID`
   - **Security (SeguranÃ§a):**
     - **Criptografia em repouso:** Habilitada (recomendado)
     - **Chave de criptografia:** Chave padrÃ£o (AWS managed)
     - **Criptografia em trÃ¢nsito:** Habilitada (recomendado)
     - **Controle de acesso:** Nenhum controle de acesso (para simplicidade do lab)
   - **Backup:**
     - **Enable automatic backups:** Enabled
   - **Maintenance:**
     - **Auto minor version upgrade:** Enabled
   - **Advanced settings:**
     - **Tags (Recomendado):**
       - **Key:** `Name` **Value:** `Lab Data - $ID`
       - **Key:** `Lab` **Value:** `Lab04`
       - **Key:** `Purpose` **Value:** `Data-Analysis`

6. Clique em **Create**

> **ğŸ“š Para saber mais sobre seguranÃ§a:**
> - [Criptografia no ElastiCache](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html)
> - [ConfiguraÃ§Ãµes de seguranÃ§a](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth.html)

#### Alternativa: CriaÃ§Ã£o RÃ¡pida via CLI

Para acelerar o processo, vocÃª pode criar o cluster via CLI:

```bash
# Obter IDs necessÃ¡rios
VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=ElastiCache-Lab-VPC" --query 'Vpcs[0].VpcId' --output text --region us-east-2)
SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$ID" --query 'SecurityGroups[0].GroupId' --output text --region us-east-2)

# IMPORTANTE: Para ter criptografia via CLI, devemos usar Replication Group (mesmo com 1 nÃ³)
# create-cache-cluster NÃƒO suporta parÃ¢metros de criptografia
aws elasticache create-replication-group \
    --replication-group-id "lab-data-$ID" \
    --replication-group-description "Data troubleshooting with encryption" \
    --num-cache-clusters 1 \
    --cache-node-type cache.t3.micro \
    --engine redis \
    --engine-version 7.0 \
    --port 6379 \
    --cache-subnet-group-name elasticache-lab-subnet-group \
    --security-group-ids $SG_ID \
    --at-rest-encryption-enabled \
    --transit-encryption-enabled \
    --auto-minor-version-upgrade \
    --tags Key=Name,Value="Lab Data - $ID" Key=Lab,Value=Lab04 Key=Purpose,Value=Data-Analysis \
    --region us-east-2

echo "âœ… Replication Group criado via CLI! Aguarde ~10-15 minutos para ficar disponÃ­vel."
```

> **ğŸ—ï¸ PONTO ARQUITETURAL IMPORTANTE:**
> 
> **Por que usar `create-replication-group` em vez de `create-cache-cluster`?**
> 
> - **`create-cache-cluster`:** Comando legado, NÃƒO suporta criptografia
> - **`create-replication-group`:** Comando moderno, suporta todas as funcionalidades
> 
> **Mesmo para 1 nÃ³ Ãºnico**, use `create-replication-group` se precisar de:
> - âœ… Criptografia (at-rest e in-transit)
> - âœ… Backups automÃ¡ticos
> - âœ… Multi-AZ (futuro)
> - âœ… Failover automÃ¡tico (futuro)
> 
> **Regra prÃ¡tica:** Sempre use `create-replication-group` em produÃ§Ã£o!

#### Passo 3: Aguardar CriaÃ§Ã£o e Obter Endpoint

```bash
# Monitorar criaÃ§Ã£o
watch -n 30 "aws elasticache describe-replication-groups --replication-group-id lab-data-$ID --query 'ReplicationGroups[0].Status' --output text --region us-east-2"

# Quando disponÃ­vel, obter endpoint
DATA_ENDPOINT=$(aws elasticache describe-replication-groups --replication-group-id lab-data-$ID --query 'ReplicationGroups[0].NodeGroups[0].PrimaryEndpoint.Address' --output text --region us-east-2)
echo "Data Cluster Endpoint: $DATA_ENDPOINT"
```

#### Passo 4: Popular com Dados Diversos

```bash
# Testar conectividade primeiro
if redis-cli -h $DATA_ENDPOINT -p 6379 --tls ping > /dev/null 2>&1; then
    echo "âœ… Conectividade OK (com TLS)"
    REDIS_CMD="redis-cli -h $DATA_ENDPOINT -p 6379 --tls"
else
    echo "âŒ Erro de conectividade"
    exit 1
fi

# Popular com diferentes tipos de dados
echo "ğŸ“Š Populando cluster com dados diversos..."

# Limpar dados existentes
$REDIS_CMD FLUSHALL

# === DADOS PEQUENOS (baseline) ===
echo "Inserindo dados pequenos..."
for i in {1..1000}; do
    $REDIS_CMD SET "small:$ID:$i" "value$i" > /dev/null
done

# === STRINGS GRANDES (big keys potenciais) ===
echo "Criando big strings..."
$REDIS_CMD SET "big_string:$ID:1mb" "$(printf 'A%.0s' {1..1048576})"
$REDIS_CMD SET "big_string:$ID:500kb" "$(printf 'B%.0s' {1..512000})"
$REDIS_CMD SET "big_string:$ID:100kb" "$(printf 'C%.0s' {1..102400})"

# === LISTAS GRANDES ===
echo "Criando big list..."
for i in {1..10000}; do
    $REDIS_CMD LPUSH "big_list:$ID" "item$i" > /dev/null
done

# === HASHES GRANDES ===
echo "Criando big hash..."
for i in {1..5000}; do
    $REDIS_CMD HSET "big_hash:$ID" "field$i" "value$i" > /dev/null
done

# === SETS GRANDES ===
echo "Criando big set..."
for i in {1..3000}; do
    $REDIS_CMD SADD "big_set:$ID" "member$i" > /dev/null
done

# === SORTED SETS GRANDES ===
echo "Criando big sorted set..."
for i in {1..2000}; do
    $REDIS_CMD ZADD "big_zset:$ID" $i "member$i" > /dev/null
done

# === DADOS COM TTL VARIADO ===
$REDIS_CMD SET "ttl_short:$ID:1" "expires in 60s" EX 60
$REDIS_CMD SET "ttl_medium:$ID:1" "expires in 300s" EX 300
$REDIS_CMD SET "ttl_long:$ID:1" "expires in 3600s" EX 3600
$REDIS_CMD SET "no_ttl:$ID:1" "never expires"

# === DADOS PARA HOT KEYS ===
echo "Criando hot key candidates..."
for i in {1..100}; do
    $REDIS_CMD SET "hot_candidate:$ID:$i" "hotvalue$i" > /dev/null
done

# === ESTRUTURAS ANINHADAS (JSON-like) ===
$REDIS_CMD SET "json_data:$ID:user1" '{"id":1,"name":"JoÃ£o Silva","email":"joao@example.com","preferences":{"theme":"dark","notifications":true},"history":[1,2,3,4,5]}'
$REDIS_CMD SET "json_data:$ID:user2" '{"id":2,"name":"Maria Santos","email":"maria@example.com","preferences":{"theme":"light","notifications":false},"history":[6,7,8,9,10]}'

# === DADOS DE SESSÃƒO ===
echo "Criando dados de sessÃ£o..."
for i in {1..200}; do
    $REDIS_CMD HSET "session:$ID:$i" user_id $i login_time $(date +%s) ip "192.168.1.$((i%255))" > /dev/null
done

echo "âœ… Dados diversos inseridos no cluster"
```

**âœ… Checkpoint:** Cluster deve estar populado com dados de diferentes tipos e tamanhos.

---

### ExercÃ­cio 2: Identificar Big Keys (15 minutos)

**Objetivo:** Usar ferramentas Redis para identificar chaves que consomem muita memÃ³ria

#### Passo 1: AnÃ¡lise BÃ¡sica de MemÃ³ria

```bash
# Verificar uso total de memÃ³ria
echo "ğŸ” Analisando uso de memÃ³ria..."
redis-cli -h $DATA_ENDPOINT -p 6379 --tls info memory | grep -E "(used_memory|used_memory_human|used_memory_peak)"

# Contar total de chaves
TOTAL_KEYS=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls dbsize)
echo "Total de chaves: $TOTAL_KEYS"
```

#### Passo 2: Usar --bigkeys para Identificar Big Keys

```bash
# Executar anÃ¡lise de big keys (pode demorar alguns minutos)
echo "ğŸ” Executando anÃ¡lise de big keys..."
redis-cli -h $DATA_ENDPOINT -p 6379 --tls --bigkeys

# Salvar resultado em arquivo para anÃ¡lise
redis-cli -h $DATA_ENDPOINT -p 6379 --tls --bigkeys > /tmp/bigkeys_analysis_$ID.txt
echo "ğŸ“„ Resultado salvo em /tmp/bigkeys_analysis_$ID.txt"
```

#### Passo 3: AnÃ¡lise Manual de Chaves EspecÃ­ficas

```bash
# Analisar uso de memÃ³ria de chaves especÃ­ficas
echo "ğŸ” Analisando chaves especÃ­ficas..."

# Verificar tamanho das big strings
echo "=== Big Strings ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls memory usage big_string:$ID:1mb
redis-cli -h $DATA_ENDPOINT -p 6379 --tls memory usage big_string:$ID:500kb
redis-cli -h $DATA_ENDPOINT -p 6379 --tls memory usage big_string:$ID:100kb

# Verificar tamanho das estruturas grandes
echo "=== Big Structures ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls memory usage big_list:$ID
redis-cli -h $DATA_ENDPOINT -p 6379 --tls memory usage big_hash:$ID
redis-cli -h $DATA_ENDPOINT -p 6379 --tls memory usage big_set:$ID
redis-cli -h $DATA_ENDPOINT -p 6379 --tls memory usage big_zset:$ID

# Verificar nÃºmero de elementos
echo "=== Contagem de Elementos ==="
echo "Lista: $(redis-cli -h $DATA_ENDPOINT -p 6379 --tls llen big_list:$ID) elementos"
echo "Hash: $(redis-cli -h $DATA_ENDPOINT -p 6379 --tls hlen big_hash:$ID) campos"
echo "Set: $(redis-cli -h $DATA_ENDPOINT -p 6379 --tls scard big_set:$ID) membros"
echo "Sorted Set: $(redis-cli -h $DATA_ENDPOINT -p 6379 --tls zcard big_zset:$ID) membros"
```

#### Passo 4: Impacto de Big Keys na Performance

```bash
# Testar impacto de operaÃ§Ãµes em big keys
echo "ğŸ§ª Testando impacto de big keys na performance..."

# OperaÃ§Ã£o custosa: obter lista completa (MUITO CUSTOSO)
echo "Testando LRANGE em big_list..."
START_TIME=$(date +%s%N)
redis-cli -h $DATA_ENDPOINT -p 6379 --tls lrange big_list:$ID 0 -1 > /dev/null
END_TIME=$(date +%s%N)
LRANGE_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "LRANGE completo: ${LRANGE_TIME}ms"

# OperaÃ§Ã£o custosa: obter hash completo
echo "Testando HGETALL em big_hash..."
START_TIME=$(date +%s%N)
redis-cli -h $DATA_ENDPOINT -p 6379 --tls hgetall big_hash:$ID > /dev/null
END_TIME=$(date +%s%N)
HGETALL_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "HGETALL completo: ${HGETALL_TIME}ms"

# Comparar com operaÃ§Ã£o simples
echo "Testando GET em chave pequena..."
START_TIME=$(date +%s%N)
redis-cli -h $DATA_ENDPOINT -p 6379 --tls get small:$ID:1 > /dev/null
END_TIME=$(date +%s%N)
GET_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "GET simples: ${GET_TIME}ms"

echo ""
echo "ğŸ“Š ComparaÃ§Ã£o de Performance:"
echo "GET simples: ${GET_TIME}ms"
echo "LRANGE big_list: ${LRANGE_TIME}ms ($(( LRANGE_TIME / GET_TIME ))x mais lento)"
echo "HGETALL big_hash: ${HGETALL_TIME}ms ($(( HGETALL_TIME / GET_TIME ))x mais lento)"
```

**Sinais de Big Keys ProblemÃ¡ticos:**
- âœ… Chaves > 100KB (strings) ou > 1000 elementos (estruturas)
- âœ… OperaÃ§Ãµes que demoram > 10ms
- âœ… Uso desproporcional de memÃ³ria
- âœ… Bloqueio de outras operaÃ§Ãµes

**âœ… Checkpoint:** Identificar quais sÃ£o as maiores chaves e seu impacto.

---

### ExercÃ­cio 3: Detectar Hot Keys (15 minutos)

**Objetivo:** Identificar chaves acessadas com alta frequÃªncia

#### Passo 1: Configurar Monitoramento de Hot Keys

```bash
# Verificar configuraÃ§Ãµes disponÃ­veis (ElastiCache pode restringir CONFIG)
echo "ğŸ” Verificando configuraÃ§Ã£o de hot key tracking..."

# No ElastiCache, hot key tracking geralmente nÃ£o estÃ¡ disponÃ­vel via CONFIG
# Vamos usar abordagens alternativas para detectar hot keys

echo "âš ï¸  NOTA: ElastiCache pode restringir comandos CONFIG por seguranÃ§a"
echo "Vamos usar mÃ©todos alternativos para detectar hot keys:"

# Verificar se conseguimos acessar informaÃ§Ãµes bÃ¡sicas
$REDIS_CMD INFO server | head -5

# Alternativa: usar MONITOR para detectar hot keys (mÃ©todo manual)
echo "ğŸ’¡ Para detectar hot keys no ElastiCache, usaremos:"
echo "1. Comando MONITOR (observaÃ§Ã£o manual)"
echo "2. AnÃ¡lise de padrÃµes de acesso"
echo "3. SimulaÃ§Ã£o controlada"
```

#### Passo 2: Simular Acesso a Hot Keys

```bash
# Simular padrÃ£o de hot keys
echo "ğŸ§ª Simulando padrÃ£o de acesso a hot keys..."

# FunÃ§Ã£o para simular carga concentrada
simulate_hot_keys() {
    local endpoint=$1
    local student_id=$2
    local duration=60  # 1 minuto de simulaÃ§Ã£o
    local end_time=$(($(date +%s) + duration))
    
    echo "Simulando hot keys por $duration segundos..."
    
    while [ $(date +%s) -lt $end_time ]; do
        # 80% dos acessos vÃ£o para apenas 3 chaves (hot keys)
        for i in {1..8}; do
            redis-cli -h $endpoint -p 6379 --tls get hot_candidate:$student_id:1 > /dev/null &
            redis-cli -h $endpoint -p 6379 --tls get hot_candidate:$student_id:2 > /dev/null &
            redis-cli -h $endpoint -p 6379 --tls get hot_candidate:$student_id:3 > /dev/null &
        done
        
        # 20% dos acessos distribuÃ­dos entre outras chaves
        for i in {1..2}; do
            RANDOM_KEY=$((RANDOM % 100 + 4))
            redis-cli -h $endpoint -p 6379 --tls get hot_candidate:$student_id:$RANDOM_KEY > /dev/null &
        done
        
        sleep 0.1
        wait  # Aguardar todos os processos background
    done
}

# Executar simulaÃ§Ã£o em background
simulate_hot_keys $DATA_ENDPOINT $ID &
SIMULATION_PID=$!

echo "ğŸ” SimulaÃ§Ã£o iniciada (PID: $SIMULATION_PID)"
echo "Aguarde 60 segundos para coleta de dados..."
```

#### Passo 3: Monitorar Hot Keys em Tempo Real

```bash
# Usar MONITOR para observar comandos (cuidado: muito verboso)
echo "ğŸ” Iniciando monitoramento de comandos por 30 segundos..."
timeout 30 redis-cli -h $DATA_ENDPOINT -p 6379 --tls monitor | grep "hot_candidate:$ID" > /tmp/monitor_output_$ID.txt &

# Aguardar coleta de dados
sleep 35

# Parar simulaÃ§Ã£o
kill $SIMULATION_PID 2>/dev/null || true
wait $SIMULATION_PID 2>/dev/null || true

echo "âœ… SimulaÃ§Ã£o concluÃ­da"
```

#### Passo 4: Analisar PadrÃµes de Acesso

```bash
# Analisar dados coletados
echo "ğŸ“Š Analisando padrÃµes de acesso..."

if [ -f /tmp/monitor_output_$ID.txt ]; then
    echo "=== Top 10 Chaves Mais Acessadas ==="
    grep -o "hot_candidate:$ID:[0-9]*" /tmp/monitor_output_$ID.txt | sort | uniq -c | sort -nr | head -10
    
    echo ""
    echo "=== EstatÃ­sticas de Acesso ==="
    TOTAL_ACCESSES=$(wc -l < /tmp/monitor_output_$ID.txt)
    TOP_3_ACCESSES=$(grep -o "hot_candidate:$ID:[1-3]" /tmp/monitor_output_$ID.txt | wc -l)
    HOT_PERCENTAGE=$(( TOP_3_ACCESSES * 100 / TOTAL_ACCESSES ))
    
    echo "Total de acessos: $TOTAL_ACCESSES"
    echo "Acessos Ã s top 3 chaves: $TOP_3_ACCESSES"
    echo "Percentual de hot keys: ${HOT_PERCENTAGE}%"
else
    echo "âš ï¸  Arquivo de monitoramento nÃ£o encontrado"
fi
```

#### Passo 5: Usar Ferramentas de AnÃ¡lise de LatÃªncia

```bash
# Verificar latÃªncia de comandos
echo "ğŸ“ˆ Analisando latÃªncia de comandos..."

# Verificar slow log
echo "=== Slow Log ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls slowlog get 10

# Verificar estatÃ­sticas de comandos
echo "=== Command Stats ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls info commandstats | head -10

# Testar latÃªncia especÃ­fica das hot keys
echo "=== LatÃªncia das Hot Keys ==="
for key in 1 2 3; do
    echo "Testando hot_candidate:$ID:$key"
    redis-cli -h $DATA_ENDPOINT -p 6379 --tls --latency-history -i 1 get hot_candidate:$ID:$key | head -5 &
    sleep 2
    kill $! 2>/dev/null || true
done
```

**Sinais de Hot Keys ProblemÃ¡ticos:**
- âœ… Poucas chaves recebem > 80% dos acessos
- âœ… LatÃªncia aumenta durante picos de acesso
- âœ… CPU alta sem distribuiÃ§Ã£o uniforme de carga
- âœ… Gargalo em single-threaded operations

**âœ… Checkpoint:** Identificar padrÃµes de hot keys e seu impacto na performance.

---

### ExercÃ­cio 4: Analisar PadrÃµes de TTL e ExpiraÃ§Ã£o (15 minutos)

**Objetivo:** Identificar problemas relacionados a TTL e gerenciamento de expiraÃ§Ã£o

#### Passo 1: Analisar TTL das Chaves Existentes

```bash
# Verificar TTL de diferentes tipos de chaves
echo "ğŸ” Analisando TTL das chaves..."

echo "=== TTL das Chaves de Teste ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls ttl ttl_short:$ID:1
redis-cli -h $DATA_ENDPOINT -p 6379 --tls ttl ttl_medium:$ID:1
redis-cli -h $DATA_ENDPOINT -p 6379 --tls ttl ttl_long:$ID:1
redis-cli -h $DATA_ENDPOINT -p 6379 --tls ttl no_ttl:$ID:1

echo ""
echo "=== TTL das Big Keys ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls ttl big_string:$ID:1mb
redis-cli -h $DATA_ENDPOINT -p 6379 --tls ttl big_list:$ID
redis-cli -h $DATA_ENDPOINT -p 6379 --tls ttl big_hash:$ID
```

#### Passo 2: Identificar Chaves sem TTL

```bash
# Encontrar chaves sem TTL (TTL = -1)
echo "ğŸ” Identificando chaves sem TTL..."

# FunÃ§Ã£o para verificar TTL de mÃºltiplas chaves
check_ttl_patterns() {
    local pattern=$1
    echo "Verificando padrÃ£o: $pattern"
    
    # Usar SCAN para evitar KEYS (mais seguro)
    redis-cli -h $DATA_ENDPOINT -p 6379 --tls --scan --pattern "$pattern" | while read key; do
        TTL=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls ttl "$key")
        if [ "$TTL" = "-1" ]; then
            SIZE=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls memory usage "$key" 2>/dev/null || echo "N/A")
            echo "  $key: sem TTL, tamanho: $SIZE bytes"
        fi
    done
}

# Verificar diferentes padrÃµes
check_ttl_patterns "big_*:$ID*"
check_ttl_patterns "session:$ID:*"
check_ttl_patterns "small:$ID:*"
```

#### Passo 3: Simular Problema de ExpiraÃ§Ã£o

```bash
# Criar chaves com TTL muito baixo para demonstrar problema
echo "ğŸ§ª Simulando problema de expiraÃ§Ã£o..."

# Criar muitas chaves com TTL baixo
echo "Criando chaves com TTL baixo..."
for i in {1..1000}; do
    $REDIS_CMD SET "expire_test:$ID:$i" "value$i" EX 30 > /dev/null
done

echo "âœ… Criadas 1000 chaves com TTL de 30 segundos"

# Monitorar estatÃ­sticas de expiraÃ§Ã£o
echo "ğŸ“Š Monitorando estatÃ­sticas de expiraÃ§Ã£o..."
for i in {1..6}; do
    echo "=== VerificaÃ§Ã£o $i ($(date '+%H:%M:%S')) ==="
    
    # EstatÃ­sticas de expiraÃ§Ã£o
    redis-cli -h $DATA_ENDPOINT -p 6379 --tls info stats | grep -E "(expired_keys|evicted_keys)"
    
    # Contar chaves restantes
    REMAINING=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls eval "return #redis.call('keys', 'expire_test:$ID:*')" 0)
    echo "Chaves restantes: $REMAINING"
    
    sleep 10
done
```

#### Passo 4: Analisar Impacto de ExpiraÃ§Ã£o na Performance

```bash
# Verificar configuraÃ§Ã£o de expiraÃ§Ã£o
echo "ğŸ” Analisando configuraÃ§Ã£o de expiraÃ§Ã£o..."

redis-cli -h $DATA_ENDPOINT -p 6379 --tls config get "*expire*"
redis-cli -h $DATA_ENDPOINT -p 6379 --tls config get "*hz*"

# Verificar estatÃ­sticas detalhadas
echo "ğŸ“ˆ EstatÃ­sticas de expiraÃ§Ã£o e eviction:"
redis-cli -h $DATA_ENDPOINT -p 6379 --tls info stats | grep -E "(expired_keys|evicted_keys|keyspace_hits|keyspace_misses)"

# Calcular hit rate
HITS=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls info stats | grep keyspace_hits | cut -d: -f2 | tr -d '\r')
MISSES=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls info stats | grep keyspace_misses | cut -d: -f2 | tr -d '\r')
TOTAL=$((HITS + MISSES))
if [ $TOTAL -gt 0 ]; then
    HIT_RATE=$(( HITS * 100 / TOTAL ))
    echo "Hit Rate: ${HIT_RATE}% ($HITS hits, $MISSES misses)"
else
    echo "Hit Rate: N/A (sem estatÃ­sticas suficientes)"
fi
```

**Problemas Comuns de TTL:**
- âœ… Big keys sem TTL (consomem memÃ³ria indefinidamente)
- âœ… TTL muito baixo (overhead de expiraÃ§Ã£o)
- âœ… TTL inconsistente (alguns dados expiram, outros nÃ£o)
- âœ… Falta de estratÃ©gia de eviction

**âœ… Checkpoint:** Identificar problemas de TTL e estratÃ©gias de expiraÃ§Ã£o.

---

## ğŸ” AnÃ¡lise AvanÃ§ada de PadrÃµes de Dados

### IdentificaÃ§Ã£o de PadrÃµes ProblemÃ¡ticos

#### 1. Big Keys ProblemÃ¡ticos
```bash
# Identificar big keys por tipo
echo "ğŸ“Š AnÃ¡lise de Big Keys por Tipo:"

# Strings grandes
redis-cli -h $DATA_ENDPOINT -p 6379 --tls --scan --pattern "*" | while read key; do
    TYPE=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls type "$key")
    if [ "$TYPE" = "string" ]; then
        SIZE=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls memory usage "$key" 2>/dev/null)
        if [ "$SIZE" -gt 10240 ]; then  # > 10KB
            echo "Big String: $key ($SIZE bytes)"
        fi
    fi
done | head -10
```

#### 2. Estruturas Ineficientes
```bash
# Analisar eficiÃªncia de estruturas
echo "ğŸ“Š AnÃ¡lise de EficiÃªncia de Estruturas:"

# Hash vs mÃºltiplas strings
echo "=== ComparaÃ§Ã£o Hash vs Strings ==="
# Criar dados equivalentes
# Usando Hash (eficiente)
$REDIS_CMD HSET "user_hash:$ID:1" name "JoÃ£o" email "joao@test.com" age "30"

# Usando mÃºltiplas strings (ineficiente)
$REDIS_CMD SET "user_string:$ID:1:name" "JoÃ£o"
$REDIS_CMD SET "user_string:$ID:1:email" "joao@test.com"
$REDIS_CMD SET "user_string:$ID:1:age" "30"

# Comparar uso de memÃ³ria
HASH_SIZE=$($REDIS_CMD memory usage "user_hash:$ID:1")
STRING1_SIZE=$($REDIS_CMD memory usage "user_string:$ID:1:name")
STRING2_SIZE=$($REDIS_CMD memory usage "user_string:$ID:1:email")
STRING3_SIZE=$($REDIS_CMD memory usage "user_string:$ID:1:age")
STRINGS_TOTAL=$((STRING1_SIZE + STRING2_SIZE + STRING3_SIZE))

echo "Hash: $HASH_SIZE bytes"
echo "Strings: $STRINGS_TOTAL bytes"
echo "Economia com Hash: $((STRINGS_TOTAL - HASH_SIZE)) bytes ($(( (STRINGS_TOTAL - HASH_SIZE) * 100 / STRINGS_TOTAL ))%)"
```

#### 3. AnÃ¡lise de FragmentaÃ§Ã£o

```bash
# Verificar fragmentaÃ§Ã£o de memÃ³ria
echo "ğŸ“Š AnÃ¡lise de FragmentaÃ§Ã£o:"
redis-cli -h $DATA_ENDPOINT -p 6379 --tls info memory | grep -E "(mem_fragmentation|mem_allocator)"

# Verificar estatÃ­sticas de alocaÃ§Ã£o
redis-cli -h $DATA_ENDPOINT -p 6379 --tls memory stats
```

## ğŸ› ï¸ EstratÃ©gias de OtimizaÃ§Ã£o

### 1. OtimizaÃ§Ã£o de Big Keys

```bash
# Demonstrar estratÃ©gias para big keys
echo "ğŸ”§ EstratÃ©gias de OtimizaÃ§Ã£o para Big Keys:"

# EstratÃ©gia 1: PaginaÃ§Ã£o de listas grandes
echo "=== PaginaÃ§Ã£o de Lista Grande ==="
# Em vez de LRANGE 0 -1 (custoso), usar paginaÃ§Ã£o
redis-cli -h $DATA_ENDPOINT -p 6379 --tls lrange big_list:$ID 0 99  # Primeira pÃ¡gina
redis-cli -h $DATA_ENDPOINT -p 6379 --tls lrange big_list:$ID 100 199  # Segunda pÃ¡gina

# EstratÃ©gia 2: Usar HSCAN em vez de HGETALL
echo "=== Scan de Hash Grande ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls hscan big_hash:$ID 0 COUNT 100
```

### 2. OtimizaÃ§Ã£o de Hot Keys

```bash
# EstratÃ©gias para hot keys
echo "ğŸ”§ EstratÃ©gias de OtimizaÃ§Ã£o para Hot Keys:"

# EstratÃ©gia 1: ReplicaÃ§Ã£o de hot keys (simulaÃ§Ã£o)
HOT_VALUE=$($REDIS_CMD GET "hot_candidate:$ID:1")
$REDIS_CMD SET "hot_replica:$ID:1:shard1" "$HOT_VALUE"
$REDIS_CMD SET "hot_replica:$ID:1:shard2" "$HOT_VALUE"
$REDIS_CMD SET "hot_replica:$ID:1:shard3" "$HOT_VALUE"

echo "âœ… Hot key replicada em 3 shards para distribuir carga"
```

### 3. ConfiguraÃ§Ã£o de TTL Inteligente

```bash
# Configurar TTL baseado no tipo de dados
echo "ğŸ”§ ConfiguraÃ§Ã£o de TTL Inteligente:"

# TTL baseado no tipo de dados
$REDIS_CMD SET "cache:$ID:user:1" "user data" EX 3600        # Cache de usuÃ¡rio: 1h
$REDIS_CMD SET "session:$ID:abc123" "session data" EX 1800   # SessÃ£o: 30min
$REDIS_CMD SET "temp:$ID:calc" "temp result" EX 300          # Resultado temporÃ¡rio: 5min

echo "âœ… TTL configurado baseado no tipo de dados"
```

## ğŸ’° AtenÃ§Ã£o aos Custos

âš ï¸ **IMPORTANTE:** Este laboratÃ³rio cria recursos AWS que geram custos na regiÃ£o us-east-2:

- Cache cluster: ~$0.017/hora (cache.t3.micro)
- Data transfer: MÃ­nimo para este lab
- CloudWatch mÃ©tricas: IncluÃ­das no Free Tier

**Custo estimado por aluno:** ~$0.05 para completar o laboratÃ³rio

## ğŸ§¹ Limpeza de Recursos

**CRÃTICO:** Ao final do laboratÃ³rio, delete seus recursos para evitar custos:

### Via Console Web:
1. **ElastiCache** > **"Caches do Redis OSS"**
   - Selecione `lab-data-$ID`
   - **Actions** > **Delete**
   - Confirme a deleÃ§Ã£o

### Via CLI:
```bash
# Deletar replication group
aws elasticache delete-replication-group --replication-group-id lab-data-$ID --region us-east-2

# Monitorar deleÃ§Ã£o
watch -n 30 "aws elasticache describe-replication-groups --replication-group-id lab-data-$ID --region us-east-2 2>/dev/null || echo 'Replication Group deletado com sucesso'"

# Limpar arquivos temporÃ¡rios
rm -f /tmp/bigkeys_analysis_$ID.txt
rm -f /tmp/monitor_output_$ID.txt
```

**NOTA:** Mantenha o Security Group para uso no prÃ³ximo laboratÃ³rio.

## ğŸ“– Recursos Adicionais

- [Redis Memory Optimization](https://redis.io/topics/memory-optimization)
- [Redis Data Types](https://redis.io/topics/data-types)
- [Redis Best Practices](https://redis.io/topics/memory-optimization)
- [ElastiCache Best Practices](https://docs.aws.amazon.com/elasticache/latest/red-ug/BestPractices.html)

## ğŸ†˜ Troubleshooting

### Problemas Comuns

1. **Erro de conexÃ£o com redis-cli**
   - **Criptografia em trÃ¢nsito habilitada:** Use `redis-cli` com `--tls`
   - **Exemplo:** `redis-cli -h $DATA_ENDPOINT -p 6379 --tls ping`
   - **DocumentaÃ§Ã£o:** [ElastiCache Encryption](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html)

2. **Big keys causando latÃªncia**
   - Use paginaÃ§Ã£o em vez de operaÃ§Ãµes completas
   - Considere quebrar big keys em estruturas menores
   - Implemente TTL apropriado

3. **Hot keys sobrecarregando cluster**
   - Replique hot keys em mÃºltiplas chaves
   - Use cache local na aplicaÃ§Ã£o
   - Considere cluster mode enabled

4. **MemÃ³ria crescendo indefinidamente**
   - Implemente TTL em todas as chaves
   - Configure polÃ­tica de eviction
   - Monitore padrÃµes de crescimento

5. **Performance degradada**
   - Evite comandos KEYS em produÃ§Ã£o
   - Use SCAN em vez de operaÃ§Ãµes completas
   - Otimize estruturas de dados

6. **Hit rate baixo**
   - Revise estratÃ©gia de TTL
   - Analise padrÃµes de acesso
   - Ajuste tamanho do cache

## ğŸ¯ Objetivos de Aprendizado AlcanÃ§ados

Ao final deste laboratÃ³rio, vocÃª deve conseguir:

- âœ… Identificar big keys usando ferramentas Redis
- âœ… Detectar hot keys atravÃ©s de monitoramento
- âœ… Analisar padrÃµes de TTL e expiraÃ§Ã£o
- âœ… Correlacionar problemas de dados com performance
- âœ… Implementar estratÃ©gias de otimizaÃ§Ã£o de dados
- âœ… Configurar estruturas de dados eficientes
- âœ… Monitorar e alertar sobre problemas de dados

## ğŸ“ Notas Importantes

- **Big keys** (>100KB ou >1000 elementos) podem bloquear operaÃ§Ãµes
- **Hot keys** concentram carga e criam gargalos
- **TTL inadequado** causa crescimento descontrolado de memÃ³ria
- **Estruturas ineficientes** desperdiÃ§am recursos
- **Comandos KEYS** devem ser evitados em produÃ§Ã£o
- **PaginaÃ§Ã£o** Ã© essencial para big keys
- **Monitoramento contÃ­nuo** previne problemas de dados

## â¡ï¸ PrÃ³ximo LaboratÃ³rio

Agora que vocÃª domina troubleshooting de dados, vÃ¡ para:

**[Lab 05: RedisInsight](../lab05-redisinsight/README.md)**

---

**ParabÃ©ns! VocÃª completou o Lab 04! ğŸ‰**

*VocÃª agora possui habilidades avanÃ§adas para identificar, analisar e resolver problemas relacionados a dados no ElastiCache.*