# Lab 04 - Troubleshooting de Dados

LaboratÃ³rio focado na anÃ¡lise do data plane do Redis no ElastiCache na regiÃ£o **us-east-2**, desenvolvendo habilidades para identificar, analisar e resolver problemas relacionados a big keys, hot keys, estruturas inadequadas e padrÃµes problemÃ¡ticos que impactam performance.

## ğŸ“‹ Objetivos do LaboratÃ³rio

- Identificar big keys que causam bloqueios e latÃªncia
- Detectar hot keys responsÃ¡veis por hotspots e sobrecarga
- Analisar estruturas de dados inadequadas e ineficientes
- Diagnosticar problemas de TTL e expiraÃ§Ã£o de chaves
- Avaliar padrÃµes de acesso e distribuiÃ§Ã£o de dados
- Correlacionar problemas de dados com mÃ©tricas de performance
- Implementar estratÃ©gias de otimizaÃ§Ã£o de dados

## â±ï¸ DuraÃ§Ã£o Estimada: 60 minutos

## ğŸŒ RegiÃ£o AWS: us-east-2 (Ohio)

**IMPORTANTE:** Todos os recursos devem ser criados na regiÃ£o **us-east-2**. Verifique sempre a regiÃ£o no canto superior direito do Console AWS.

## ğŸ—ï¸ Estrutura do LaboratÃ³rio

```
lab04-troubleshooting-dados/
â”œâ”€â”€ README.md                    # Este guia (foco principal)
â”œâ”€â”€ scripts/                     # Scripts de referÃªncia (opcional)
â”‚   â”œâ”€â”€ create-data-cluster.sh
â”‚   â”œâ”€â”€ generate-big-keys.sh
â”‚   â”œâ”€â”€ simulate-hot-keys.sh
â”‚   â”œâ”€â”€ analyze-data-patterns.sh
â”‚   â””â”€â”€ cleanup-lab04.sh
â””â”€â”€ ferramentas/                 # Ferramentas de anÃ¡lise (opcional)
    â”œâ”€â”€ big-key-analyzer.py
    â”œâ”€â”€ hot-key-detector.sh
    â””â”€â”€ data-pattern-report.py
```

**IMPORTANTE:** Este laboratÃ³rio foca na anÃ¡lise manual via Redis CLI e ferramentas especÃ­ficas. Os scripts sÃ£o apenas para referÃªncia e simulaÃ§Ã£o de cenÃ¡rios.

## ğŸš€ PrÃ©-requisitos

- Conta AWS ativa configurada para regiÃ£o **us-east-2**
- AWS CLI configurado para regiÃ£o us-east-2
- Acesso Ã  instÃ¢ncia EC2 fornecida pelo instrutor (Bastion Host)
- Redis CLI instalado e funcional
- Conhecimento bÃ¡sico de estruturas de dados Redis
- **ID do Aluno:** VocÃª deve usar seu ID Ãºnico (ex: aluno01, aluno02, etc.)
- **Labs anteriores:** VPC, Subnet Group e Security Group jÃ¡ criados

## ğŸ·ï¸ ConvenÃ§Ã£o de Nomenclatura

Todos os recursos criados devem seguir o padrÃ£o:
- **Cluster de Dados:** `lab-data-$ID`
- **Security Groups:** Reutilizar `elasticache-lab-sg-$ID` dos labs anteriores

**Exemplo para aluno01:**
- Cluster: `lab-data-aluno01`
- Security Group: `elasticache-lab-sg-aluno01` (jÃ¡ existente)

## ğŸ“š ExercÃ­cios

### ExercÃ­cio 1: Preparar Ambiente com Dados Diversos (15 minutos)

**Objetivo:** Criar cluster e popular com diferentes tipos e tamanhos de dados

> **ğŸ¯ POR QUE ESTE EXERCÃCIO Ã‰ IMPORTANTE:**
> 
> Imagine que vocÃª Ã© um detetive investigando um crime. Antes de procurar pistas, vocÃª precisa conhecer a cena do crime. No Redis, os "crimes" sÃ£o problemas de performance causados por dados mal estruturados.
> 
> **Neste exercÃ­cio, vamos criar uma "cena do crime" controlada** com diferentes tipos de problemas de dados:
> - **Big Keys** (chaves grandes) - como caixas pesadas que demoram para mover
> - **Hot Keys** (chaves populares) - como uma porta que todo mundo quer usar ao mesmo tempo
> - **Dados sem TTL** - como lixo que nunca Ã© coletado
> - **Estruturas ineficientes** - como usar 10 gavetas quando 1 bastaria

#### Passo 1: Verificar PrÃ©-requisitos

```bash
# Verificar Security Group dos labs anteriores
aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$ID" --region us-east-2
```

#### Passo 2: Criar Cluster de Dados via Console Web

1. Acesse **ElastiCache** no Console AWS
2. Na pÃ¡gina inicial, selecione **"Caches do Redis OSS"** â† **IMPORTANTE**
3. Selecione **"Cache de cluster"** (nÃ£o serverless)
4. Selecione **"Cache de cluster"** (configuraÃ§Ã£o manual, nÃ£o criaÃ§Ã£o fÃ¡cil)
5. Configure:
   - **Cluster mode:** Disabled
   - **Cluster info:**
     - **Name:** `lab-data-$ID`
     - **Description:** `Lab data troubleshooting cluster for $ID`
   - **Location:**
     - **AWS Cloud**
     - **Multi-AZ:** Disabled (para este lab)
     - **Failover automÃ¡tico:** Desabilitado (nÃ£o aplicÃ¡vel sem rÃ©plicas)
   - **Cluster settings:**
     - **Engine version:** 7.0
     - **Port:** 6379
     - **Node type:** **cache.t3.micro** (para demonstrar limitaÃ§Ãµes)
     - **Number of replicas:** 0
   - **Connectivity:**
     - **Network type:** IPv4
     - **Subnet group:** `elasticache-lab-subnet-group`
     - **Security groups:** Selecione seu SG `elasticache-lab-sg-$ID`
   - **Security (SeguranÃ§a):**
     - **Criptografia em repouso:** Habilitada (recomendado)
     - **Chave de criptografia:** Chave padrÃ£o (AWS managed)
     - **Criptografia em trÃ¢nsito:** Habilitada (recomendado)
     - **Controle de acesso:** Nenhum controle de acesso (para simplicidade do lab)
   - **Backup:**
     - **Enable automatic backups:** Enabled
   - **Maintenance:**
     - **Auto minor version upgrade:** Enabled
   - **Advanced settings:**
     - **Tags (Recomendado):**
       - **Key:** `Name` **Value:** `Lab Data - $ID`
       - **Key:** `Lab` **Value:** `Lab04`
       - **Key:** `Purpose` **Value:** `Data-Analysis`

6. Clique em **Create**

> **ğŸ“š Para saber mais sobre seguranÃ§a:**
> - [Criptografia no ElastiCache](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html)
> - [ConfiguraÃ§Ãµes de seguranÃ§a](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth.html)

#### Alternativa: CriaÃ§Ã£o RÃ¡pida via CLI

Para acelerar o processo, vocÃª pode criar o cluster via CLI:

```bash
# Obter IDs necessÃ¡rios
VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=ElastiCache-Lab-VPC" --query 'Vpcs[0].VpcId' --output text --region us-east-2)
SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$ID" --query 'SecurityGroups[0].GroupId' --output text --region us-east-2)

# IMPORTANTE: Para ter criptografia via CLI, devemos usar Replication Group (mesmo com 1 nÃ³)
# create-cache-cluster NÃƒO suporta parÃ¢metros de criptografia
aws elasticache create-replication-group \
    --replication-group-id "lab-data-$ID" \
    --replication-group-description "Data troubleshooting with encryption" \
    --num-cache-clusters 1 \
    --cache-node-type cache.t3.micro \
    --engine redis \
    --engine-version 7.0 \
    --port 6379 \
    --cache-subnet-group-name elasticache-lab-subnet-group \
    --security-group-ids $SG_ID \
    --at-rest-encryption-enabled \
    --transit-encryption-enabled \
    --auto-minor-version-upgrade \
    --tags Key=Name,Value="Lab Data - $ID" Key=Lab,Value=Lab04 Key=Purpose,Value=Data-Analysis \
    --region us-east-2

echo "âœ… Replication Group criado via CLI! Aguarde ~10-15 minutos para ficar disponÃ­vel."
```

> **ğŸ—ï¸ PONTO ARQUITETURAL IMPORTANTE:**
> 
> **Por que usar `create-replication-group` em vez de `create-cache-cluster`?**
> 
> - **`create-cache-cluster`:** Comando legado, NÃƒO suporta criptografia
> - **`create-replication-group`:** Comando moderno, suporta todas as funcionalidades
> 
> **Mesmo para 1 nÃ³ Ãºnico**, use `create-replication-group` se precisar de:
> - âœ… Criptografia (at-rest e in-transit)
> - âœ… Backups automÃ¡ticos
> - âœ… Multi-AZ (futuro)
> - âœ… Failover automÃ¡tico (futuro)
> 
> **Regra prÃ¡tica:** Sempre use `create-replication-group` em produÃ§Ã£o!

#### Passo 3: Aguardar CriaÃ§Ã£o e Obter Endpoint

```bash
# Monitorar criaÃ§Ã£o
watch -n 30 "aws elasticache describe-replication-groups --replication-group-id lab-data-$ID --query 'ReplicationGroups[0].Status' --output text --region us-east-2"

# Quando disponÃ­vel, obter endpoint
DATA_ENDPOINT=$(aws elasticache describe-replication-groups --replication-group-id lab-data-$ID --query 'ReplicationGroups[0].NodeGroups[0].PrimaryEndpoint.Address' --output text --region us-east-2)
echo "Data Cluster Endpoint: $DATA_ENDPOINT"
```

#### Passo 4: Popular com Dados Diversos

```bash
# Testar conectividade primeiro
if redis-cli -h $DATA_ENDPOINT -p 6379 --tls ping > /dev/null 2>&1; then
    echo "âœ… Conectividade OK (com TLS)"
    REDIS_CMD="redis-cli -h $DATA_ENDPOINT -p 6379 --tls"
else
    echo "âŒ Erro de conectividade"
    exit 1
fi

# Popular com diferentes tipos de dados
echo "ğŸ“Š Populando cluster com dados diversos..."

# Limpar dados existentes
$REDIS_CMD FLUSHALL

# === DADOS PEQUENOS (baseline) ===
echo "Inserindo dados pequenos..."
for i in {1..1000}; do
    $REDIS_CMD SET "small:$ID:$i" "value$i" > /dev/null
done

# === STRINGS GRANDES (big keys potenciais) ===
echo "Criando big strings..."
$REDIS_CMD SET "big_string:$ID:1mb" "$(printf 'A%.0s' {1..1048576})"
$REDIS_CMD SET "big_string:$ID:500kb" "$(printf 'B%.0s' {1..512000})"
$REDIS_CMD SET "big_string:$ID:100kb" "$(printf 'C%.0s' {1..102400})"

# === LISTAS GRANDES ===
echo "Criando big list..."
for i in {1..10000}; do
    $REDIS_CMD LPUSH "big_list:$ID" "item$i" > /dev/null
done

# === HASHES GRANDES ===
echo "Criando big hash..."
for i in {1..5000}; do
    $REDIS_CMD HSET "big_hash:$ID" "field$i" "value$i" > /dev/null
done

# === SETS GRANDES ===
echo "Criando big set..."
for i in {1..3000}; do
    $REDIS_CMD SADD "big_set:$ID" "member$i" > /dev/null
done

# === SORTED SETS GRANDES ===
echo "Criando big sorted set..."
for i in {1..2000}; do
    $REDIS_CMD ZADD "big_zset:$ID" $i "member$i" > /dev/null
done

# === DADOS COM TTL VARIADO ===
$REDIS_CMD SET "ttl_short:$ID:1" "expires in 60s" EX 60
$REDIS_CMD SET "ttl_medium:$ID:1" "expires in 300s" EX 300
$REDIS_CMD SET "ttl_long:$ID:1" "expires in 3600s" EX 3600
$REDIS_CMD SET "no_ttl:$ID:1" "never expires"

# === DADOS PARA HOT KEYS ===
echo "Criando hot key candidates..."
for i in {1..100}; do
    $REDIS_CMD SET "hot_candidate:$ID:$i" "hotvalue$i" > /dev/null
done

# === ESTRUTURAS ANINHADAS (JSON-like) ===
$REDIS_CMD SET "json_data:$ID:user1" '{"id":1,"name":"JoÃ£o Silva","email":"joao@example.com","preferences":{"theme":"dark","notifications":true},"history":[1,2,3,4,5]}'
$REDIS_CMD SET "json_data:$ID:user2" '{"id":2,"name":"Maria Santos","email":"maria@example.com","preferences":{"theme":"light","notifications":false},"history":[6,7,8,9,10]}'

# === DADOS DE SESSÃƒO ===
echo "Criando dados de sessÃ£o..."
for i in {1..200}; do
    $REDIS_CMD HSET "session:$ID:$i" user_id $i login_time $(date +%s) ip "192.168.1.$((i%255))" > /dev/null
done

echo "âœ… Dados diversos inseridos no cluster"
```

**âœ… Checkpoint:** Cluster deve estar populado com dados de diferentes tipos e tamanhos.

---

### ExercÃ­cio 2: Identificar Big Keys (15 minutos)

**Objetivo:** Usar ferramentas Redis para identificar chaves que consomem muita memÃ³ria

> **ğŸ” O QUE SÃƒO BIG KEYS E POR QUE SÃƒO PROBLEMÃTICAS:**
> 
> **Analogia:** Imagine um estacionamento onde a maioria dos carros sÃ£o compactos, mas alguns sÃ£o caminhÃµes gigantes. Os caminhÃµes:
> - **Demoram mais para entrar/sair** (operaÃ§Ãµes lentas)
> - **Ocupam muito espaÃ§o** (consomem muita memÃ³ria)  
> - **Bloqueiam outras vagas** (Redis Ã© single-threaded, operaÃ§Ãµes grandes bloqueiam outras)
> - **Causam engarrafamento** (impactam performance geral)
> 
> **No Redis, Big Keys sÃ£o:**
> - **Strings > 100KB** (textos muito grandes)
> - **Listas > 1000 elementos** (arrays gigantes)
> - **Hashes > 1000 campos** (objetos com muitas propriedades)
> - **Sets/Sorted Sets > 1000 membros** (coleÃ§Ãµes enormes)
> 
> **Por que sÃ£o problemÃ¡ticas:**
> - âœ… **OperaÃ§Ãµes lentas:** `GET` de 1MB demora muito mais que `GET` de 1KB
> - âœ… **Bloqueio:** Enquanto processa big key, outras operaÃ§Ãµes esperam
> - âœ… **MemÃ³ria:** Podem consumir 80% da RAM disponÃ­vel
> - âœ… **ReplicaÃ§Ã£o:** Demoram para sincronizar entre nÃ³s

#### Passo 1: AnÃ¡lise BÃ¡sica de MemÃ³ria

> **ğŸ§  O QUE VAMOS FAZER:**
> Antes de procurar big keys especÃ­ficas, vamos entender o "panorama geral" da memÃ³ria, como um mÃ©dico que primeiro mede pressÃ£o e temperatura antes de fazer exames especÃ­ficos.

```bash
# Verificar uso total de memÃ³ria
echo "ğŸ” Analisando uso de memÃ³ria..."
$REDIS_CMD info memory | grep -E "(used_memory|used_memory_human|used_memory_peak)"

# Contar total de chaves
TOTAL_KEYS=$($REDIS_CMD dbsize)
echo "Total de chaves: $TOTAL_KEYS"
```

> **ğŸ“Š INTERPRETANDO OS RESULTADOS:**
> 
> **used_memory_human:** MemÃ³ria total usada (ex: "2.5M" = 2.5 megabytes)
> - **< 10MB:** Uso baixo, normal para labs
> - **10-100MB:** Uso moderado
> - **> 100MB:** Uso alto, investigar big keys
> 
> **used_memory_peak:** Maior uso de memÃ³ria jÃ¡ registrado
> - Se muito maior que atual = houve picos de uso
> - Pode indicar big keys temporÃ¡rias ou vazamentos
> 
> **Total de chaves vs MemÃ³ria:**
> - **1000 chaves = 1MB:** Chaves pequenas (~1KB cada)
> - **1000 chaves = 10MB:** Chaves mÃ©dias (~10KB cada)  
> - **1000 chaves = 100MB:** Big keys! (~100KB cada)
> 
> **ğŸš¨ SINAIS DE ALERTA:**
> - Poucas chaves mas muita memÃ³ria = Big Keys
> - Muitas chaves mas pouca memÃ³ria = Chaves muito pequenas (ineficiente)
> - Pico muito maior que atual = Problema intermitente

#### Passo 2: Usar --bigkeys para Identificar Big Keys

> **ğŸ”§ O QUE Ã‰ O COMANDO --bigkeys:**
> 
> **Analogia:** Ã‰ como um "scanner de bagagem" no aeroporto que identifica automaticamente as malas mais pesadas sem precisar abrir cada uma.
> 
> **O que faz:**
> - **Escaneia TODAS as chaves** do banco (pode demorar!)
> - **Agrupa por tipo** (strings, listas, hashes, etc.)
> - **Identifica as maiores** de cada tipo
> - **Mostra estatÃ­sticas** gerais de uso
> 
> **âš ï¸ CUIDADO:** Em produÃ§Ã£o, pode impactar performance durante o scan!

```bash
# Executar anÃ¡lise de big keys (pode demorar alguns minutos)
echo "ğŸ” Executando anÃ¡lise de big keys..."
$REDIS_CMD --bigkeys

# Salvar resultado em arquivo para anÃ¡lise
$REDIS_CMD --bigkeys > /tmp/bigkeys_analysis_$ID.txt
echo "ğŸ“„ Resultado salvo em /tmp/bigkeys_analysis_$ID.txt"
```

> **ğŸ“‹ INTERPRETANDO O RESULTADO DO --bigkeys:**
> 
> **Exemplo de saÃ­da:**
> ```
> -------- summary -------
> Sampled 5000 keys in the keyspace!
> Total key length in bytes is 45000 (avg len 9.00)
> 
> Biggest string found 'big_string:aluno01:1mb' has 1048576 bytes
> Biggest list   found 'big_list:aluno01' has 10000 items
> Biggest hash   found 'big_hash:aluno01' has 5000 fields
> ```
> 
> **Como interpretar:**
> - **"Biggest string":** A maior string encontrada (1MB neste caso)
> - **"has X bytes":** Tamanho em bytes (1048576 = 1MB)
> - **"has X items/fields":** NÃºmero de elementos na estrutura
> - **"avg len":** Tamanho mÃ©dio das chaves (nome da chave, nÃ£o valor)
> 
> **ğŸš¨ ALERTAS:**
> - **Strings > 100KB:** Considere quebrar em pedaÃ§os menores
> - **Listas > 1000 items:** Use paginaÃ§Ã£o ou estruturas menores
> - **Hashes > 1000 fields:** Considere mÃºltiplos hashes menores

#### Passo 3: AnÃ¡lise Manual de Chaves EspecÃ­ficas

> **ğŸ¯ POR QUE ANÃLISE MANUAL:**
> 
> **Analogia:** O --bigkeys Ã© como um "resumo executivo", mas Ã s vezes vocÃª precisa "abrir a gaveta" e ver exatamente o que tem dentro.
> 
> **Quando usar:**
> - **Investigar chaves suspeitas** identificadas pelo --bigkeys
> - **Comparar tamanhos** entre diferentes estruturas
> - **Entender o crescimento** de chaves especÃ­ficas
> - **Validar otimizaÃ§Ãµes** apÃ³s mudanÃ§as
> 
> **Comando MEMORY USAGE:**
> - **Mostra bytes exatos** que a chave ocupa na RAM
> - **Inclui overhead** do Redis (metadados, Ã­ndices, etc.)
> - **Mais preciso** que estimativas baseadas em conteÃºdo

```bash
# Analisar uso de memÃ³ria de chaves especÃ­ficas
echo "ğŸ” Analisando chaves especÃ­ficas..."

# Verificar tamanho das big strings
echo "=== Big Strings ==="
$REDIS_CMD memory usage big_string:$ID:1mb
$REDIS_CMD memory usage big_string:$ID:500kb
$REDIS_CMD memory usage big_string:$ID:100kb

# Verificar tamanho das estruturas grandes
echo "=== Big Structures ==="
$REDIS_CMD memory usage big_list:$ID
$REDIS_CMD memory usage big_hash:$ID
$REDIS_CMD memory usage big_set:$ID
$REDIS_CMD memory usage big_zset:$ID

# Verificar nÃºmero de elementos
echo "=== Contagem de Elementos ==="
echo "Lista: $($REDIS_CMD llen big_list:$ID) elementos"
echo "Hash: $($REDIS_CMD hlen big_hash:$ID) campos"
echo "Set: $($REDIS_CMD scard big_set:$ID) membros"
echo "Sorted Set: $($REDIS_CMD zcard big_zset:$ID) membros"
```

> **ğŸ“Š INTERPRETANDO OS RESULTADOS:**
> 
> **MEMORY USAGE retorna bytes:**
> - **1048576 bytes = 1MB** (nossa big string de 1MB)
> - **512000 bytes = 500KB** (nossa big string de 500KB)
> - **Valores maiores que esperado?** Redis adiciona overhead (metadados)
> 
> **Contagem vs Tamanho:**
> - **Lista com 10000 elementos = ~200KB:** Normal (~20 bytes por item)
> - **Hash com 5000 campos = ~300KB:** Normal (~60 bytes por campo)
> - **Valores muito maiores?** Elementos individuais sÃ£o grandes
> 
> **ğŸ” ANÃLISE PRÃTICA:**
> ```
> Lista: 10000 elementos, 500KB total
> â†’ 500KB Ã· 10000 = 50 bytes por elemento (normal)
> 
> Lista: 1000 elementos, 500KB total  
> â†’ 500KB Ã· 1000 = 500 bytes por elemento (elementos grandes!)
> ```
> 
> **ğŸš¨ SINAIS DE PROBLEMA:**
> - **Overhead > 50%:** Muitas chaves pequenas (ineficiente)
> - **Elementos > 1KB cada:** Considere estruturas diferentes
> - **Crescimento descontrolado:** Falta TTL ou limpeza

#### Passo 4: Impacto de Big Keys na Performance

> **âš¡ POR QUE BIG KEYS AFETAM PERFORMANCE:**
> 
> **Analogia:** Imagine que vocÃª precisa mover uma caixa. Uma caixa de 1kg vocÃª move rapidamente, mas uma caixa de 100kg:
> - **Demora muito mais para mover** (operaÃ§Ã£o lenta)
> - **VocÃª fica ocupado por mais tempo** (bloqueia outras tarefas)
> - **Cansa mais** (usa mais recursos)
> - **Outras pessoas esperam** (impacta outras operaÃ§Ãµes)
> 
> **No Redis Ã© igual:**
> - **Redis Ã© single-threaded:** Uma operaÃ§Ã£o lenta bloqueia todas as outras
> - **OperaÃ§Ãµes grandes = latÃªncia alta:** UsuÃ¡rios esperam mais
> - **MemÃ³ria fragmentada:** Dificulta alocaÃ§Ã£o de novos dados
> - **ReplicaÃ§Ã£o lenta:** Demora para sincronizar com rÃ©plicas

```bash
# Testar impacto de operaÃ§Ãµes em big keys
echo "ğŸ§ª Testando impacto de big keys na performance..."

# OperaÃ§Ã£o custosa: obter lista completa (MUITO CUSTOSO)
echo "Testando LRANGE em big_list..."
START_TIME=$(date +%s%N)
$REDIS_CMD lrange big_list:$ID 0 -1 > /dev/null
END_TIME=$(date +%s%N)
LRANGE_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "LRANGE completo: ${LRANGE_TIME}ms"

# OperaÃ§Ã£o custosa: obter hash completo
echo "Testando HGETALL em big_hash..."
START_TIME=$(date +%s%N)
$REDIS_CMD hgetall big_hash:$ID > /dev/null
END_TIME=$(date +%s%N)
HGETALL_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "HGETALL completo: ${HGETALL_TIME}ms"

# Comparar com operaÃ§Ã£o simples
echo "Testando GET em chave pequena..."
START_TIME=$(date +%s%N)
$REDIS_CMD get small:$ID:1 > /dev/null
END_TIME=$(date +%s%N)
GET_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "GET simples: ${GET_TIME}ms"

echo ""
echo "ğŸ“Š ComparaÃ§Ã£o de Performance:"
echo "GET simples: ${GET_TIME}ms"
echo "LRANGE big_list: ${LRANGE_TIME}ms ($(( LRANGE_TIME / GET_TIME ))x mais lento)"
echo "HGETALL big_hash: ${HGETALL_TIME}ms ($(( HGETALL_TIME / GET_TIME ))x mais lento)"
```

> **ğŸ“Š INTERPRETANDO OS RESULTADOS DE PERFORMANCE:**
> 
> **Tempos tÃ­picos esperados:**
> - **GET simples:** 0.1-1ms (muito rÃ¡pido)
> - **LRANGE pequeno (100 items):** 1-5ms (rÃ¡pido)
> - **LRANGE grande (10000 items):** 10-100ms (lento!)
> - **HGETALL pequeno (10 campos):** 1-5ms (rÃ¡pido)
> - **HGETALL grande (5000 campos):** 50-200ms (muito lento!)
> 
> **ğŸš¨ SINAIS DE PROBLEMA:**
> - **OperaÃ§Ã£o > 10ms:** Pode impactar usuÃ¡rios
> - **OperaÃ§Ã£o > 100ms:** Definitivamente problemÃ¡tica
> - **DiferenÃ§a > 100x:** Big key muito problemÃ¡tica
> 
> **ğŸ’¡ IMPACTO REAL:**
> ```
> CenÃ¡rio: 1000 usuÃ¡rios simultÃ¢neos
> 
> GET simples (1ms):
> â†’ 1000 operaÃ§Ãµes/segundo = OK
> 
> HGETALL grande (100ms):
> â†’ 10 operaÃ§Ãµes/segundo = PROBLEMA!
> â†’ 990 usuÃ¡rios ficam esperando
> ```
> 
> **ğŸ”§ SOLUÃ‡Ã•ES:**
> - **PaginaÃ§Ã£o:** `LRANGE 0 99` em vez de `LRANGE 0 -1`
> - **Campos especÃ­ficos:** `HGET` em vez de `HGETALL`
> - **Estruturas menores:** Quebrar big keys em vÃ¡rias pequenas
> - **Cache local:** Evitar buscar big keys repetidamente

**Sinais de Big Keys ProblemÃ¡ticos:**
- âœ… Chaves > 100KB (strings) ou > 1000 elementos (estruturas)
- âœ… OperaÃ§Ãµes que demoram > 10ms
- âœ… Uso desproporcional de memÃ³ria
- âœ… Bloqueio de outras operaÃ§Ãµes

**âœ… Checkpoint:** Identificar quais sÃ£o as maiores chaves e seu impacto.

---

### ExercÃ­cio 3: Detectar Hot Keys (15 minutos)

**Objetivo:** Identificar chaves acessadas com alta frequÃªncia

> **ğŸ”¥ O QUE SÃƒO HOT KEYS E POR QUE SÃƒO PROBLEMÃTICAS:**
> 
> **Analogia:** Imagine uma loja com 1000 produtos, mas 80% dos clientes querem apenas 3 produtos especÃ­ficos. Esses 3 produtos sÃ£o "hot items":
> - **Criam filas longas** (gargalo de acesso)
> - **Esgotam rapidamente** (sobrecarga do servidor)
> - **FuncionÃ¡rios ficam ocupados** (recursos concentrados)
> - **Outros produtos sÃ£o ignorados** (distribuiÃ§Ã£o desigual)
> 
> **No Redis, Hot Keys sÃ£o:**
> - **Chaves acessadas muito frequentemente** (ex: 80% dos GETs)
> - **Concentram carga em poucos pontos** (hotspots)
> - **Causam gargalos de performance** (single-threaded)
> - **Podem sobrecarregar rÃ©plicas** (se usadas para leitura)
> 
> **Exemplos tÃ­picos de Hot Keys:**
> - **ConfiguraÃ§Ãµes globais:** `app:config`, `feature:flags`
> - **Dados de usuÃ¡rio popular:** `user:admin`, `user:celebrity`
> - **Contadores globais:** `stats:total_users`, `counter:page_views`
> - **Cache de consultas populares:** `search:trending`, `products:featured`
> 
> **Por que sÃ£o problemÃ¡ticas:**
> - âœ… **Gargalo de CPU:** Poucas chaves consomem muito processamento
> - âœ… **LatÃªncia alta:** Fila de espera para acessar hot keys
> - âœ… **DistribuiÃ§Ã£o desigual:** Em clusters, alguns nÃ³s ficam sobrecarregados
> - âœ… **Falha em cascata:** Se hot key falha, muitas operaÃ§Ãµes falham

#### Passo 1: Configurar Monitoramento de Hot Keys

```bash
# Verificar configuraÃ§Ãµes disponÃ­veis (ElastiCache pode restringir CONFIG)
echo "ğŸ” Verificando configuraÃ§Ã£o de hot key tracking..."

# No ElastiCache, hot key tracking geralmente nÃ£o estÃ¡ disponÃ­vel via CONFIG
# Vamos usar abordagens alternativas para detectar hot keys

echo "âš ï¸  NOTA: ElastiCache pode restringir comandos CONFIG por seguranÃ§a"
echo "Vamos usar mÃ©todos alternativos para detectar hot keys:"

# Verificar se conseguimos acessar informaÃ§Ãµes bÃ¡sicas
$REDIS_CMD INFO server | head -5

# Alternativa: usar MONITOR para detectar hot keys (mÃ©todo manual)
echo "ğŸ’¡ Para detectar hot keys no ElastiCache, usaremos:"
echo "1. Comando MONITOR (observaÃ§Ã£o manual)"
echo "2. AnÃ¡lise de padrÃµes de acesso"
echo "3. SimulaÃ§Ã£o controlada"
```

#### Passo 2: Simular Acesso a Hot Keys

```bash
# Simular padrÃ£o de hot keys
echo "ğŸ§ª Simulando padrÃ£o de acesso a hot keys..."

# FunÃ§Ã£o para simular carga concentrada
simulate_hot_keys() {
    local endpoint=$1
    local student_id=$2
    local duration=60  # 1 minuto de simulaÃ§Ã£o
    local end_time=$(($(date +%s) + duration))
    
    echo "Simulando hot keys por $duration segundos..."
    
    while [ $(date +%s) -lt $end_time ]; do
        # 80% dos acessos vÃ£o para apenas 3 chaves (hot keys)
        for i in {1..8}; do
            redis-cli -h $endpoint -p 6379 --tls get hot_candidate:$student_id:1 > /dev/null &
            redis-cli -h $endpoint -p 6379 --tls get hot_candidate:$student_id:2 > /dev/null &
            redis-cli -h $endpoint -p 6379 --tls get hot_candidate:$student_id:3 > /dev/null &
        done
        
        # 20% dos acessos distribuÃ­dos entre outras chaves
        for i in {1..2}; do
            RANDOM_KEY=$((RANDOM % 100 + 4))
            redis-cli -h $endpoint -p 6379 --tls get hot_candidate:$student_id:$RANDOM_KEY > /dev/null &
        done
        
        sleep 0.1
        wait  # Aguardar todos os processos background
    done
}

# Executar simulaÃ§Ã£o em background
simulate_hot_keys $DATA_ENDPOINT $ID &
SIMULATION_PID=$!

echo "ğŸ” SimulaÃ§Ã£o iniciada (PID: $SIMULATION_PID)"
echo "Aguarde 60 segundos para coleta de dados..."
```

#### Passo 3: Monitorar Hot Keys em Tempo Real

```bash
# Usar MONITOR para observar comandos (cuidado: muito verboso)
echo "ğŸ” Iniciando monitoramento de comandos por 30 segundos..."
timeout 30 redis-cli -h $DATA_ENDPOINT -p 6379 --tls monitor | grep "hot_candidate:$ID" > /tmp/monitor_output_$ID.txt &

# Aguardar coleta de dados
sleep 35

# Parar simulaÃ§Ã£o
kill $SIMULATION_PID 2>/dev/null || true
wait $SIMULATION_PID 2>/dev/null || true

echo "âœ… SimulaÃ§Ã£o concluÃ­da"
```

#### Passo 4: Analisar PadrÃµes de Acesso

```bash
# Analisar dados coletados
echo "ğŸ“Š Analisando padrÃµes de acesso..."

if [ -f /tmp/monitor_output_$ID.txt ]; then
    echo "=== Top 10 Chaves Mais Acessadas ==="
    grep -o "hot_candidate:$ID:[0-9]*" /tmp/monitor_output_$ID.txt | sort | uniq -c | sort -nr | head -10
    
    echo ""
    echo "=== EstatÃ­sticas de Acesso ==="
    TOTAL_ACCESSES=$(wc -l < /tmp/monitor_output_$ID.txt)
    TOP_3_ACCESSES=$(grep -o "hot_candidate:$ID:[1-3]" /tmp/monitor_output_$ID.txt | wc -l)
    HOT_PERCENTAGE=$(( TOP_3_ACCESSES * 100 / TOTAL_ACCESSES ))
    
    echo "Total de acessos: $TOTAL_ACCESSES"
    echo "Acessos Ã s top 3 chaves: $TOP_3_ACCESSES"
    echo "Percentual de hot keys: ${HOT_PERCENTAGE}%"
else
    echo "âš ï¸  Arquivo de monitoramento nÃ£o encontrado"
fi
```

#### Passo 5: Usar Ferramentas de AnÃ¡lise de LatÃªncia

```bash
# Verificar latÃªncia de comandos
echo "ğŸ“ˆ Analisando latÃªncia de comandos..."

# Verificar slow log
echo "=== Slow Log ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls slowlog get 10

# Verificar estatÃ­sticas de comandos
echo "=== Command Stats ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls info commandstats | head -10

# Testar latÃªncia especÃ­fica das hot keys
echo "=== LatÃªncia das Hot Keys ==="
for key in 1 2 3; do
    echo "Testando hot_candidate:$ID:$key"
    redis-cli -h $DATA_ENDPOINT -p 6379 --tls --latency-history -i 1 get hot_candidate:$ID:$key | head -5 &
    sleep 2
    kill $! 2>/dev/null || true
done
```

**Sinais de Hot Keys ProblemÃ¡ticos:**
- âœ… Poucas chaves recebem > 80% dos acessos
- âœ… LatÃªncia aumenta durante picos de acesso
- âœ… CPU alta sem distribuiÃ§Ã£o uniforme de carga
- âœ… Gargalo em single-threaded operations

**âœ… Checkpoint:** Identificar padrÃµes de hot keys e seu impacto na performance.

---

### ExercÃ­cio 4: Analisar PadrÃµes de TTL e ExpiraÃ§Ã£o (15 minutos)

**Objetivo:** Identificar problemas relacionados a TTL e gerenciamento de expiraÃ§Ã£o

> **â° O QUE Ã‰ TTL E POR QUE Ã‰ CRUCIAL:**
> 
> **Analogia:** TTL (Time To Live) Ã© como a **data de validade** nos alimentos:
> - **Leite sem data de validade** â†’ Pode estragar e contaminar outros alimentos
> - **Dados sem TTL** â†’ Podem ficar obsoletos e consumir memÃ³ria desnecessariamente
> - **Data de validade muito curta** â†’ DesperdÃ­cio (joga fora comida boa)
> - **TTL muito baixo** â†’ Overhead (Redis fica deletando dados Ãºteis)
> 
> **No Redis, TTL gerencia o "ciclo de vida" dos dados:**
> - **TTL = -1:** Dados "imortais" (nunca expiram) - **PERIGOSO!**
> - **TTL = 0:** Dados jÃ¡ expirados (serÃ£o deletados)
> - **TTL > 0:** Segundos restantes atÃ© expirar
> 
> **Por que TTL Ã© fundamental:**
> - âœ… **Controla crescimento de memÃ³ria:** Evita acÃºmulo infinito
> - âœ… **MantÃ©m dados frescos:** Remove informaÃ§Ãµes obsoletas
> - âœ… **Otimiza performance:** Menos dados = operaÃ§Ãµes mais rÃ¡pidas
> - âœ… **Previne vazamentos:** Dados temporÃ¡rios nÃ£o ficam "esquecidos"
> 
> **Problemas comuns de TTL:**
> - **Sem TTL:** Dados crescem infinitamente (vazamento de memÃ³ria)
> - **TTL muito alto:** Dados obsoletos ocupam espaÃ§o
> - **TTL muito baixo:** Overhead de expiraÃ§Ã£o constante
> - **TTL inconsistente:** Alguns dados expiram, outros nÃ£o (inconsistÃªncia)

#### Passo 1: Analisar TTL das Chaves Existentes

> **ğŸ” O QUE VAMOS INVESTIGAR:**
> 
> **Analogia:** Somos "inspetores de validade" verificando se os produtos na prateleira tÃªm data de validade adequada.
> 
> **O comando TTL retorna:**
> - **NÃºmero positivo:** Segundos restantes (ex: 3600 = 1 hora)
> - **-1:** Sem TTL (nunca expira) - **ALERTA!**
> - **-2:** Chave nÃ£o existe (jÃ¡ expirou ou nunca existiu)
> 
> **EstratÃ©gia de anÃ¡lise:**
> 1. **Verificar chaves de teste** (criadas com TTL diferentes)
> 2. **Verificar big keys** (podem estar sem TTL)
> 3. **Identificar padrÃµes** (quais tipos tÃªm/nÃ£o tÃªm TTL)

```bash
# Verificar TTL de diferentes tipos de chaves
echo "ğŸ” Analisando TTL das chaves..."

echo "=== TTL das Chaves de Teste ==="
$REDIS_CMD ttl ttl_short:$ID:1
$REDIS_CMD ttl ttl_medium:$ID:1
$REDIS_CMD ttl ttl_long:$ID:1
$REDIS_CMD ttl no_ttl:$ID:1

echo ""
echo "=== TTL das Big Keys ==="
$REDIS_CMD ttl big_string:$ID:1mb
$REDIS_CMD ttl big_list:$ID
$REDIS_CMD ttl big_hash:$ID
```

> **ğŸ“Š INTERPRETANDO OS RESULTADOS:**
> 
> **Exemplo de saÃ­da esperada:**
> ```
> TTL ttl_short:$ID:1    â†’ 45      (45 segundos restantes)
> TTL ttl_medium:$ID:1   â†’ 280     (280 segundos = ~5 minutos)
> TTL ttl_long:$ID:1     â†’ 3540    (3540 segundos = ~1 hora)
> TTL no_ttl:$ID:1       â†’ -1      (SEM TTL - PROBLEMA!)
> TTL big_string:$ID:1mb â†’ -1      (Big key sem TTL - GRAVE!)
> ```
> 
> **ğŸš¨ SINAIS DE ALERTA:**
> - **TTL = -1 em big keys:** MemÃ³ria pode crescer infinitamente
> - **TTL = -1 em dados temporÃ¡rios:** Vazamento de memÃ³ria
> - **TTL muito baixo (< 60s):** Overhead de expiraÃ§Ã£o
> - **TTL inconsistente:** Alguns dados expiram, outros nÃ£o
> 
> **ğŸ’¡ ANÃLISE PRÃTICA:**
> ```
> CenÃ¡rio: E-commerce
> 
> âœ… BOM:
> - Carrinho de compras: TTL 1800s (30 min)
> - Cache de produtos: TTL 3600s (1 hora)
> - SessÃ£o de usuÃ¡rio: TTL 7200s (2 horas)
> 
> âŒ PROBLEMÃTICO:
> - Dados de auditoria: TTL -1 (cresce infinitamente)
> - Cache temporÃ¡rio: TTL -1 (nunca limpa)
> - Logs de debug: TTL -1 (acumula lixo)
> ```

#### Passo 2: Identificar Chaves sem TTL

> **ğŸ•µï¸ CAÃ‡A AOS "IMORTAIS":**
> 
> **Analogia:** Vamos procurar produtos na loja que **nÃ£o tÃªm data de validade** - estes sÃ£o os mais perigosos porque podem "estragar" sem aviso.
> 
> **Por que chaves sem TTL sÃ£o problemÃ¡ticas:**
> - **Crescimento infinito:** Nunca sÃ£o removidas automaticamente
> - **MemÃ³ria desperdiÃ§ada:** Dados obsoletos ocupam espaÃ§o
> - **Performance degradada:** Mais dados = operaÃ§Ãµes mais lentas
> - **InconsistÃªncia:** Dados antigos podem estar incorretos
> 
> **EstratÃ©gia de busca:**
> 1. **SCAN em vez de KEYS:** Mais seguro em produÃ§Ã£o
> 2. **Verificar por padrÃµes:** big_*, session:*, cache:*
> 3. **Calcular tamanho:** Priorizar big keys sem TTL
> 
> **âš ï¸ IMPORTANTE:** Comando KEYS Ã© perigoso em produÃ§Ã£o (bloqueia Redis), sempre use SCAN!

```bash
# Encontrar chaves sem TTL (TTL = -1)
echo "ğŸ” Identificando chaves sem TTL..."

# FunÃ§Ã£o para verificar TTL de mÃºltiplas chaves
check_ttl_patterns() {
    local pattern=$1
    echo "Verificando padrÃ£o: $pattern"
    
    # Usar SCAN para evitar KEYS (mais seguro)
    $REDIS_CMD --scan --pattern "$pattern" | while read key; do
        TTL=$($REDIS_CMD ttl "$key")
        if [ "$TTL" = "-1" ]; then
            SIZE=$($REDIS_CMD memory usage "$key" 2>/dev/null || echo "N/A")
            echo "  $key: sem TTL, tamanho: $SIZE bytes"
        fi
    done
}

# Verificar diferentes padrÃµes
check_ttl_patterns "big_*:$ID*"
check_ttl_patterns "session:$ID:*"
check_ttl_patterns "small:$ID:*"
```

> **ğŸ“Š INTERPRETANDO OS RESULTADOS:**
> 
> **Exemplo de saÃ­da esperada:**
> ```
> Verificando padrÃ£o: big_*:aluno01*
>   big_string:aluno01:1mb: sem TTL, tamanho: 1048576 bytes  â† CRÃTICO!
>   big_list:aluno01: sem TTL, tamanho: 245760 bytes         â† PROBLEMA!
> 
> Verificando padrÃ£o: session:aluno01:*
>   session:aluno01:15: sem TTL, tamanho: 128 bytes          â† Menor prioridade
>   session:aluno01:23: sem TTL, tamanho: 128 bytes
> ```
> 
> **ğŸš¨ PRIORIZAÃ‡ÃƒO DE PROBLEMAS:**
> 
> **CRÃTICO (AÃ§Ã£o imediata):**
> - **Big keys sem TTL:** > 100KB sem expiraÃ§Ã£o
> - **Dados temporÃ¡rios sem TTL:** Cache, sessÃµes, logs
> 
> **ALTO (AÃ§Ã£o em breve):**
> - **MÃºltiplas chaves pequenas sem TTL:** AcÃºmulo gradual
> - **Dados de negÃ³cio sem TTL:** Podem ficar obsoletos
> 
> **MÃ‰DIO (Monitorar):**
> - **ConfiguraÃ§Ãµes sem TTL:** Podem ser intencionais
> - **Dados de referÃªncia sem TTL:** Raramente mudam
> 
> **ğŸ’¡ ESTRATÃ‰GIAS DE CORREÃ‡ÃƒO:**
> ```bash
> # Para big keys sem TTL (URGENTE):
> EXPIRE big_string:aluno01:1mb 3600    # 1 hora
> 
> # Para sessÃµes sem TTL:
> EXPIRE session:aluno01:15 1800        # 30 minutos
> 
> # Para dados temporÃ¡rios:
> EXPIRE cache:temp:data 300            # 5 minutos
> ```

#### Passo 3: Simular Problema de ExpiraÃ§Ã£o

> **ğŸ§ª LABORATÃ“RIO DE EXPIRAÃ‡ÃƒO:**
> 
> **Analogia:** Vamos simular uma situaÃ§Ã£o onde colocamos **1000 produtos com validade de 30 segundos** na prateleira e observamos o que acontece quando todos comeÃ§am a "vencer" ao mesmo tempo.
> 
> **O que vamos observar:**
> - **Overhead de expiraÃ§Ã£o:** Redis precisa processar muitas expiraÃ§Ãµes
> - **Impacto na performance:** CPU ocupada removendo chaves expiradas
> - **PadrÃµes de expiraÃ§Ã£o:** Como Redis gerencia expiraÃ§Ãµes em lote
> 
> **Por que TTL muito baixo Ã© problemÃ¡tico:**
> - **CPU overhead:** Redis gasta tempo removendo chaves constantemente
> - **FragmentaÃ§Ã£o:** MemÃ³ria fica fragmentada com criaÃ§Ã£o/remoÃ§Ã£o frequente
> - **InconsistÃªncia:** Dados podem expirar no meio de operaÃ§Ãµes
> 
> **ConfiguraÃ§Ã£o do Redis para expiraÃ§Ã£o:**
> - **hz:** FrequÃªncia de verificaÃ§Ã£o de expiraÃ§Ãµes (padrÃ£o: 10 Hz)
> - **ExpiraÃ§Ã£o ativa:** Redis remove chaves expiradas proativamente
> - **ExpiraÃ§Ã£o passiva:** Remove quando chave Ã© acessada

```bash
# Criar chaves com TTL muito baixo para demonstrar problema
echo "ğŸ§ª Simulando problema de expiraÃ§Ã£o..."

# Criar muitas chaves com TTL baixo
echo "Criando chaves com TTL baixo..."
for i in {1..1000}; do
    $REDIS_CMD SET "expire_test:$ID:$i" "value$i" EX 30 > /dev/null
done

echo "âœ… Criadas 1000 chaves com TTL de 30 segundos"

# Monitorar estatÃ­sticas de expiraÃ§Ã£o
echo "ğŸ“Š Monitorando estatÃ­sticas de expiraÃ§Ã£o..."
for i in {1..6}; do
    echo "=== VerificaÃ§Ã£o $i ($(date '+%H:%M:%S')) ==="
    
    # EstatÃ­sticas de expiraÃ§Ã£o
    $REDIS_CMD info stats | grep -E "(expired_keys|evicted_keys)"
    
    # Contar chaves restantes
    REMAINING=$($REDIS_CMD eval "return #redis.call('keys', 'expire_test:$ID:*')" 0)
    echo "Chaves restantes: $REMAINING"
    
    sleep 10
done
```

> **ğŸ“Š INTERPRETANDO O MONITORAMENTO:**
> 
> **EstatÃ­sticas importantes:**
> - **expired_keys:** Total de chaves que expiraram desde o inÃ­cio
> - **evicted_keys:** Chaves removidas por polÃ­tica de memÃ³ria (diferente de expiraÃ§Ã£o)
> 
> **Exemplo de progressÃ£o esperada:**
> ```
> VerificaÃ§Ã£o 1 (14:30:00):
> expired_keys:0
> Chaves restantes: 1000
> 
> VerificaÃ§Ã£o 4 (14:30:30):  â† TTL de 30s expirando
> expired_keys:856
> Chaves restantes: 144
> 
> VerificaÃ§Ã£o 6 (14:30:50):
> expired_keys:1000
> Chaves restantes: 0
> ```
> 
> **ğŸ” ANÃLISE DO COMPORTAMENTO:**
> 
> **ExpiraÃ§Ã£o nÃ£o Ã© instantÃ¢nea:**
> - Redis nÃ£o remove chaves exatamente no segundo da expiraÃ§Ã£o
> - Usa algoritmo probabilÃ­stico para eficiÃªncia
> - Algumas chaves podem "sobreviver" alguns segundos extras
> 
> **PadrÃµes de expiraÃ§Ã£o:**
> - **ExpiraÃ§Ã£o em lotes:** Redis remove vÃ¡rias chaves por vez
> - **DistribuiÃ§Ã£o temporal:** NÃ£o todas expiram simultaneamente
> - **Overhead variÃ¡vel:** Depende da quantidade de chaves expirando
> 
> **ğŸš¨ SINAIS DE PROBLEMA COM TTL:**
> - **expired_keys crescendo muito rÃ¡pido:** TTL muito baixo
> - **Chaves nÃ£o expirando:** PossÃ­vel problema de configuraÃ§Ã£o
> - **Performance degradada:** Overhead de expiraÃ§Ã£o alto
> - **MemÃ³ria nÃ£o liberando:** FragmentaÃ§Ã£o ou vazamentos

#### Passo 4: Analisar Impacto de ExpiraÃ§Ã£o na Performance

```bash
# Verificar configuraÃ§Ã£o de expiraÃ§Ã£o
echo "ğŸ” Analisando configuraÃ§Ã£o de expiraÃ§Ã£o..."
redis-cli -h $DATA_ENDPOINT -p 6379 --tls INFO stats | grep expired_keys

# Verificar estatÃ­sticas detalhadas
echo "ğŸ“ˆ EstatÃ­sticas de expiraÃ§Ã£o e eviction:"
redis-cli -h $DATA_ENDPOINT -p 6379 --tls info stats | grep -E "(expired_keys|evicted_keys|keyspace_hits|keyspace_misses)"

# Calcular hit rate
HITS=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls info stats | grep keyspace_hits | cut -d: -f2 | tr -d '\r')
MISSES=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls info stats | grep keyspace_misses | cut -d: -f2 | tr -d '\r')
TOTAL=$((HITS + MISSES))
if [ $TOTAL -gt 0 ]; then
    HIT_RATE=$(( HITS * 100 / TOTAL ))
    echo "Hit Rate: ${HIT_RATE}% ($HITS hits, $MISSES misses)"
else
    echo "Hit Rate: N/A (sem estatÃ­sticas suficientes)"
fi
```

**Problemas Comuns de TTL:**
- âœ… Big keys sem TTL (consomem memÃ³ria indefinidamente)
- âœ… TTL muito baixo (overhead de expiraÃ§Ã£o)
- âœ… TTL inconsistente (alguns dados expiram, outros nÃ£o)
- âœ… Falta de estratÃ©gia de eviction

**âœ… Checkpoint:** Identificar problemas de TTL e estratÃ©gias de expiraÃ§Ã£o.

---

## ğŸ” AnÃ¡lise AvanÃ§ada de PadrÃµes de Dados

### IdentificaÃ§Ã£o de PadrÃµes ProblemÃ¡ticos

#### 1. Big Keys ProblemÃ¡ticos
```bash
# Identificar big keys por tipo
echo "ğŸ“Š AnÃ¡lise de Big Keys por Tipo:"

# Strings grandes
redis-cli -h $DATA_ENDPOINT -p 6379 --tls --scan --pattern "*" | while read key; do
    TYPE=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls type "$key")
    if [ "$TYPE" = "string" ]; then
        SIZE=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls memory usage "$key" 2>/dev/null)
        if [ "$SIZE" -gt 10240 ]; then  # > 10KB
            echo "Big String: $key ($SIZE bytes)"
        fi
    fi
done | head -10
```

#### 2. Estruturas Ineficientes
```bash
# Analisar eficiÃªncia de estruturas
echo "ğŸ“Š AnÃ¡lise de EficiÃªncia de Estruturas:"

# Hash vs mÃºltiplas strings
echo "=== ComparaÃ§Ã£o Hash vs Strings ==="
# Criar dados equivalentes
# Usando Hash (eficiente)
$REDIS_CMD HSET "user_hash:$ID:1" name "JoÃ£o" email "joao@test.com" age "30"

# Usando mÃºltiplas strings (ineficiente)
$REDIS_CMD SET "user_string:$ID:1:name" "JoÃ£o"
$REDIS_CMD SET "user_string:$ID:1:email" "joao@test.com"
$REDIS_CMD SET "user_string:$ID:1:age" "30"

# Comparar uso de memÃ³ria
HASH_SIZE=$($REDIS_CMD memory usage "user_hash:$ID:1")
STRING1_SIZE=$($REDIS_CMD memory usage "user_string:$ID:1:name")
STRING2_SIZE=$($REDIS_CMD memory usage "user_string:$ID:1:email")
STRING3_SIZE=$($REDIS_CMD memory usage "user_string:$ID:1:age")
STRINGS_TOTAL=$((STRING1_SIZE + STRING2_SIZE + STRING3_SIZE))

echo "Hash: $HASH_SIZE bytes"
echo "Strings: $STRINGS_TOTAL bytes"
echo "Economia com Hash: $((STRINGS_TOTAL - HASH_SIZE)) bytes ($(( (STRINGS_TOTAL - HASH_SIZE) * 100 / STRINGS_TOTAL ))%)"
```

#### 3. AnÃ¡lise de FragmentaÃ§Ã£o

```bash
# Verificar fragmentaÃ§Ã£o de memÃ³ria
echo "ğŸ“Š AnÃ¡lise de FragmentaÃ§Ã£o:"
redis-cli -h $DATA_ENDPOINT -p 6379 --tls info memory | grep -E "(mem_fragmentation|mem_allocator)"

# Verificar estatÃ­sticas de alocaÃ§Ã£o
redis-cli -h $DATA_ENDPOINT -p 6379 --tls memory stats
```

## ğŸ› ï¸ EstratÃ©gias de OtimizaÃ§Ã£o

### 1. OtimizaÃ§Ã£o de Big Keys

```bash
# Demonstrar estratÃ©gias para big keys
echo "ğŸ”§ EstratÃ©gias de OtimizaÃ§Ã£o para Big Keys:"

# EstratÃ©gia 1: PaginaÃ§Ã£o de listas grandes
echo "=== PaginaÃ§Ã£o de Lista Grande ==="
# Em vez de LRANGE 0 -1 (custoso), usar paginaÃ§Ã£o
redis-cli -h $DATA_ENDPOINT -p 6379 --tls lrange big_list:$ID 0 99  # Primeira pÃ¡gina
redis-cli -h $DATA_ENDPOINT -p 6379 --tls lrange big_list:$ID 100 199  # Segunda pÃ¡gina

# EstratÃ©gia 2: Usar HSCAN em vez de HGETALL
echo "=== Scan de Hash Grande ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls hscan big_hash:$ID 0 COUNT 100
```

### 2. OtimizaÃ§Ã£o de Hot Keys

```bash
# EstratÃ©gias para hot keys
echo "ğŸ”§ EstratÃ©gias de OtimizaÃ§Ã£o para Hot Keys:"

# EstratÃ©gia 1: ReplicaÃ§Ã£o de hot keys (simulaÃ§Ã£o)
HOT_VALUE=$($REDIS_CMD GET "hot_candidate:$ID:1")
$REDIS_CMD SET "hot_replica:$ID:1:shard1" "$HOT_VALUE"
$REDIS_CMD SET "hot_replica:$ID:1:shard2" "$HOT_VALUE"
$REDIS_CMD SET "hot_replica:$ID:1:shard3" "$HOT_VALUE"

echo "âœ… Hot key replicada em 3 shards para distribuir carga"
```

### 3. ConfiguraÃ§Ã£o de TTL Inteligente

```bash
# Configurar TTL baseado no tipo de dados
echo "ğŸ”§ ConfiguraÃ§Ã£o de TTL Inteligente:"

# TTL baseado no tipo de dados
$REDIS_CMD SET "cache:$ID:user:1" "user data" EX 3600        # Cache de usuÃ¡rio: 1h
$REDIS_CMD SET "session:$ID:abc123" "session data" EX 1800   # SessÃ£o: 30min
$REDIS_CMD SET "temp:$ID:calc" "temp result" EX 300          # Resultado temporÃ¡rio: 5min

echo "âœ… TTL configurado baseado no tipo de dados"
```

## ğŸ’° AtenÃ§Ã£o aos Custos

âš ï¸ **IMPORTANTE:** Este laboratÃ³rio cria recursos AWS que geram custos na regiÃ£o us-east-2:

- Cache cluster: ~$0.017/hora (cache.t3.micro)
- Data transfer: MÃ­nimo para este lab
- CloudWatch mÃ©tricas: IncluÃ­das no Free Tier

**Custo estimado por aluno:** ~$0.05 para completar o laboratÃ³rio

## ğŸ§¹ Limpeza de Recursos

**CRÃTICO:** Ao final do laboratÃ³rio, delete seus recursos para evitar custos:

### Via Console Web:
1. **ElastiCache** > **"Caches do Redis OSS"**
   - Selecione `lab-data-$ID`
   - **Actions** > **Delete**
   - Confirme a deleÃ§Ã£o

### Via CLI:
```bash
# Deletar replication group
aws elasticache delete-replication-group --replication-group-id lab-data-$ID --region us-east-2

# Monitorar deleÃ§Ã£o
watch -n 30 "aws elasticache describe-replication-groups --replication-group-id lab-data-$ID --region us-east-2 2>/dev/null || echo 'Replication Group deletado com sucesso'"

# Limpar arquivos temporÃ¡rios
rm -f /tmp/bigkeys_analysis_$ID.txt
rm -f /tmp/monitor_output_$ID.txt
```

**NOTA:** Mantenha o Security Group para uso no prÃ³ximo laboratÃ³rio.

## ğŸ“– Recursos Adicionais

- [Redis Memory Optimization](https://redis.io/topics/memory-optimization)
- [Redis Data Types](https://redis.io/topics/data-types)
- [Redis Best Practices](https://redis.io/topics/memory-optimization)
- [ElastiCache Best Practices](https://docs.aws.amazon.com/elasticache/latest/red-ug/BestPractices.html)

## ğŸ†˜ Troubleshooting

### Problemas Comuns

1. **Erro de conexÃ£o com redis-cli**
   - **Criptografia em trÃ¢nsito habilitada:** Use `redis-cli` com `--tls`
   - **Exemplo:** `redis-cli -h $DATA_ENDPOINT -p 6379 --tls ping`
   - **DocumentaÃ§Ã£o:** [ElastiCache Encryption](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html)

2. **Big keys causando latÃªncia**
   - Use paginaÃ§Ã£o em vez de operaÃ§Ãµes completas
   - Considere quebrar big keys em estruturas menores
   - Implemente TTL apropriado

3. **Hot keys sobrecarregando cluster**
   - Replique hot keys em mÃºltiplas chaves
   - Use cache local na aplicaÃ§Ã£o
   - Considere cluster mode enabled

4. **MemÃ³ria crescendo indefinidamente**
   - Implemente TTL em todas as chaves
   - Configure polÃ­tica de eviction
   - Monitore padrÃµes de crescimento

5. **Performance degradada**
   - Evite comandos KEYS em produÃ§Ã£o
   - Use SCAN em vez de operaÃ§Ãµes completas
   - Otimize estruturas de dados

6. **Hit rate baixo**
   - Revise estratÃ©gia de TTL
   - Analise padrÃµes de acesso
   - Ajuste tamanho do cache

## ğŸ¯ Objetivos de Aprendizado AlcanÃ§ados

Ao final deste laboratÃ³rio, vocÃª deve conseguir:

- âœ… Identificar big keys usando ferramentas Redis
- âœ… Detectar hot keys atravÃ©s de monitoramento
- âœ… Analisar padrÃµes de TTL e expiraÃ§Ã£o
- âœ… Correlacionar problemas de dados com performance
- âœ… Implementar estratÃ©gias de otimizaÃ§Ã£o de dados
- âœ… Configurar estruturas de dados eficientes
- âœ… Monitorar e alertar sobre problemas de dados

## ğŸ“ **RESUMO EDUCACIONAL - O QUE APRENDEMOS**

### **ğŸ” Big Keys - "Os Elefantes na Sala"**

**Conceito:** Chaves que ocupam muito espaÃ§o ou tÃªm muitos elementos.

**Por que sÃ£o problemÃ¡ticas:**
- **Redis Ã© single-threaded:** Uma operaÃ§Ã£o grande bloqueia todas as outras
- **MemÃ³ria limitada:** Poucas big keys podem consumir toda a RAM
- **ReplicaÃ§Ã£o lenta:** Demora para sincronizar entre nÃ³s

**Como identificar:**
1. **`--bigkeys`:** Scanner automÃ¡tico (como raio-X)
2. **`MEMORY USAGE`:** AnÃ¡lise especÃ­fica (como microscÃ³pio)
3. **Monitoramento de latÃªncia:** OperaÃ§Ãµes lentas indicam big keys

**SoluÃ§Ãµes prÃ¡ticas:**
- **PaginaÃ§Ã£o:** `LRANGE 0 99` em vez de `LRANGE 0 -1`
- **Campos especÃ­ficos:** `HGET campo` em vez de `HGETALL`
- **Quebrar em pedaÃ§os:** 1 big key â†’ vÃ¡rias small keys
- **TTL adequado:** Evitar crescimento descontrolado

### **ğŸ”¥ Hot Keys - "As Celebridades do Redis"**

**Conceito:** Chaves acessadas com alta frequÃªncia (poucos dados, muito acesso).

**Por que sÃ£o problemÃ¡ticas:**
- **Gargalo de CPU:** 80% dos acessos em 20% das chaves
- **DistribuiÃ§Ã£o desigual:** Em clusters, alguns nÃ³s ficam sobrecarregados
- **Falha em cascata:** Se hot key falha, muitas operaÃ§Ãµes falham

**Como identificar:**
1. **`MONITOR`:** ObservaÃ§Ã£o em tempo real (como cÃ¢mera de seguranÃ§a)
2. **AnÃ¡lise de padrÃµes:** EstatÃ­sticas de acesso
3. **MÃ©tricas de CPU:** Picos correlacionados com chaves especÃ­ficas

**SoluÃ§Ãµes prÃ¡ticas:**
- **ReplicaÃ§Ã£o:** MÃºltiplas cÃ³pias da hot key
- **Cache local:** Evitar acessar Redis repetidamente
- **Sharding:** Distribuir carga entre mÃºltiplas chaves
- **Rate limiting:** Controlar frequÃªncia de acesso

### **â° TTL - "O Lixeiro AutomÃ¡tico"**

**Conceito:** Time To Live - tempo de vida das chaves.

**Por que Ã© importante:**
- **MemÃ³ria limitada:** Dados antigos ocupam espaÃ§o desnecessÃ¡rio
- **Performance:** Menos dados = operaÃ§Ãµes mais rÃ¡pidas
- **ConsistÃªncia:** Dados expirados podem estar incorretos

**Como gerenciar:**
1. **Identificar chaves sem TTL:** `TTL chave` retorna -1
2. **Definir TTL apropriado:** Baseado no tipo de dados
3. **Monitorar expiraÃ§Ã£o:** EstatÃ­sticas de expired_keys

**EstratÃ©gias por tipo de dados:**
- **Cache de consultas:** 5-30 minutos
- **SessÃµes de usuÃ¡rio:** 30 minutos - 24 horas
- **Dados temporÃ¡rios:** Segundos a minutos
- **ConfiguraÃ§Ãµes:** Horas a dias

### **ğŸ“Š Estruturas Eficientes - "A Arte da OrganizaÃ§Ã£o"**

**Conceito:** Escolher a estrutura de dados certa para cada situaÃ§Ã£o.

**ComparaÃ§Ã£o prÃ¡tica:**
```
Dados de usuÃ¡rio:
âŒ Ineficiente: 3 strings separadas (user:1:name, user:1:email, user:1:age)
âœ… Eficiente: 1 hash (user:1 com campos name, email, age)

Resultado: 60% menos memÃ³ria, operaÃ§Ãµes mais rÃ¡pidas
```

**Regras prÃ¡ticas:**
- **Dados relacionados:** Use hashes em vez de mÃºltiplas strings
- **Listas grandes:** Considere paginaÃ§Ã£o ou mÃºltiplas listas menores
- **Contadores:** Use strings simples com INCR/DECR
- **Relacionamentos:** Use sets para membros Ãºnicos

### **ğŸ› ï¸ Metodologia de Troubleshooting**

**1. DiagnÃ³stico (O que estÃ¡ acontecendo?)**
- Analisar uso de memÃ³ria geral
- Identificar big keys com --bigkeys
- Monitorar padrÃµes de acesso

**2. AnÃ¡lise (Por que estÃ¡ acontecendo?)**
- Medir impacto na performance
- Correlacionar com mÃ©tricas de sistema
- Identificar padrÃµes problemÃ¡ticos

**3. SoluÃ§Ã£o (Como resolver?)**
- Implementar otimizaÃ§Ãµes especÃ­ficas
- Monitorar resultados
- Documentar liÃ§Ãµes aprendidas

**4. PrevenÃ§Ã£o (Como evitar no futuro?)**
- Estabelecer polÃ­ticas de TTL
- Monitoramento proativo
- Code review focado em estruturas de dados

### **ğŸ¯ Principais Takeaways**

1. **"Measure, don't guess"** - Sempre meÃ§a antes de otimizar
2. **"Small is beautiful"** - Prefira muitas chaves pequenas a poucas grandes
3. **"Everything expires"** - Todo dado deve ter TTL apropriado
4. **"Monitor continuously"** - Problemas de dados crescem com o tempo
5. **"Structure matters"** - A escolha da estrutura impacta performance e memÃ³ria

### **ğŸš¨ Red Flags - Sinais de Alerta**

- **MemÃ³ria crescendo constantemente** â†’ Falta TTL
- **OperaÃ§Ãµes > 10ms** â†’ Big keys problemÃ¡ticas  
- **CPU alta sem carga aparente** â†’ Hot keys
- **Hit rate baixo** â†’ TTL inadequado ou dados irrelevantes
- **Poucas chaves, muita memÃ³ria** â†’ Big keys
- **Muitas chaves, pouca memÃ³ria** â†’ Overhead excessivo

**Lembre-se:** Redis Ã© uma ferramenta poderosa, mas como qualquer ferramenta, precisa ser usada corretamente. O troubleshooting de dados Ã© uma habilidade que se desenvolve com prÃ¡tica e experiÃªncia!

## â¡ï¸ PrÃ³ximo LaboratÃ³rio

Agora que vocÃª domina troubleshooting de dados, vÃ¡ para:

**[Lab 05: RedisInsight](../lab05-redisinsight/README.md)**

---

**ParabÃ©ns! VocÃª completou o Lab 04! ğŸ‰**

*VocÃª agora possui habilidades avanÃ§adas para identificar, analisar e resolver problemas relacionados a dados no ElastiCache.*