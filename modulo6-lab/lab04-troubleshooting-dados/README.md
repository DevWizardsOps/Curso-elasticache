# Lab 04 - Troubleshooting de Dados

Laborat√≥rio focado na an√°lise do data plane do Redis no ElastiCache na regi√£o **us-east-2**, desenvolvendo habilidades para identificar, analisar e resolver problemas relacionados a big keys, hot keys, estruturas inadequadas e padr√µes problem√°ticos que impactam performance.

## üìã Objetivos do Laborat√≥rio

- Identificar big keys que causam bloqueios e lat√™ncia
- Detectar hot keys respons√°veis por hotspots e sobrecarga
- Analisar estruturas de dados inadequadas e ineficientes
- Diagnosticar problemas de TTL e expira√ß√£o de chaves
- Avaliar padr√µes de acesso e distribui√ß√£o de dados
- Correlacionar problemas de dados com m√©tricas de performance
- Implementar estrat√©gias de otimiza√ß√£o de dados

## ‚è±Ô∏è Dura√ß√£o Estimada: 60 minutos

## üåç Regi√£o AWS: us-east-2 (Ohio)

**IMPORTANTE:** Todos os recursos devem ser criados na regi√£o **us-east-2**. Verifique sempre a regi√£o no canto superior direito do Console AWS.

## üèóÔ∏è Estrutura do Laborat√≥rio

```
lab04-troubleshooting-dados/
‚îú‚îÄ‚îÄ README.md                    # Este guia (foco principal)
‚îú‚îÄ‚îÄ scripts/                     # Scripts de refer√™ncia (opcional)
‚îÇ   ‚îú‚îÄ‚îÄ create-data-cluster.sh
‚îÇ   ‚îú‚îÄ‚îÄ generate-big-keys.sh
‚îÇ   ‚îú‚îÄ‚îÄ simulate-hot-keys.sh
‚îÇ   ‚îú‚îÄ‚îÄ analyze-data-patterns.sh
‚îÇ   ‚îî‚îÄ‚îÄ cleanup-lab04.sh
‚îî‚îÄ‚îÄ ferramentas/                 # Ferramentas de an√°lise (opcional)
    ‚îú‚îÄ‚îÄ big-key-analyzer.py
    ‚îú‚îÄ‚îÄ hot-key-detector.sh
    ‚îî‚îÄ‚îÄ data-pattern-report.py
```

**IMPORTANTE:** Este laborat√≥rio foca na an√°lise manual via Redis CLI e ferramentas espec√≠ficas. Os scripts s√£o apenas para refer√™ncia e simula√ß√£o de cen√°rios.

## üöÄ Pr√©-requisitos

- Conta AWS ativa configurada para regi√£o **us-east-2**
- AWS CLI configurado para regi√£o us-east-2
- Acesso √† inst√¢ncia EC2 fornecida pelo instrutor (Bastion Host)
- Redis CLI instalado e funcional
- Conhecimento b√°sico de estruturas de dados Redis
- **ID do Aluno:** Voc√™ deve usar seu ID √∫nico (ex: aluno01, aluno02, etc.)
- **Labs anteriores:** VPC, Subnet Group e Security Group j√° criados

## üè∑Ô∏è Conven√ß√£o de Nomenclatura

Todos os recursos criados devem seguir o padr√£o:
- **Cluster de Dados:** `lab-data-$ID`
- **Security Groups:** Reutilizar `elasticache-lab-sg-$ID` dos labs anteriores

**Exemplo para aluno01:**
- Cluster: `lab-data-aluno01`
- Security Group: `elasticache-lab-sg-aluno01` (j√° existente)

## üìö Exerc√≠cios

### Exerc√≠cio 1: Preparar Ambiente com Dados Diversos (15 minutos)

**Objetivo:** Criar cluster e popular com diferentes tipos e tamanhos de dados

> **üéØ POR QUE ESTE EXERC√çCIO √â IMPORTANTE:**
> 
> Imagine que voc√™ √© um detetive investigando um crime. Antes de procurar pistas, voc√™ precisa conhecer a cena do crime. No Redis, os "crimes" s√£o problemas de performance causados por dados mal estruturados.
> 
> **Neste exerc√≠cio, vamos criar uma "cena do crime" controlada** com diferentes tipos de problemas de dados:
> - **Big Keys** (chaves grandes) - como caixas pesadas que demoram para mover
> - **Hot Keys** (chaves populares) - como uma porta que todo mundo quer usar ao mesmo tempo
> - **Dados sem TTL** - como lixo que nunca √© coletado
> - **Estruturas ineficientes** - como usar 10 gavetas quando 1 bastaria

#### Passo 1: Verificar Pr√©-requisitos

```bash
# Verificar Security Group dos labs anteriores
aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$ID" --region us-east-2
```

#### Passo 2: Criar Cluster de Dados via Console Web

1. Acesse **ElastiCache** no Console AWS
2. Na p√°gina inicial, selecione **"Caches do Redis OSS"** ‚Üê **IMPORTANTE**
3. Selecione **"Cache de cluster"** (n√£o serverless)
4. Selecione **"Cache de cluster"** (configura√ß√£o manual, n√£o cria√ß√£o f√°cil)
5. Configure:
   - **Cluster mode:** Disabled
   - **Cluster info:**
     - **Name:** `lab-data-$ID`
     - **Description:** `Lab data troubleshooting cluster for $ID`
   - **Location:**
     - **AWS Cloud**
     - **Multi-AZ:** Disabled (para este lab)
     - **Failover autom√°tico:** Desabilitado (n√£o aplic√°vel sem r√©plicas)
   - **Cluster settings:**
     - **Engine version:** 7.0
     - **Port:** 6379
     - **Node type:** **cache.t3.micro** (para demonstrar limita√ß√µes)
     - **Number of replicas:** 0
   - **Connectivity:**
     - **Network type:** IPv4
     - **Subnet group:** `elasticache-lab-subnet-group`
     - **Security groups:** Selecione seu SG `elasticache-lab-sg-$ID`
   - **Security (Seguran√ßa):**
     - **Criptografia em repouso:** Habilitada (recomendado)
     - **Chave de criptografia:** Chave padr√£o (AWS managed)
     - **Criptografia em tr√¢nsito:** Habilitada (recomendado)
     - **Controle de acesso:** Nenhum controle de acesso (para simplicidade do lab)
   - **Backup:**
     - **Enable automatic backups:** Enabled
   - **Maintenance:**
     - **Auto minor version upgrade:** Enabled
   - **Advanced settings:**
     - **Tags (Recomendado):**
       - **Key:** `Name` **Value:** `Lab Data - $ID`
       - **Key:** `Lab` **Value:** `Lab04`
       - **Key:** `Purpose` **Value:** `Data-Analysis`

6. Clique em **Create**

> **üìö Para saber mais sobre seguran√ßa:**
> - [Criptografia no ElastiCache](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html)
> - [Configura√ß√µes de seguran√ßa](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth.html)

#### Alternativa: Cria√ß√£o R√°pida via CLI

Para acelerar o processo, voc√™ pode criar o cluster via CLI:

```bash
# Obter IDs necess√°rios
VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=ElastiCache-Lab-VPC" --query 'Vpcs[0].VpcId' --output text --region us-east-2)
SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$ID" --query 'SecurityGroups[0].GroupId' --output text --region us-east-2)

# IMPORTANTE: Para ter criptografia via CLI, devemos usar Replication Group (mesmo com 1 n√≥)
# create-cache-cluster N√ÉO suporta par√¢metros de criptografia
aws elasticache create-replication-group \
    --replication-group-id "lab-data-$ID" \
    --replication-group-description "Data troubleshooting with encryption" \
    --num-cache-clusters 1 \
    --cache-node-type cache.t3.micro \
    --engine redis \
    --engine-version 7.0 \
    --port 6379 \
    --cache-subnet-group-name elasticache-lab-subnet-group \
    --security-group-ids $SG_ID \
    --at-rest-encryption-enabled \
    --transit-encryption-enabled \
    --auto-minor-version-upgrade \
    --tags Key=Name,Value="Lab Data - $ID" Key=Lab,Value=Lab04 Key=Purpose,Value=Data-Analysis \
    --region us-east-2

echo "‚úÖ Replication Group criado via CLI! Aguarde ~10-15 minutos para ficar dispon√≠vel."
```

> **üèóÔ∏è PONTO ARQUITETURAL IMPORTANTE:**
> 
> **Por que usar `create-replication-group` em vez de `create-cache-cluster`?**
> 
> - **`create-cache-cluster`:** Comando legado, N√ÉO suporta criptografia
> - **`create-replication-group`:** Comando moderno, suporta todas as funcionalidades
> 
> **Mesmo para 1 n√≥ √∫nico**, use `create-replication-group` se precisar de:
> - ‚úÖ Criptografia (at-rest e in-transit)
> - ‚úÖ Backups autom√°ticos
> - ‚úÖ Multi-AZ (futuro)
> - ‚úÖ Failover autom√°tico (futuro)
> 
> **Regra pr√°tica:** Sempre use `create-replication-group` em produ√ß√£o!

#### Passo 3: Aguardar Cria√ß√£o e Obter Endpoint

```bash
# Monitorar cria√ß√£o
watch -n 30 "aws elasticache describe-replication-groups --replication-group-id lab-data-$ID --query 'ReplicationGroups[0].Status' --output text --region us-east-2"

# Quando dispon√≠vel, obter endpoint
DATA_ENDPOINT=$(aws elasticache describe-replication-groups --replication-group-id lab-data-$ID --query 'ReplicationGroups[0].NodeGroups[0].PrimaryEndpoint.Address' --output text --region us-east-2)
echo "Data Cluster Endpoint: $DATA_ENDPOINT"
```

#### Passo 4: Popular com Dados Diversos

```bash
# Testar conectividade primeiro
if redis-cli -h $DATA_ENDPOINT -p 6379 --tls ping > /dev/null 2>&1; then
    echo "‚úÖ Conectividade OK (com TLS)"
    REDIS_CMD="redis-cli -h $DATA_ENDPOINT -p 6379 --tls"
else
    echo "‚ùå Erro de conectividade"
    exit 1
fi

# Popular com diferentes tipos de dados
echo "üìä Populando cluster com dados diversos..."

# Limpar dados existentes
$REDIS_CMD FLUSHALL

# === DADOS PEQUENOS (baseline) ===
echo "Inserindo dados pequenos..."
for i in {1..1000}; do
    $REDIS_CMD SET "small:$ID:$i" "value$i" > /dev/null
done

# === STRINGS GRANDES (big keys potenciais) ===
echo "Criando big strings..."
$REDIS_CMD SET "big_string:$ID:1mb" "$(printf 'A%.0s' {1..1048576})"
$REDIS_CMD SET "big_string:$ID:500kb" "$(printf 'B%.0s' {1..512000})"
$REDIS_CMD SET "big_string:$ID:100kb" "$(printf 'C%.0s' {1..102400})"

# === LISTAS GRANDES ===
echo "Criando big list..."
for i in {1..10000}; do
    $REDIS_CMD LPUSH "big_list:$ID" "item$i" > /dev/null
done

# === HASHES GRANDES ===
echo "Criando big hash..."
for i in {1..5000}; do
    $REDIS_CMD HSET "big_hash:$ID" "field$i" "value$i" > /dev/null
done

# === SETS GRANDES ===
echo "Criando big set..."
for i in {1..3000}; do
    $REDIS_CMD SADD "big_set:$ID" "member$i" > /dev/null
done

# === SORTED SETS GRANDES ===
echo "Criando big sorted set..."
for i in {1..2000}; do
    $REDIS_CMD ZADD "big_zset:$ID" $i "member$i" > /dev/null
done

# === DADOS COM TTL VARIADO ===
$REDIS_CMD SET "ttl_short:$ID:1" "expires in 60s" EX 60
$REDIS_CMD SET "ttl_medium:$ID:1" "expires in 300s" EX 300
$REDIS_CMD SET "ttl_long:$ID:1" "expires in 3600s" EX 3600
$REDIS_CMD SET "no_ttl:$ID:1" "never expires"

# === DADOS PARA HOT KEYS ===
echo "Criando hot key candidates..."
for i in {1..100}; do
    $REDIS_CMD SET "hot_candidate:$ID:$i" "hotvalue$i" > /dev/null
done

# === ESTRUTURAS ANINHADAS (JSON-like) ===
$REDIS_CMD SET "json_data:$ID:user1" '{"id":1,"name":"Jo√£o Silva","email":"joao@example.com","preferences":{"theme":"dark","notifications":true},"history":[1,2,3,4,5]}'
$REDIS_CMD SET "json_data:$ID:user2" '{"id":2,"name":"Maria Santos","email":"maria@example.com","preferences":{"theme":"light","notifications":false},"history":[6,7,8,9,10]}'

# === DADOS DE SESS√ÉO ===
echo "Criando dados de sess√£o..."
for i in {1..200}; do
    $REDIS_CMD HSET "session:$ID:$i" user_id $i login_time $(date +%s) ip "192.168.1.$((i%255))" > /dev/null
done

echo "‚úÖ Dados diversos inseridos no cluster"
```

**‚úÖ Checkpoint:** Cluster deve estar populado com dados de diferentes tipos e tamanhos.

---

### Exerc√≠cio 2: Identificar Big Keys (15 minutos)

**Objetivo:** Usar ferramentas Redis para identificar chaves que consomem muita mem√≥ria

> **üîç O QUE S√ÉO BIG KEYS E POR QUE S√ÉO PROBLEM√ÅTICAS:**
> 
> **Analogia:** Imagine um estacionamento onde a maioria dos carros s√£o compactos, mas alguns s√£o caminh√µes gigantes. Os caminh√µes:
> - **Demoram mais para entrar/sair** (opera√ß√µes lentas)
> - **Ocupam muito espa√ßo** (consomem muita mem√≥ria)  
> - **Bloqueiam outras vagas** (Redis √© single-threaded, opera√ß√µes grandes bloqueiam outras)
> - **Causam engarrafamento** (impactam performance geral)
> 
> **No Redis, Big Keys s√£o:**
> - **Strings > 100KB** (textos muito grandes)
> - **Listas > 1000 elementos** (arrays gigantes)
> - **Hashes > 1000 campos** (objetos com muitas propriedades)
> - **Sets/Sorted Sets > 1000 membros** (cole√ß√µes enormes)
> 
> **Por que s√£o problem√°ticas:**
> - ‚úÖ **Opera√ß√µes lentas:** `GET` de 1MB demora muito mais que `GET` de 1KB
> - ‚úÖ **Bloqueio:** Enquanto processa big key, outras opera√ß√µes esperam
> - ‚úÖ **Mem√≥ria:** Podem consumir 80% da RAM dispon√≠vel
> - ‚úÖ **Replica√ß√£o:** Demoram para sincronizar entre n√≥s

#### Passo 1: An√°lise B√°sica de Mem√≥ria

> **üß† O QUE VAMOS FAZER:**
> Antes de procurar big keys espec√≠ficas, vamos entender o "panorama geral" da mem√≥ria, como um m√©dico que primeiro mede press√£o e temperatura antes de fazer exames espec√≠ficos.

```bash
# Verificar uso total de mem√≥ria
echo "üîç Analisando uso de mem√≥ria..."
$REDIS_CMD info memory | grep -E "(used_memory|used_memory_human|used_memory_peak)"

# Contar total de chaves
TOTAL_KEYS=$($REDIS_CMD dbsize)
echo "Total de chaves: $TOTAL_KEYS"
```

> **üìä INTERPRETANDO OS RESULTADOS:**
> 
> **used_memory_human:** Mem√≥ria total usada (ex: "2.5M" = 2.5 megabytes)
> - **< 10MB:** Uso baixo, normal para labs
> - **10-100MB:** Uso moderado
> - **> 100MB:** Uso alto, investigar big keys
> 
> **used_memory_peak:** Maior uso de mem√≥ria j√° registrado
> - Se muito maior que atual = houve picos de uso
> - Pode indicar big keys tempor√°rias ou vazamentos
> 
> **Total de chaves vs Mem√≥ria:**
> - **1000 chaves = 1MB:** Chaves pequenas (~1KB cada)
> - **1000 chaves = 10MB:** Chaves m√©dias (~10KB cada)  
> - **1000 chaves = 100MB:** Big keys! (~100KB cada)
> 
> **üö® SINAIS DE ALERTA:**
> - Poucas chaves mas muita mem√≥ria = Big Keys
> - Muitas chaves mas pouca mem√≥ria = Chaves muito pequenas (ineficiente)
> - Pico muito maior que atual = Problema intermitente

#### Passo 2: Usar --bigkeys para Identificar Big Keys

> **üîß O QUE √â O COMANDO --bigkeys:**
> 
> **Analogia:** √â como um "scanner de bagagem" no aeroporto que identifica automaticamente as malas mais pesadas sem precisar abrir cada uma.
> 
> **O que faz:**
> - **Escaneia TODAS as chaves** do banco (pode demorar!)
> - **Agrupa por tipo** (strings, listas, hashes, etc.)
> - **Identifica as maiores** de cada tipo
> - **Mostra estat√≠sticas** gerais de uso
> 
> **‚ö†Ô∏è CUIDADO:** Em produ√ß√£o, pode impactar performance durante o scan!

```bash
# Executar an√°lise de big keys (pode demorar alguns minutos)
echo "üîç Executando an√°lise de big keys..."
$REDIS_CMD --bigkeys

# Salvar resultado em arquivo para an√°lise
$REDIS_CMD --bigkeys > /tmp/bigkeys_analysis_$ID.txt
echo "üìÑ Resultado salvo em /tmp/bigkeys_analysis_$ID.txt"
```

> **üìã INTERPRETANDO O RESULTADO DO --bigkeys:**
> 
> **Exemplo de sa√≠da:**
> ```
> -------- summary -------
> Sampled 5000 keys in the keyspace!
> Total key length in bytes is 45000 (avg len 9.00)
> 
> Biggest string found 'big_string:aluno01:1mb' has 1048576 bytes
> Biggest list   found 'big_list:aluno01' has 10000 items
> Biggest hash   found 'big_hash:aluno01' has 5000 fields
> ```
> 
> **Como interpretar:**
> - **"Biggest string":** A maior string encontrada (1MB neste caso)
> - **"has X bytes":** Tamanho em bytes (1048576 = 1MB)
> - **"has X items/fields":** N√∫mero de elementos na estrutura
> - **"avg len":** Tamanho m√©dio das chaves (nome da chave, n√£o valor)
> 
> **üö® ALERTAS:**
> - **Strings > 100KB:** Considere quebrar em peda√ßos menores
> - **Listas > 1000 items:** Use pagina√ß√£o ou estruturas menores
> - **Hashes > 1000 fields:** Considere m√∫ltiplos hashes menores

#### Passo 3: An√°lise Manual de Chaves Espec√≠ficas

> **üéØ POR QUE AN√ÅLISE MANUAL:**
> 
> **Analogia:** O --bigkeys √© como um "resumo executivo", mas √†s vezes voc√™ precisa "abrir a gaveta" e ver exatamente o que tem dentro.
> 
> **Quando usar:**
> - **Investigar chaves suspeitas** identificadas pelo --bigkeys
> - **Comparar tamanhos** entre diferentes estruturas
> - **Entender o crescimento** de chaves espec√≠ficas
> - **Validar otimiza√ß√µes** ap√≥s mudan√ßas
> 
> **Comando MEMORY USAGE:**
> - **Mostra bytes exatos** que a chave ocupa na RAM
> - **Inclui overhead** do Redis (metadados, √≠ndices, etc.)
> - **Mais preciso** que estimativas baseadas em conte√∫do

```bash
# Analisar uso de mem√≥ria de chaves espec√≠ficas
echo "üîç Analisando chaves espec√≠ficas..."

# Verificar tamanho das big strings
echo "=== Big Strings ==="
$REDIS_CMD memory usage big_string:$ID:1mb
$REDIS_CMD memory usage big_string:$ID:500kb
$REDIS_CMD memory usage big_string:$ID:100kb

# Verificar tamanho das estruturas grandes
echo "=== Big Structures ==="
$REDIS_CMD memory usage big_list:$ID
$REDIS_CMD memory usage big_hash:$ID
$REDIS_CMD memory usage big_set:$ID
$REDIS_CMD memory usage big_zset:$ID

# Verificar n√∫mero de elementos
echo "=== Contagem de Elementos ==="
echo "Lista: $($REDIS_CMD llen big_list:$ID) elementos"
echo "Hash: $($REDIS_CMD hlen big_hash:$ID) campos"
echo "Set: $($REDIS_CMD scard big_set:$ID) membros"
echo "Sorted Set: $($REDIS_CMD zcard big_zset:$ID) membros"
```

> **üìä INTERPRETANDO OS RESULTADOS:**
> 
> **MEMORY USAGE retorna bytes:**
> - **1048576 bytes = 1MB** (nossa big string de 1MB)
> - **512000 bytes = 500KB** (nossa big string de 500KB)
> - **Valores maiores que esperado?** Redis adiciona overhead (metadados)
> 
> **Contagem vs Tamanho:**
> - **Lista com 10000 elementos = ~200KB:** Normal (~20 bytes por item)
> - **Hash com 5000 campos = ~300KB:** Normal (~60 bytes por campo)
> - **Valores muito maiores?** Elementos individuais s√£o grandes
> 
> **üîç AN√ÅLISE PR√ÅTICA:**
> ```
> Lista: 10000 elementos, 500KB total
> ‚Üí 500KB √∑ 10000 = 50 bytes por elemento (normal)
> 
> Lista: 1000 elementos, 500KB total  
> ‚Üí 500KB √∑ 1000 = 500 bytes por elemento (elementos grandes!)
> ```
> 
> **üö® SINAIS DE PROBLEMA:**
> - **Overhead > 50%:** Muitas chaves pequenas (ineficiente)
> - **Elementos > 1KB cada:** Considere estruturas diferentes
> - **Crescimento descontrolado:** Falta TTL ou limpeza

#### Passo 4: Impacto de Big Keys na Performance

> **‚ö° POR QUE BIG KEYS AFETAM PERFORMANCE:**
> 
> **Analogia:** Imagine que voc√™ precisa mover uma caixa. Uma caixa de 1kg voc√™ move rapidamente, mas uma caixa de 100kg:
> - **Demora muito mais para mover** (opera√ß√£o lenta)
> - **Voc√™ fica ocupado por mais tempo** (bloqueia outras tarefas)
> - **Cansa mais** (usa mais recursos)
> - **Outras pessoas esperam** (impacta outras opera√ß√µes)
> 
> **No Redis √© igual:**
> - **Redis √© single-threaded:** Uma opera√ß√£o lenta bloqueia todas as outras
> - **Opera√ß√µes grandes = lat√™ncia alta:** Usu√°rios esperam mais
> - **Mem√≥ria fragmentada:** Dificulta aloca√ß√£o de novos dados
> - **Replica√ß√£o lenta:** Demora para sincronizar com r√©plicas

```bash
# Testar impacto de opera√ß√µes em big keys
echo "üß™ Testando impacto de big keys na performance..."

# Opera√ß√£o custosa: obter lista completa (MUITO CUSTOSO)
echo "Testando LRANGE em big_list..."
START_TIME=$(date +%s%N)
$REDIS_CMD lrange big_list:$ID 0 -1 > /dev/null
END_TIME=$(date +%s%N)
LRANGE_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "LRANGE completo: ${LRANGE_TIME}ms"

# Opera√ß√£o custosa: obter hash completo
echo "Testando HGETALL em big_hash..."
START_TIME=$(date +%s%N)
$REDIS_CMD hgetall big_hash:$ID > /dev/null
END_TIME=$(date +%s%N)
HGETALL_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "HGETALL completo: ${HGETALL_TIME}ms"

# Comparar com opera√ß√£o simples
echo "Testando GET em chave pequena..."
START_TIME=$(date +%s%N)
$REDIS_CMD get small:$ID:1 > /dev/null
END_TIME=$(date +%s%N)
GET_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "GET simples: ${GET_TIME}ms"

echo ""
echo "üìä Compara√ß√£o de Performance:"
echo "GET simples: ${GET_TIME}ms"
echo "LRANGE big_list: ${LRANGE_TIME}ms ($(( LRANGE_TIME / GET_TIME ))x mais lento)"
echo "HGETALL big_hash: ${HGETALL_TIME}ms ($(( HGETALL_TIME / GET_TIME ))x mais lento)"
```

> **üìä INTERPRETANDO OS RESULTADOS DE PERFORMANCE:**
> 
> **Tempos t√≠picos esperados:**
> - **GET simples:** 0.1-1ms (muito r√°pido)
> - **LRANGE pequeno (100 items):** 1-5ms (r√°pido)
> - **LRANGE grande (10000 items):** 10-100ms (lento!)
> - **HGETALL pequeno (10 campos):** 1-5ms (r√°pido)
> - **HGETALL grande (5000 campos):** 50-200ms (muito lento!)
> 
> **üö® SINAIS DE PROBLEMA:**
> - **Opera√ß√£o > 10ms:** Pode impactar usu√°rios
> - **Opera√ß√£o > 100ms:** Definitivamente problem√°tica
> - **Diferen√ßa > 100x:** Big key muito problem√°tica
> 
> **üí° IMPACTO REAL:**
> ```
> Cen√°rio: 1000 usu√°rios simult√¢neos
> 
> GET simples (1ms):
> ‚Üí 1000 opera√ß√µes/segundo = OK
> 
> HGETALL grande (100ms):
> ‚Üí 10 opera√ß√µes/segundo = PROBLEMA!
> ‚Üí 990 usu√°rios ficam esperando
> ```
> 
> **üîß SOLU√á√ïES:**
> - **Pagina√ß√£o:** `LRANGE 0 99` em vez de `LRANGE 0 -1`
> - **Campos espec√≠ficos:** `HGET` em vez de `HGETALL`
> - **Estruturas menores:** Quebrar big keys em v√°rias pequenas
> - **Cache local:** Evitar buscar big keys repetidamente

**Sinais de Big Keys Problem√°ticos:**
- ‚úÖ Chaves > 100KB (strings) ou > 1000 elementos (estruturas)
- ‚úÖ Opera√ß√µes que demoram > 10ms
- ‚úÖ Uso desproporcional de mem√≥ria
- ‚úÖ Bloqueio de outras opera√ß√µes

**‚úÖ Checkpoint:** Identificar quais s√£o as maiores chaves e seu impacto.

---

### Exerc√≠cio 3: Detectar Hot Keys (15 minutos)

**Objetivo:** Identificar chaves acessadas com alta frequ√™ncia

> **üî• O QUE S√ÉO HOT KEYS E POR QUE S√ÉO PROBLEM√ÅTICAS:**
> 
> **Analogia:** Imagine uma loja com 1000 produtos, mas 80% dos clientes querem apenas 3 produtos espec√≠ficos. Esses 3 produtos s√£o "hot items":
> - **Criam filas longas** (gargalo de acesso)
> - **Esgotam rapidamente** (sobrecarga do servidor)
> - **Funcion√°rios ficam ocupados** (recursos concentrados)
> - **Outros produtos s√£o ignorados** (distribui√ß√£o desigual)
> 
> **No Redis, Hot Keys s√£o:**
> - **Chaves acessadas muito frequentemente** (ex: 80% dos GETs)
> - **Concentram carga em poucos pontos** (hotspots)
> - **Causam gargalos de performance** (single-threaded)
> - **Podem sobrecarregar r√©plicas** (se usadas para leitura)
> 
> **Exemplos t√≠picos de Hot Keys:**
> - **Configura√ß√µes globais:** `app:config`, `feature:flags`
> - **Dados de usu√°rio popular:** `user:admin`, `user:celebrity`
> - **Contadores globais:** `stats:total_users`, `counter:page_views`
> - **Cache de consultas populares:** `search:trending`, `products:featured`
> 
> **Por que s√£o problem√°ticas:**
> - ‚úÖ **Gargalo de CPU:** Poucas chaves consomem muito processamento
> - ‚úÖ **Lat√™ncia alta:** Fila de espera para acessar hot keys
> - ‚úÖ **Distribui√ß√£o desigual:** Em clusters, alguns n√≥s ficam sobrecarregados
> - ‚úÖ **Falha em cascata:** Se hot key falha, muitas opera√ß√µes falham

#### Passo 1: Configurar Monitoramento de Hot Keys

```bash
# Verificar configura√ß√µes dispon√≠veis (ElastiCache pode restringir CONFIG)
echo "üîç Verificando configura√ß√£o de hot key tracking..."

# No ElastiCache, hot key tracking geralmente n√£o est√° dispon√≠vel via CONFIG
# Vamos usar abordagens alternativas para detectar hot keys

echo "‚ö†Ô∏è  NOTA: ElastiCache pode restringir comandos CONFIG por seguran√ßa"
echo "Vamos usar m√©todos alternativos para detectar hot keys:"

# Verificar se conseguimos acessar informa√ß√µes b√°sicas
$REDIS_CMD INFO server | head -5

# Alternativa: usar MONITOR para detectar hot keys (m√©todo manual)
echo "üí° Para detectar hot keys no ElastiCache, usaremos:"
echo "1. Comando MONITOR (observa√ß√£o manual)"
echo "2. An√°lise de padr√µes de acesso"
echo "3. Simula√ß√£o controlada"
```

#### Passo 2: Simular Acesso a Hot Keys

```bash
# Simular padr√£o de hot keys
echo "üß™ Simulando padr√£o de acesso a hot keys..."

# Fun√ß√£o para simular carga concentrada
simulate_hot_keys() {
    local endpoint=$1
    local student_id=$2
    local duration=60  # 1 minuto de simula√ß√£o
    local end_time=$(($(date +%s) + duration))
    
    echo "Simulando hot keys por $duration segundos..."
    
    while [ $(date +%s) -lt $end_time ]; do
        # 80% dos acessos v√£o para apenas 3 chaves (hot keys)
        for i in {1..8}; do
            redis-cli -h $endpoint -p 6379 --tls get hot_candidate:$student_id:1 > /dev/null &
            redis-cli -h $endpoint -p 6379 --tls get hot_candidate:$student_id:2 > /dev/null &
            redis-cli -h $endpoint -p 6379 --tls get hot_candidate:$student_id:3 > /dev/null &
        done
        
        # 20% dos acessos distribu√≠dos entre outras chaves
        for i in {1..2}; do
            RANDOM_KEY=$((RANDOM % 100 + 4))
            redis-cli -h $endpoint -p 6379 --tls get hot_candidate:$student_id:$RANDOM_KEY > /dev/null &
        done
        
        sleep 0.1
        wait  # Aguardar todos os processos background
    done
}

# Executar simula√ß√£o em background
simulate_hot_keys $DATA_ENDPOINT $ID &
SIMULATION_PID=$!

echo "üîç Simula√ß√£o iniciada (PID: $SIMULATION_PID)"
echo "Aguarde 60 segundos para coleta de dados..."
```

#### Passo 3: Monitorar Hot Keys em Tempo Real

```bash
# Usar MONITOR para observar comandos (cuidado: muito verboso)
echo "üîç Iniciando monitoramento de comandos por 30 segundos..."
timeout 30 redis-cli -h $DATA_ENDPOINT -p 6379 --tls monitor | grep "hot_candidate:$ID" > /tmp/monitor_output_$ID.txt &

# Aguardar coleta de dados
sleep 35

# Parar simula√ß√£o
kill $SIMULATION_PID 2>/dev/null || true
wait $SIMULATION_PID 2>/dev/null || true

echo "‚úÖ Simula√ß√£o conclu√≠da"
```

#### Passo 4: Analisar Padr√µes de Acesso

```bash
# Analisar dados coletados
echo "üìä Analisando padr√µes de acesso..."

if [ -f /tmp/monitor_output_$ID.txt ]; then
    echo "=== Top 10 Chaves Mais Acessadas ==="
    grep -o "hot_candidate:$ID:[0-9]*" /tmp/monitor_output_$ID.txt | sort | uniq -c | sort -nr | head -10
    
    echo ""
    echo "=== Estat√≠sticas de Acesso ==="
    TOTAL_ACCESSES=$(wc -l < /tmp/monitor_output_$ID.txt)
    TOP_3_ACCESSES=$(grep -o "hot_candidate:$ID:[1-3]" /tmp/monitor_output_$ID.txt | wc -l)
    HOT_PERCENTAGE=$(( TOP_3_ACCESSES * 100 / TOTAL_ACCESSES ))
    
    echo "Total de acessos: $TOTAL_ACCESSES"
    echo "Acessos √†s top 3 chaves: $TOP_3_ACCESSES"
    echo "Percentual de hot keys: ${HOT_PERCENTAGE}%"
else
    echo "‚ö†Ô∏è  Arquivo de monitoramento n√£o encontrado"
fi
```

#### Passo 5: Usar Ferramentas de An√°lise de Lat√™ncia

```bash
# Verificar lat√™ncia de comandos
echo "üìà Analisando lat√™ncia de comandos..."

# Verificar slow log
echo "=== Slow Log ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls slowlog get 10

# Verificar estat√≠sticas de comandos
echo "=== Command Stats ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls info commandstats | head -10

# Testar lat√™ncia espec√≠fica das hot keys
echo "=== Lat√™ncia das Hot Keys ==="
for key in 1 2 3; do
    echo "Testando hot_candidate:$ID:$key"
    redis-cli -h $DATA_ENDPOINT -p 6379 --tls --latency-history -i 1 get hot_candidate:$ID:$key | head -5 &
    sleep 2
    kill $! 2>/dev/null || true
done
```

**Sinais de Hot Keys Problem√°ticos:**
- ‚úÖ Poucas chaves recebem > 80% dos acessos
- ‚úÖ Lat√™ncia aumenta durante picos de acesso
- ‚úÖ CPU alta sem distribui√ß√£o uniforme de carga
- ‚úÖ Gargalo em single-threaded operations

**‚úÖ Checkpoint:** Identificar padr√µes de hot keys e seu impacto na performance.

---

### Exerc√≠cio 4: Analisar Padr√µes de TTL e Expira√ß√£o (15 minutos)

**Objetivo:** Identificar problemas relacionados a TTL e gerenciamento de expira√ß√£o

> **‚è∞ O QUE √â TTL E POR QUE √â CRUCIAL:**
> 
> **Analogia:** TTL (Time To Live) √© como a **data de validade** nos alimentos:
> - **Leite sem data de validade** ‚Üí Pode estragar e contaminar outros alimentos
> - **Dados sem TTL** ‚Üí Podem ficar obsoletos e consumir mem√≥ria desnecessariamente
> - **Data de validade muito curta** ‚Üí Desperd√≠cio (joga fora comida boa)
> - **TTL muito baixo** ‚Üí Overhead (Redis fica deletando dados √∫teis)
> 
> **No Redis, TTL gerencia o "ciclo de vida" dos dados:**
> - **TTL = -1:** Dados "imortais" (nunca expiram) - **PERIGOSO!**
> - **TTL = 0:** Dados j√° expirados (ser√£o deletados)
> - **TTL > 0:** Segundos restantes at√© expirar
> 
> **Por que TTL √© fundamental:**
> - ‚úÖ **Controla crescimento de mem√≥ria:** Evita ac√∫mulo infinito
> - ‚úÖ **Mant√©m dados frescos:** Remove informa√ß√µes obsoletas
> - ‚úÖ **Otimiza performance:** Menos dados = opera√ß√µes mais r√°pidas
> - ‚úÖ **Previne vazamentos:** Dados tempor√°rios n√£o ficam "esquecidos"
> 
> **Problemas comuns de TTL:**
> - **Sem TTL:** Dados crescem infinitamente (vazamento de mem√≥ria)
> - **TTL muito alto:** Dados obsoletos ocupam espa√ßo
> - **TTL muito baixo:** Overhead de expira√ß√£o constante
> - **TTL inconsistente:** Alguns dados expiram, outros n√£o (inconsist√™ncia)

#### Passo 1: Analisar TTL das Chaves Existentes

> **üîç O QUE VAMOS INVESTIGAR:**
> 
> **Analogia:** Somos "inspetores de validade" verificando se os produtos na prateleira t√™m data de validade adequada.
> 
> **O comando TTL retorna:**
> - **N√∫mero positivo:** Segundos restantes (ex: 3600 = 1 hora)
> - **-1:** Sem TTL (nunca expira) - **ALERTA!**
> - **-2:** Chave n√£o existe (j√° expirou ou nunca existiu)
> 
> **Estrat√©gia de an√°lise:**
> 1. **Verificar chaves de teste** (criadas com TTL diferentes)
> 2. **Verificar big keys** (podem estar sem TTL)
> 3. **Identificar padr√µes** (quais tipos t√™m/n√£o t√™m TTL)

```bash
# Verificar TTL de diferentes tipos de chaves
echo "üîç Analisando TTL das chaves..."

echo "=== TTL das Chaves de Teste ==="
$REDIS_CMD ttl ttl_short:$ID:1
$REDIS_CMD ttl ttl_medium:$ID:1
$REDIS_CMD ttl ttl_long:$ID:1
$REDIS_CMD ttl no_ttl:$ID:1

echo ""
echo "=== TTL das Big Keys ==="
$REDIS_CMD ttl big_string:$ID:1mb
$REDIS_CMD ttl big_list:$ID
$REDIS_CMD ttl big_hash:$ID
```

> **üìä INTERPRETANDO OS RESULTADOS:**
> 
> **Exemplo de sa√≠da esperada:**
> ```
> TTL ttl_short:$ID:1    ‚Üí 45      (45 segundos restantes)
> TTL ttl_medium:$ID:1   ‚Üí 280     (280 segundos = ~5 minutos)
> TTL ttl_long:$ID:1     ‚Üí 3540    (3540 segundos = ~1 hora)
> TTL no_ttl:$ID:1       ‚Üí -1      (SEM TTL - PROBLEMA!)
> TTL big_string:$ID:1mb ‚Üí -1      (Big key sem TTL - GRAVE!)
> ```
> 
> **üö® SINAIS DE ALERTA:**
> - **TTL = -1 em big keys:** Mem√≥ria pode crescer infinitamente
> - **TTL = -1 em dados tempor√°rios:** Vazamento de mem√≥ria
> - **TTL muito baixo (< 60s):** Overhead de expira√ß√£o
> - **TTL inconsistente:** Alguns dados expiram, outros n√£o
> 
> **üí° AN√ÅLISE PR√ÅTICA:**
> ```
> Cen√°rio: E-commerce
> 
> ‚úÖ BOM:
> - Carrinho de compras: TTL 1800s (30 min)
> - Cache de produtos: TTL 3600s (1 hora)
> - Sess√£o de usu√°rio: TTL 7200s (2 horas)
> 
> ‚ùå PROBLEM√ÅTICO:
> - Dados de auditoria: TTL -1 (cresce infinitamente)
> - Cache tempor√°rio: TTL -1 (nunca limpa)
> - Logs de debug: TTL -1 (acumula lixo)
> ```

#### Passo 2: Identificar Chaves sem TTL

> **üïµÔ∏è CA√áA AOS "IMORTAIS":**
> 
> **Analogia:** Vamos procurar produtos na loja que **n√£o t√™m data de validade** - estes s√£o os mais perigosos porque podem "estragar" sem aviso.
> 
> **Por que chaves sem TTL s√£o problem√°ticas:**
> - **Crescimento infinito:** Nunca s√£o removidas automaticamente
> - **Mem√≥ria desperdi√ßada:** Dados obsoletos ocupam espa√ßo
> - **Performance degradada:** Mais dados = opera√ß√µes mais lentas
> - **Inconsist√™ncia:** Dados antigos podem estar incorretos
> 
> **Estrat√©gia de busca:**
> 1. **SCAN em vez de KEYS:** Mais seguro em produ√ß√£o
> 2. **Verificar por padr√µes:** big_*, session:*, cache:*
> 3. **Calcular tamanho:** Priorizar big keys sem TTL
> 
> **‚ö†Ô∏è IMPORTANTE:** Comando KEYS √© perigoso em produ√ß√£o (bloqueia Redis), sempre use SCAN!

```bash
# Encontrar chaves sem TTL (TTL = -1)
echo "üîç Identificando chaves sem TTL..."

# Fun√ß√£o para verificar TTL de m√∫ltiplas chaves
check_ttl_patterns() {
    local pattern=$1
    echo "Verificando padr√£o: $pattern"
    
    # Usar SCAN para evitar KEYS (mais seguro)
    $REDIS_CMD --scan --pattern "$pattern" | while read key; do
        TTL=$($REDIS_CMD ttl "$key")
        if [ "$TTL" = "-1" ]; then
            SIZE=$($REDIS_CMD memory usage "$key" 2>/dev/null || echo "N/A")
            echo "  $key: sem TTL, tamanho: $SIZE bytes"
        fi
    done
}

# Verificar diferentes padr√µes
check_ttl_patterns "big_*:$ID*"
check_ttl_patterns "session:$ID:*"
check_ttl_patterns "small:$ID:*"
```

> **üìä INTERPRETANDO OS RESULTADOS:**
> 
> **Exemplo de sa√≠da esperada:**
> ```
> Verificando padr√£o: big_*:aluno01*
>   big_string:aluno01:1mb: sem TTL, tamanho: 1048576 bytes  ‚Üê CR√çTICO!
>   big_list:aluno01: sem TTL, tamanho: 245760 bytes         ‚Üê PROBLEMA!
> 
> Verificando padr√£o: session:aluno01:*
>   session:aluno01:15: sem TTL, tamanho: 128 bytes          ‚Üê Menor prioridade
>   session:aluno01:23: sem TTL, tamanho: 128 bytes
> ```
> 
> **üö® PRIORIZA√á√ÉO DE PROBLEMAS:**
> 
> **CR√çTICO (A√ß√£o imediata):**
> - **Big keys sem TTL:** > 100KB sem expira√ß√£o
> - **Dados tempor√°rios sem TTL:** Cache, sess√µes, logs
> 
> **ALTO (A√ß√£o em breve):**
> - **M√∫ltiplas chaves pequenas sem TTL:** Ac√∫mulo gradual
> - **Dados de neg√≥cio sem TTL:** Podem ficar obsoletos
> 
> **M√âDIO (Monitorar):**
> - **Configura√ß√µes sem TTL:** Podem ser intencionais
> - **Dados de refer√™ncia sem TTL:** Raramente mudam
> 
> **üí° ESTRAT√âGIAS DE CORRE√á√ÉO:**
> ```bash
> # Para big keys sem TTL (URGENTE):
> EXPIRE big_string:aluno01:1mb 3600    # 1 hora
> 
> # Para sess√µes sem TTL:
> EXPIRE session:aluno01:15 1800        # 30 minutos
> 
> # Para dados tempor√°rios:
> EXPIRE cache:temp:data 300            # 5 minutos
> ```

#### Passo 3: Simular Problema de Expira√ß√£o

> **üß™ LABORAT√ìRIO DE EXPIRA√á√ÉO:**
> 
> **Analogia:** Vamos simular uma situa√ß√£o onde colocamos **1000 produtos com validade de 30 segundos** na prateleira e observamos o que acontece quando todos come√ßam a "vencer" ao mesmo tempo.
> 
> **O que vamos observar:**
> - **Overhead de expira√ß√£o:** Redis precisa processar muitas expira√ß√µes
> - **Impacto na performance:** CPU ocupada removendo chaves expiradas
> - **Padr√µes de expira√ß√£o:** Como Redis gerencia expira√ß√µes em lote
> 
> **Por que TTL muito baixo √© problem√°tico:**
> - **CPU overhead:** Redis gasta tempo removendo chaves constantemente
> - **Fragmenta√ß√£o:** Mem√≥ria fica fragmentada com cria√ß√£o/remo√ß√£o frequente
> - **Inconsist√™ncia:** Dados podem expirar no meio de opera√ß√µes
> 
> **Configura√ß√£o do Redis para expira√ß√£o:**
> - **hz:** Frequ√™ncia de verifica√ß√£o de expira√ß√µes (padr√£o: 10 Hz)
> - **Expira√ß√£o ativa:** Redis remove chaves expiradas proativamente
> - **Expira√ß√£o passiva:** Remove quando chave √© acessada

```bash
# Criar chaves com TTL muito baixo para demonstrar problema
echo "üß™ Simulando problema de expira√ß√£o..."

# Criar muitas chaves com TTL baixo
echo "Criando chaves com TTL baixo..."
for i in {1..1000}; do
    $REDIS_CMD SET "expire_test:$ID:$i" "value$i" EX 30 > /dev/null
done

echo "‚úÖ Criadas 1000 chaves com TTL de 30 segundos"

# Monitorar estat√≠sticas de expira√ß√£o
echo "üìä Monitorando estat√≠sticas de expira√ß√£o..."
for i in {1..6}; do
    echo "=== Verifica√ß√£o $i ($(date '+%H:%M:%S')) ==="
    
    # Estat√≠sticas de expira√ß√£o
    $REDIS_CMD info stats | grep -E "(expired_keys|evicted_keys)"
    
    # Contar chaves restantes
    REMAINING=$($REDIS_CMD eval "return #redis.call('keys', 'expire_test:$ID:*')" 0)
    echo "Chaves restantes: $REMAINING"
    
    sleep 10
done
```

> **üìä INTERPRETANDO O MONITORAMENTO:**
> 
> **Estat√≠sticas importantes:**
> - **expired_keys:** Total de chaves que expiraram desde o in√≠cio
> - **evicted_keys:** Chaves removidas por pol√≠tica de mem√≥ria (diferente de expira√ß√£o)
> 
> **Exemplo de progress√£o esperada:**
> ```
> Verifica√ß√£o 1 (14:30:00):
> expired_keys:0
> Chaves restantes: 1000
> 
> Verifica√ß√£o 4 (14:30:30):  ‚Üê TTL de 30s expirando
> expired_keys:856
> Chaves restantes: 144
> 
> Verifica√ß√£o 6 (14:30:50):
> expired_keys:1000
> Chaves restantes: 0
> ```
> 
> **üîç AN√ÅLISE DO COMPORTAMENTO:**
> 
> **Expira√ß√£o n√£o √© instant√¢nea:**
> - Redis n√£o remove chaves exatamente no segundo da expira√ß√£o
> - Usa algoritmo probabil√≠stico para efici√™ncia
> - Algumas chaves podem "sobreviver" alguns segundos extras
> 
> **Padr√µes de expira√ß√£o:**
> - **Expira√ß√£o em lotes:** Redis remove v√°rias chaves por vez
> - **Distribui√ß√£o temporal:** N√£o todas expiram simultaneamente
> - **Overhead vari√°vel:** Depende da quantidade de chaves expirando
> 
> **üö® SINAIS DE PROBLEMA COM TTL:**
> - **expired_keys crescendo muito r√°pido:** TTL muito baixo
> - **Chaves n√£o expirando:** Poss√≠vel problema de configura√ß√£o
> - **Performance degradada:** Overhead de expira√ß√£o alto
> - **Mem√≥ria n√£o liberando:** Fragmenta√ß√£o ou vazamentos

#### Passo 4: Analisar Impacto de Expira√ß√£o na Performance

```bash
# Verificar configura√ß√£o de expira√ß√£o
echo "üîç Analisando configura√ß√£o de expira√ß√£o..."
redis-cli -h $DATA_ENDPOINT -p 6379 --tls INFO stats | grep expired_keys

# Verificar estat√≠sticas detalhadas
echo "üìà Estat√≠sticas de expira√ß√£o e eviction:"
redis-cli -h $DATA_ENDPOINT -p 6379 --tls info stats | grep -E "(expired_keys|evicted_keys|keyspace_hits|keyspace_misses)"

# Calcular hit rate
HITS=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls info stats | grep keyspace_hits | cut -d: -f2 | tr -d '\r')
MISSES=$(redis-cli -h $DATA_ENDPOINT -p 6379 --tls info stats | grep keyspace_misses | cut -d: -f2 | tr -d '\r')
TOTAL=$((HITS + MISSES))
if [ $TOTAL -gt 0 ]; then
    HIT_RATE=$(( HITS * 100 / TOTAL ))
    echo "Hit Rate: ${HIT_RATE}% ($HITS hits, $MISSES misses)"
else
    echo "Hit Rate: N/A (sem estat√≠sticas suficientes)"
fi
```

**Problemas Comuns de TTL:**
- ‚úÖ Big keys sem TTL (consomem mem√≥ria indefinidamente)
- ‚úÖ TTL muito baixo (overhead de expira√ß√£o)
- ‚úÖ TTL inconsistente (alguns dados expiram, outros n√£o)
- ‚úÖ Falta de estrat√©gia de eviction

**‚úÖ Checkpoint:** Identificar problemas de TTL e estrat√©gias de expira√ß√£o.

---

## üîç An√°lise Avan√ßada de Padr√µes de Dados

> **üéØ OBJETIVO DESTA SE√á√ÉO:**
> 
> Agora que voc√™ j√° identificou big keys, hot keys e problemas de TTL individualmente, vamos fazer uma **an√°lise hol√≠stica** - como um m√©dico que, ap√≥s exames espec√≠ficos, faz um diagn√≥stico geral do paciente.
> 
> **Analogia:** Se os exerc√≠cios anteriores foram como "examinar √≥rg√£os individuais", agora vamos "fazer um check-up completo" para entender como todos os problemas se relacionam e impactam o sistema como um todo.
> 
> **O que vamos aprender:**
> - **Correla√ß√£o entre problemas:** Como big keys + hot keys = desastre
> - **Padr√µes de inefici√™ncia:** Estruturas que parecem OK mas s√£o problem√°ticas
> - **Fragmenta√ß√£o de mem√≥ria:** O "lixo invis√≠vel" que consome RAM
> - **An√°lise de custo-benef√≠cio:** Quais otimiza√ß√µes t√™m maior impacto

### Identifica√ß√£o de Padr√µes Problem√°ticos

#### 1. Big Keys Problem√°ticos por Tipo

> **üî¨ AN√ÅLISE CIENT√çFICA DE BIG KEYS:**
> 
> **Analogia:** Imagine que voc√™ √© um nutricionista analisando a dieta de algu√©m. N√£o basta saber que a pessoa come muito - voc√™ precisa saber **o que** ela come muito:
> - **Muito a√ß√∫car?** ‚Üí Problema de energia (strings grandes)
> - **Muito sal?** ‚Üí Problema de press√£o (listas grandes)
> - **Muita gordura?** ‚Üí Problema de colesterol (hashes grandes)
> 
> **No Redis, cada tipo de big key tem impactos diferentes:**
> - **Big Strings:** Impacto na transfer√™ncia de rede e serializa√ß√£o
> - **Big Lists:** Impacto em opera√ß√µes de range e itera√ß√£o
> - **Big Hashes:** Impacto em opera√ß√µes de campo e busca
> - **Big Sets:** Impacto em opera√ß√µes de uni√£o e interse√ß√£o
> 
> **Por que analisar por tipo:**
> - **Estrat√©gias diferentes:** Cada tipo precisa de otimiza√ß√£o espec√≠fica
> - **Impactos diferentes:** String grande ‚â† Lista grande em termos de performance
> - **Solu√ß√µes espec√≠ficas:** Hash grande ‚Üí m√∫ltiplos hashes pequenos

```bash
# Identificar big keys por tipo com an√°lise detalhada
echo "üìä An√°lise Detalhada de Big Keys por Tipo:"

# Fun√ß√£o para analisar big keys por tipo
analyze_big_keys_by_type() {
    echo "=== An√°lise por Tipo de Estrutura ==="
    
    # Contadores por tipo
    declare -A type_count
    declare -A type_total_size
    
    # Analisar todas as chaves
    $REDIS_CMD --scan --pattern "*:$ID*" | while read key; do
        TYPE=$($REDIS_CMD type "$key")
        SIZE=$($REDIS_CMD memory usage "$key" 2>/dev/null || echo "0")
        
        # Considerar "big" se > 10KB
        if [ "$SIZE" -gt 10240 ]; then
            case $TYPE in
                "string")
                    echo "ÔøΩ Big String: $key"
                    echo "   Tamanho: $SIZE bytes ($(( SIZE / 1024 ))KB)"
                    LENGTH=$($REDIS_CMD strlen "$key")
                    echo "   Caracteres: $LENGTH"
                    echo "   Overhead: $(( SIZE - LENGTH )) bytes ($(( (SIZE - LENGTH) * 100 / SIZE ))%)"
                    echo "   üí° Solu√ß√£o: Considere compress√£o ou chunking"
                    ;;
                "list")
                    echo "üìã Big List: $key"
                    echo "   Tamanho: $SIZE bytes ($(( SIZE / 1024 ))KB)"
                    COUNT=$($REDIS_CMD llen "$key")
                    echo "   Elementos: $COUNT"
                    echo "   Bytes por elemento: $(( SIZE / COUNT ))"
                    echo "   üí° Solu√ß√£o: Pagina√ß√£o ou m√∫ltiplas listas menores"
                    ;;
                "hash")
                    echo "üóÇÔ∏è  Big Hash: $key"
                    echo "   Tamanho: $SIZE bytes ($(( SIZE / 1024 ))KB)"
                    COUNT=$($REDIS_CMD hlen "$key")
                    echo "   Campos: $COUNT"
                    echo "   Bytes por campo: $(( SIZE / COUNT ))"
                    echo "   üí° Solu√ß√£o: M√∫ltiplos hashes ou estrutura hier√°rquica"
                    ;;
                "set")
                    echo "üéØ Big Set: $key"
                    echo "   Tamanho: $SIZE bytes ($(( SIZE / 1024 ))KB)"
                    COUNT=$($REDIS_CMD scard "$key")
                    echo "   Membros: $COUNT"
                    echo "   Bytes por membro: $(( SIZE / COUNT ))"
                    echo "   üí° Solu√ß√£o: M√∫ltiplos sets ou bloom filters"
                    ;;
                "zset")
                    echo "üìä Big Sorted Set: $key"
                    echo "   Tamanho: $SIZE bytes ($(( SIZE / 1024 ))KB)"
                    COUNT=$($REDIS_CMD zcard "$key")
                    echo "   Membros: $COUNT"
                    echo "   Bytes por membro: $(( SIZE / COUNT ))"
                    echo "   üí° Solu√ß√£o: Pagina√ß√£o ou m√∫ltiplos sorted sets"
                    ;;
            esac
            echo ""
        fi
    done
}

# Executar an√°lise
analyze_big_keys_by_type
```

> **üìä INTERPRETANDO A AN√ÅLISE POR TIPO:**
> 
> **Para cada tipo, observe:**
> 
> **üî§ Strings:**
> - **Overhead baixo (< 10%):** String eficiente
> - **Overhead alto (> 30%):** Considere compress√£o
> - **Muito grandes (> 1MB):** Considere chunking
> 
> **üìã Lists:**
> - **< 100 bytes/elemento:** Eficiente
> - **> 1000 bytes/elemento:** Elementos muito grandes
> - **> 10000 elementos:** Considere pagina√ß√£o
> 
> **üóÇÔ∏è Hashes:**
> - **< 200 bytes/campo:** Eficiente
> - **> 1000 campos:** Considere m√∫ltiplos hashes
> - **Campos muito grandes:** Considere normaliza√ß√£o
> 
> **üéØ Sets/Sorted Sets:**
> - **< 100 bytes/membro:** Eficiente
> - **> 100000 membros:** Considere particionamento
> - **Membros muito grandes:** Considere refer√™ncias

#### 2. Estruturas Ineficientes

> **üèóÔ∏è ARQUITETURA DE DADOS EFICIENTE:**
> 
> **Analogia:** Imagine organizar uma biblioteca. Voc√™ pode:
> - **‚ùå Ineficiente:** 1 livro por estante (m√∫ltiplas strings)
> - **‚úÖ Eficiente:** V√°rios livros por estante (hash com m√∫ltiplos campos)
> 
> **No Redis, a escolha da estrutura impacta:**
> - **Mem√≥ria:** Overhead por chave vs overhead por estrutura
> - **Performance:** Opera√ß√µes at√¥micas vs m√∫ltiplas opera√ß√µes
> - **Manutenibilidade:** Consist√™ncia de dados relacionados
> 
> **Regra de ouro:** Dados relacionados devem ficar juntos!
> 
> **Exemplos de inefici√™ncia:**
> ```
> ‚ùå INEFICIENTE:
> user:123:name ‚Üí "Jo√£o"
> user:123:email ‚Üí "joao@test.com"  
> user:123:age ‚Üí "30"
> (3 chaves, 3x overhead, 3 opera√ß√µes para buscar usu√°rio completo)
> 
> ‚úÖ EFICIENTE:
> user:123 ‚Üí {name: "Jo√£o", email: "joao@test.com", age: "30"}
> (1 chave, 1x overhead, 1 opera√ß√£o para buscar usu√°rio completo)
> ```

```bash
# Analisar efici√™ncia de estruturas com compara√ß√£o pr√°tica
echo "üìä An√°lise de Efici√™ncia de Estruturas:"

# Demonstra√ß√£o pr√°tica: Hash vs m√∫ltiplas strings
echo "=== Experimento: Hash vs Strings M√∫ltiplas ==="

# Limpar dados de teste anteriores
$REDIS_CMD del "user_hash:$ID:1" "user_string:$ID:1:name" "user_string:$ID:1:email" "user_string:$ID:1:age"

# M√©todo 1: Usando Hash (EFICIENTE)
echo "üóÇÔ∏è Criando dados usando Hash..."
$REDIS_CMD HSET "user_hash:$ID:1" name "Jo√£o Silva" email "joao.silva@empresa.com" age "35" department "TI" salary "5000" city "S√£o Paulo"

# M√©todo 2: Usando m√∫ltiplas strings (INEFICIENTE)  
echo "üî§ Criando dados usando m√∫ltiplas Strings..."
$REDIS_CMD SET "user_string:$ID:1:name" "Jo√£o Silva"
$REDIS_CMD SET "user_string:$ID:1:email" "joao.silva@empresa.com"
$REDIS_CMD SET "user_string:$ID:1:age" "35"
$REDIS_CMD SET "user_string:$ID:1:department" "TI"
$REDIS_CMD SET "user_string:$ID:1:salary" "5000"
$REDIS_CMD SET "user_string:$ID:1:city" "S√£o Paulo"

# Comparar uso de mem√≥ria
echo ""
echo "üìä Compara√ß√£o de Uso de Mem√≥ria:"
HASH_SIZE=$($REDIS_CMD memory usage "user_hash:$ID:1")
STRING1_SIZE=$($REDIS_CMD memory usage "user_string:$ID:1:name")
STRING2_SIZE=$($REDIS_CMD memory usage "user_string:$ID:1:email")
STRING3_SIZE=$($REDIS_CMD memory usage "user_string:$ID:1:age")
STRING4_SIZE=$($REDIS_CMD memory usage "user_string:$ID:1:department")
STRING5_SIZE=$($REDIS_CMD memory usage "user_string:$ID:1:salary")
STRING6_SIZE=$($REDIS_CMD memory usage "user_string:$ID:1:city")
STRINGS_TOTAL=$((STRING1_SIZE + STRING2_SIZE + STRING3_SIZE + STRING4_SIZE + STRING5_SIZE + STRING6_SIZE))

echo "Hash (1 chave): $HASH_SIZE bytes"
echo "Strings (6 chaves): $STRINGS_TOTAL bytes"
echo "Economia com Hash: $((STRINGS_TOTAL - HASH_SIZE)) bytes"
echo "Percentual de economia: $(( (STRINGS_TOTAL - HASH_SIZE) * 100 / STRINGS_TOTAL ))%"

# Comparar performance de acesso
echo ""
echo "‚ö° Compara√ß√£o de Performance:"

# Testar acesso via Hash (1 opera√ß√£o)
echo "Hash - buscar usu√°rio completo:"
START_TIME=$(date +%s%N)
$REDIS_CMD HGETALL "user_hash:$ID:1" > /dev/null
END_TIME=$(date +%s%N)
HASH_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "Tempo: ${HASH_TIME}ms (1 opera√ß√£o)"

# Testar acesso via m√∫ltiplas strings (6 opera√ß√µes)
echo "Strings - buscar usu√°rio completo:"
START_TIME=$(date +%s%N)
$REDIS_CMD GET "user_string:$ID:1:name" > /dev/null
$REDIS_CMD GET "user_string:$ID:1:email" > /dev/null
$REDIS_CMD GET "user_string:$ID:1:age" > /dev/null
$REDIS_CMD GET "user_string:$ID:1:department" > /dev/null
$REDIS_CMD GET "user_string:$ID:1:salary" > /dev/null
$REDIS_CMD GET "user_string:$ID:1:city" > /dev/null
END_TIME=$(date +%s%N)
STRINGS_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "Tempo: ${STRINGS_TIME}ms (6 opera√ß√µes)"

echo ""
echo "üéØ Resultado da Compara√ß√£o:"
echo "Economia de mem√≥ria: $(( (STRINGS_TOTAL - HASH_SIZE) * 100 / STRINGS_TOTAL ))%"
echo "Diferen√ßa de performance: $(( STRINGS_TIME - HASH_TIME ))ms ($(( STRINGS_TIME * 100 / HASH_TIME - 100 ))% mais lento com strings)"
echo "Redu√ß√£o de opera√ß√µes: 6 ‚Üí 1 (83% menos opera√ß√µes)"
```

> **üìä INTERPRETANDO OS RESULTADOS DE EFICI√äNCIA:**
> 
> **Economia de Mem√≥ria T√≠pica:**
> - **Hash vs Strings:** 30-60% menos mem√≥ria
> - **Motivo:** Overhead por chave √© eliminado
> - **Impacto:** Mais dados cabem na mesma RAM
> 
> **Melhoria de Performance:**
> - **Menos opera√ß√µes de rede:** 6 GETs ‚Üí 1 HGETALL
> - **Opera√ß√£o at√¥mica:** Dados consistentes
> - **Menos overhead de protocolo:** Menos comandos Redis
> 
> **Outros Benef√≠cios:**
> - **Consist√™ncia:** Dados relacionados ficam juntos
> - **Atomicidade:** HSET atualiza m√∫ltiplos campos atomicamente
> - **Simplicidade:** Menos chaves para gerenciar
> 
> **üö® QUANDO N√ÉO USAR HASH:**
> - **Campos muito grandes (> 1MB):** Use strings separadas
> - **Acesso independente:** Se nunca acessa campos juntos
> - **TTL diferente:** Se campos precisam expirar em tempos diferentes
> - **Tipos diferentes:** Se precisa de listas, sets, etc. por campo

#### 3. An√°lise de Fragmenta√ß√£o

> **üß© FRAGMENTA√á√ÉO DE MEM√ìRIA - O "LIXO INVIS√çVEL":**
> 
> **Analogia:** Imagine um estacionamento onde carros saem e entram constantemente:
> - **Sem fragmenta√ß√£o:** Carros estacionados em sequ√™ncia, espa√ßo otimizado
> - **Com fragmenta√ß√£o:** Espa√ßos vazios espalhados, dif√≠cil estacionar carros grandes
> 
> **No Redis, fragmenta√ß√£o acontece quando:**
> - **Chaves s√£o criadas e deletadas constantemente**
> - **Tamanhos de dados variam muito**
> - **Mem√≥ria fica "furada" com espa√ßos inutiliz√°veis**
> 
> **Por que fragmenta√ß√£o √© problem√°tica:**
> - **Desperd√≠cio de RAM:** Espa√ßos pequenos n√£o podem ser usados
> - **Performance degradada:** Alocador precisa procurar espa√ßos livres
> - **OOM prematuro:** Redis pode ficar "sem mem√≥ria" mesmo com espa√ßos livres
> 
> **M√©tricas importantes:**
> - **mem_fragmentation_ratio:** Raz√£o entre mem√≥ria alocada e usada
> - **< 1.0:** Swap sendo usado (CR√çTICO!)
> - **1.0-1.5:** Fragmenta√ß√£o normal (OK)
> - **> 1.5:** Fragmenta√ß√£o alta (PROBLEMA!)

```bash
# An√°lise detalhada de fragmenta√ß√£o de mem√≥ria
echo "üìä An√°lise Detalhada de Fragmenta√ß√£o:"

# Obter estat√≠sticas completas de mem√≥ria
echo "=== Estat√≠sticas de Mem√≥ria ==="
MEMORY_INFO=$($REDIS_CMD info memory)

# Extrair m√©tricas importantes
USED_MEMORY=$(echo "$MEMORY_INFO" | grep "used_memory:" | cut -d: -f2 | tr -d '\r')
USED_MEMORY_RSS=$(echo "$MEMORY_INFO" | grep "used_memory_rss:" | cut -d: -f2 | tr -d '\r')
USED_MEMORY_PEAK=$(echo "$MEMORY_INFO" | grep "used_memory_peak:" | cut -d: -f2 | tr -d '\r')
MEM_FRAGMENTATION_RATIO=$(echo "$MEMORY_INFO" | grep "mem_fragmentation_ratio:" | cut -d: -f2 | tr -d '\r')
MEM_ALLOCATOR=$(echo "$MEMORY_INFO" | grep "mem_allocator:" | cut -d: -f2 | tr -d '\r')

echo "Mem√≥ria usada (l√≥gica): $USED_MEMORY bytes ($(( USED_MEMORY / 1024 / 1024 ))MB)"
echo "Mem√≥ria RSS (f√≠sica): $USED_MEMORY_RSS bytes ($(( USED_MEMORY_RSS / 1024 / 1024 ))MB)"
echo "Pico de mem√≥ria: $USED_MEMORY_PEAK bytes ($(( USED_MEMORY_PEAK / 1024 / 1024 ))MB)"
echo "Alocador de mem√≥ria: $MEM_ALLOCATOR"
echo "Raz√£o de fragmenta√ß√£o: $MEM_FRAGMENTATION_RATIO"

# Interpretar fragmenta√ß√£o
echo ""
echo "üîç Interpreta√ß√£o da Fragmenta√ß√£o:"
FRAG_INT=$(echo "$MEM_FRAGMENTATION_RATIO" | cut -d. -f1)
FRAG_DEC=$(echo "$MEM_FRAGMENTATION_RATIO" | cut -d. -f2)

if [ "$FRAG_INT" -eq 0 ] || ([ "$FRAG_INT" -eq 1 ] && [ "${FRAG_DEC:0:1}" -lt 5 ]); then
    echo "üö® CR√çTICO: Fragmenta√ß√£o muito baixa (< 1.5)"
    echo "   Poss√≠vel uso de swap ou compress√£o excessiva"
    echo "   A√ß√£o: Verificar configura√ß√£o de mem√≥ria"
elif [ "$FRAG_INT" -eq 1 ] && [ "${FRAG_DEC:0:1}" -lt 5 ]; then
    echo "‚úÖ NORMAL: Fragmenta√ß√£o saud√°vel (1.0-1.5)"
    echo "   Sistema operando eficientemente"
elif [ "$FRAG_INT" -eq 1 ] && [ "${FRAG_DEC:0:1}" -ge 5 ]; then
    echo "‚ö†Ô∏è ATEN√á√ÉO: Fragmenta√ß√£o moderada (1.5-2.0)"
    echo "   Monitorar crescimento, considerar otimiza√ß√µes"
else
    echo "üö® PROBLEMA: Fragmenta√ß√£o alta (> 2.0)"
    echo "   A√ß√£o necess√°ria: restart ou otimiza√ß√£o de dados"
fi

# Calcular desperd√≠cio de mem√≥ria
WASTED_MEMORY=$((USED_MEMORY_RSS - USED_MEMORY))
WASTE_PERCENTAGE=$(( WASTED_MEMORY * 100 / USED_MEMORY_RSS ))
echo ""
echo "üí∏ An√°lise de Desperd√≠cio:"
echo "Mem√≥ria desperdi√ßada: $WASTED_MEMORY bytes ($(( WASTED_MEMORY / 1024 / 1024 ))MB)"
echo "Percentual de desperd√≠cio: $WASTE_PERCENTAGE%"

# Verificar estat√≠sticas avan√ßadas de aloca√ß√£o (se dispon√≠vel)
echo ""
echo "=== Estat√≠sticas Avan√ßadas de Aloca√ß√£o ==="
$REDIS_CMD memory stats 2>/dev/null || echo "‚ö†Ô∏è Comando MEMORY STATS n√£o dispon√≠vel nesta vers√£o"
```

> **üìä INTERPRETANDO A AN√ÅLISE DE FRAGMENTA√á√ÉO:**
> 
> **Raz√£o de Fragmenta√ß√£o (mem_fragmentation_ratio):**
> 
> **< 1.0 (CR√çTICO):**
> - **Problema:** Sistema usando swap ou compress√£o
> - **Sintomas:** Performance muito degradada
> - **A√ß√£o:** Aumentar RAM ou reduzir dados
> 
> **1.0-1.5 (NORMAL):**
> - **Status:** Fragmenta√ß√£o saud√°vel
> - **Explica√ß√£o:** Overhead normal do alocador
> - **A√ß√£o:** Continuar monitorando
> 
> **1.5-2.0 (ATEN√á√ÉO):**
> - **Status:** Fragmenta√ß√£o moderada
> - **Causa:** Padr√µes de cria√ß√£o/dele√ß√£o de dados
> - **A√ß√£o:** Considerar otimiza√ß√µes ou restart
> 
> **> 2.0 (PROBLEMA):**
> - **Status:** Fragmenta√ß√£o alta
> - **Impacto:** Desperd√≠cio significativo de RAM
> - **A√ß√£o:** Restart do Redis ou reestrutura√ß√£o de dados
> 
> **üí° CAUSAS COMUNS DE FRAGMENTA√á√ÉO:**
> - **Chaves com TTL muito baixo:** Cria√ß√£o/dele√ß√£o constante
> - **Tamanhos muito variados:** Big keys misturadas com small keys
> - **Padr√µes de acesso irregular:** Algumas √°reas "mortas" na mem√≥ria
> - **Falta de compacta√ß√£o:** Alocador n√£o consegue reorganizar
> 
> **üîß SOLU√á√ïES PARA FRAGMENTA√á√ÉO:**
> ```bash
> # Solu√ß√£o 1: Restart do Redis (mais efetiva)
> # Reorganiza toda a mem√≥ria
> 
> # Solu√ß√£o 2: Otimizar padr√µes de dados
> # - TTL mais consistente
> # - Tamanhos mais uniformes
> # - Menos cria√ß√£o/dele√ß√£o frequente
> 
> # Solu√ß√£o 3: Configurar alocador
> # - jemalloc (padr√£o, bom para fragmenta√ß√£o)
> # - libc (simples, pode fragmentar mais)
> ```
> 
> **üö® SINAIS DE ALERTA:**
> - **Fragmenta√ß√£o crescendo constantemente**
> - **Mem√≥ria RSS muito maior que mem√≥ria l√≥gica**
> - **Performance degradando sem aumento de dados**
> - **OOM errors com mem√≥ria "dispon√≠vel"**

## üõ†Ô∏è Estrat√©gias de Otimiza√ß√£o

### 1. Otimiza√ß√£o de Big Keys

```bash
# Demonstrar estrat√©gias para big keys
echo "üîß Estrat√©gias de Otimiza√ß√£o para Big Keys:"

# Estrat√©gia 1: Pagina√ß√£o de listas grandes
echo "=== Pagina√ß√£o de Lista Grande ==="
# Em vez de LRANGE 0 -1 (custoso), usar pagina√ß√£o
redis-cli -h $DATA_ENDPOINT -p 6379 --tls lrange big_list:$ID 0 99  # Primeira p√°gina
redis-cli -h $DATA_ENDPOINT -p 6379 --tls lrange big_list:$ID 100 199  # Segunda p√°gina

# Estrat√©gia 2: Usar HSCAN em vez de HGETALL
echo "=== Scan de Hash Grande ==="
redis-cli -h $DATA_ENDPOINT -p 6379 --tls hscan big_hash:$ID 0 COUNT 100
```

### 2. Otimiza√ß√£o de Hot Keys

```bash
# Estrat√©gias para hot keys
echo "üîß Estrat√©gias de Otimiza√ß√£o para Hot Keys:"

# Estrat√©gia 1: Replica√ß√£o de hot keys (simula√ß√£o)
HOT_VALUE=$($REDIS_CMD GET "hot_candidate:$ID:1")
$REDIS_CMD SET "hot_replica:$ID:1:shard1" "$HOT_VALUE"
$REDIS_CMD SET "hot_replica:$ID:1:shard2" "$HOT_VALUE"
$REDIS_CMD SET "hot_replica:$ID:1:shard3" "$HOT_VALUE"

echo "‚úÖ Hot key replicada em 3 shards para distribuir carga"
```

### 3. Configura√ß√£o de TTL Inteligente

```bash
# Configurar TTL baseado no tipo de dados
echo "üîß Configura√ß√£o de TTL Inteligente:"

# TTL baseado no tipo de dados
$REDIS_CMD SET "cache:$ID:user:1" "user data" EX 3600        # Cache de usu√°rio: 1h
$REDIS_CMD SET "session:$ID:abc123" "session data" EX 1800   # Sess√£o: 30min
$REDIS_CMD SET "temp:$ID:calc" "temp result" EX 300          # Resultado tempor√°rio: 5min

echo "‚úÖ TTL configurado baseado no tipo de dados"
```

## üí∞ Aten√ß√£o aos Custos

‚ö†Ô∏è **IMPORTANTE:** Este laborat√≥rio cria recursos AWS que geram custos na regi√£o us-east-2:

- Cache cluster: ~$0.017/hora (cache.t3.micro)
- Data transfer: M√≠nimo para este lab
- CloudWatch m√©tricas: Inclu√≠das no Free Tier

**Custo estimado por aluno:** ~$0.05 para completar o laborat√≥rio

## üßπ Limpeza de Recursos

**CR√çTICO:** Ao final do laborat√≥rio, delete seus recursos para evitar custos:

### Via Console Web:
1. **ElastiCache** > **"Caches do Redis OSS"**
   - Selecione `lab-data-$ID`
   - **Actions** > **Delete**
   - Confirme a dele√ß√£o

### Via CLI:
```bash
# Deletar replication group
aws elasticache delete-replication-group --replication-group-id lab-data-$ID --region us-east-2

# Monitorar dele√ß√£o
watch -n 30 "aws elasticache describe-replication-groups --replication-group-id lab-data-$ID --region us-east-2 2>/dev/null || echo 'Replication Group deletado com sucesso'"

# Limpar arquivos tempor√°rios
rm -f /tmp/bigkeys_analysis_$ID.txt
rm -f /tmp/monitor_output_$ID.txt
```

**NOTA:** Mantenha o Security Group para uso no pr√≥ximo laborat√≥rio.

## üìñ Recursos Adicionais

- [Redis Memory Optimization](https://redis.io/topics/memory-optimization)
- [Redis Data Types](https://redis.io/topics/data-types)
- [Redis Best Practices](https://redis.io/topics/memory-optimization)
- [ElastiCache Best Practices](https://docs.aws.amazon.com/elasticache/latest/red-ug/BestPractices.html)

## üÜò Troubleshooting

### Problemas Comuns

1. **Erro de conex√£o com redis-cli**
   - **Criptografia em tr√¢nsito habilitada:** Use `redis-cli` com `--tls`
   - **Exemplo:** `redis-cli -h $DATA_ENDPOINT -p 6379 --tls ping`
   - **Documenta√ß√£o:** [ElastiCache Encryption](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html)

2. **Big keys causando lat√™ncia**
   - Use pagina√ß√£o em vez de opera√ß√µes completas
   - Considere quebrar big keys em estruturas menores
   - Implemente TTL apropriado

3. **Hot keys sobrecarregando cluster**
   - Replique hot keys em m√∫ltiplas chaves
   - Use cache local na aplica√ß√£o
   - Considere cluster mode enabled

4. **Mem√≥ria crescendo indefinidamente**
   - Implemente TTL em todas as chaves
   - Configure pol√≠tica de eviction
   - Monitore padr√µes de crescimento

5. **Performance degradada**
   - Evite comandos KEYS em produ√ß√£o
   - Use SCAN em vez de opera√ß√µes completas
   - Otimize estruturas de dados

6. **Hit rate baixo**
   - Revise estrat√©gia de TTL
   - Analise padr√µes de acesso
   - Ajuste tamanho do cache

## üéØ Objetivos de Aprendizado Alcan√ßados

Ao final deste laborat√≥rio, voc√™ deve conseguir:

- ‚úÖ Identificar big keys usando ferramentas Redis
- ‚úÖ Detectar hot keys atrav√©s de monitoramento
- ‚úÖ Analisar padr√µes de TTL e expira√ß√£o
- ‚úÖ Correlacionar problemas de dados com performance
- ‚úÖ Implementar estrat√©gias de otimiza√ß√£o de dados
- ‚úÖ Configurar estruturas de dados eficientes
- ‚úÖ Monitorar e alertar sobre problemas de dados

## üéì **RESUMO EDUCACIONAL - O QUE APRENDEMOS**

### **üîç Big Keys - "Os Elefantes na Sala"**

**Conceito:** Chaves que ocupam muito espa√ßo ou t√™m muitos elementos.

**Por que s√£o problem√°ticas:**
- **Redis √© single-threaded:** Uma opera√ß√£o grande bloqueia todas as outras
- **Mem√≥ria limitada:** Poucas big keys podem consumir toda a RAM
- **Replica√ß√£o lenta:** Demora para sincronizar entre n√≥s

**Como identificar:**
1. **`--bigkeys`:** Scanner autom√°tico (como raio-X)
2. **`MEMORY USAGE`:** An√°lise espec√≠fica (como microsc√≥pio)
3. **Monitoramento de lat√™ncia:** Opera√ß√µes lentas indicam big keys

**Solu√ß√µes pr√°ticas:**
- **Pagina√ß√£o:** `LRANGE 0 99` em vez de `LRANGE 0 -1`
- **Campos espec√≠ficos:** `HGET campo` em vez de `HGETALL`
- **Quebrar em peda√ßos:** 1 big key ‚Üí v√°rias small keys
- **TTL adequado:** Evitar crescimento descontrolado

### **üî• Hot Keys - "As Celebridades do Redis"**

**Conceito:** Chaves acessadas com alta frequ√™ncia (poucos dados, muito acesso).

**Por que s√£o problem√°ticas:**
- **Gargalo de CPU:** 80% dos acessos em 20% das chaves
- **Distribui√ß√£o desigual:** Em clusters, alguns n√≥s ficam sobrecarregados
- **Falha em cascata:** Se hot key falha, muitas opera√ß√µes falham

**Como identificar:**
1. **`MONITOR`:** Observa√ß√£o em tempo real (como c√¢mera de seguran√ßa)
2. **An√°lise de padr√µes:** Estat√≠sticas de acesso
3. **M√©tricas de CPU:** Picos correlacionados com chaves espec√≠ficas

**Solu√ß√µes pr√°ticas:**
- **Replica√ß√£o:** M√∫ltiplas c√≥pias da hot key
- **Cache local:** Evitar acessar Redis repetidamente
- **Sharding:** Distribuir carga entre m√∫ltiplas chaves
- **Rate limiting:** Controlar frequ√™ncia de acesso

### **‚è∞ TTL - "O Lixeiro Autom√°tico"**

**Conceito:** Time To Live - tempo de vida das chaves.

**Por que √© importante:**
- **Mem√≥ria limitada:** Dados antigos ocupam espa√ßo desnecess√°rio
- **Performance:** Menos dados = opera√ß√µes mais r√°pidas
- **Consist√™ncia:** Dados expirados podem estar incorretos

**Como gerenciar:**
1. **Identificar chaves sem TTL:** `TTL chave` retorna -1
2. **Definir TTL apropriado:** Baseado no tipo de dados
3. **Monitorar expira√ß√£o:** Estat√≠sticas de expired_keys

**Estrat√©gias por tipo de dados:**
- **Cache de consultas:** 5-30 minutos
- **Sess√µes de usu√°rio:** 30 minutos - 24 horas
- **Dados tempor√°rios:** Segundos a minutos
- **Configura√ß√µes:** Horas a dias

### **üìä Estruturas Eficientes - "A Arte da Organiza√ß√£o"**

**Conceito:** Escolher a estrutura de dados certa para cada situa√ß√£o.

**Compara√ß√£o pr√°tica:**
```
Dados de usu√°rio:
‚ùå Ineficiente: 3 strings separadas (user:1:name, user:1:email, user:1:age)
‚úÖ Eficiente: 1 hash (user:1 com campos name, email, age)

Resultado: 60% menos mem√≥ria, opera√ß√µes mais r√°pidas
```

**Regras pr√°ticas:**
- **Dados relacionados:** Use hashes em vez de m√∫ltiplas strings
- **Listas grandes:** Considere pagina√ß√£o ou m√∫ltiplas listas menores
- **Contadores:** Use strings simples com INCR/DECR
- **Relacionamentos:** Use sets para membros √∫nicos

### **üõ†Ô∏è Metodologia de Troubleshooting**

**1. Diagn√≥stico (O que est√° acontecendo?)**
- Analisar uso de mem√≥ria geral
- Identificar big keys com --bigkeys
- Monitorar padr√µes de acesso

**2. An√°lise (Por que est√° acontecendo?)**
- Medir impacto na performance
- Correlacionar com m√©tricas de sistema
- Identificar padr√µes problem√°ticos

**3. Solu√ß√£o (Como resolver?)**
- Implementar otimiza√ß√µes espec√≠ficas
- Monitorar resultados
- Documentar li√ß√µes aprendidas

**4. Preven√ß√£o (Como evitar no futuro?)**
- Estabelecer pol√≠ticas de TTL
- Monitoramento proativo
- Code review focado em estruturas de dados

### **üéØ Principais Takeaways**

1. **"Measure, don't guess"** - Sempre me√ßa antes de otimizar
2. **"Small is beautiful"** - Prefira muitas chaves pequenas a poucas grandes
3. **"Everything expires"** - Todo dado deve ter TTL apropriado
4. **"Monitor continuously"** - Problemas de dados crescem com o tempo
5. **"Structure matters"** - A escolha da estrutura impacta performance e mem√≥ria

### **üö® Red Flags - Sinais de Alerta**

- **Mem√≥ria crescendo constantemente** ‚Üí Falta TTL
- **Opera√ß√µes > 10ms** ‚Üí Big keys problem√°ticas  
- **CPU alta sem carga aparente** ‚Üí Hot keys
- **Hit rate baixo** ‚Üí TTL inadequado ou dados irrelevantes
- **Poucas chaves, muita mem√≥ria** ‚Üí Big keys
- **Muitas chaves, pouca mem√≥ria** ‚Üí Overhead excessivo

**Lembre-se:** Redis √© uma ferramenta poderosa, mas como qualquer ferramenta, precisa ser usada corretamente. O troubleshooting de dados √© uma habilidade que se desenvolve com pr√°tica e experi√™ncia!

## ‚û°Ô∏è Pr√≥ximo Laborat√≥rio

Agora que voc√™ domina troubleshooting de dados, v√° para:

**[Lab 05: RedisInsight](../lab05-redisinsight/README.md)**

---

**Parab√©ns! Voc√™ completou o Lab 04! üéâ**

*Voc√™ agora possui habilidades avan√ßadas para identificar, analisar e resolver problemas relacionados a dados no ElastiCache.*