# Lab 04 - Troubleshooting de Dados

Laborat√≥rio focado na an√°lise do data plane do Redis no ElastiCache na regi√£o **us-east-2**, desenvolvendo habilidades para identificar, analisar e resolver problemas relacionados a big keys, hot keys, estruturas inadequadas e padr√µes problem√°ticos que impactam performance.

## üìã Objetivos do Laborat√≥rio

- Identificar big keys que causam bloqueios e lat√™ncia
- Detectar hot keys respons√°veis por hotspots e sobrecarga
- Analisar estruturas de dados inadequadas e ineficientes
- Diagnosticar problemas de TTL e expira√ß√£o de chaves
- Avaliar padr√µes de acesso e distribui√ß√£o de dados
- Correlacionar problemas de dados com m√©tricas de performance
- Implementar estrat√©gias de otimiza√ß√£o de dados

## ‚è±Ô∏è Dura√ß√£o Estimada: 60 minutos

## üåç Regi√£o AWS: us-east-2 (Ohio)

**IMPORTANTE:** Todos os recursos devem ser criados na regi√£o **us-east-2**. Verifique sempre a regi√£o no canto superior direito do Console AWS.

## üèóÔ∏è Estrutura do Laborat√≥rio

```
lab04-troubleshooting-dados/
‚îú‚îÄ‚îÄ README.md                    # Este guia (foco principal)
‚îú‚îÄ‚îÄ scripts/                     # Scripts de refer√™ncia (opcional)
‚îÇ   ‚îú‚îÄ‚îÄ create-data-cluster.sh
‚îÇ   ‚îú‚îÄ‚îÄ generate-big-keys.sh
‚îÇ   ‚îú‚îÄ‚îÄ simulate-hot-keys.sh
‚îÇ   ‚îú‚îÄ‚îÄ analyze-data-patterns.sh
‚îÇ   ‚îî‚îÄ‚îÄ cleanup-lab04.sh
‚îî‚îÄ‚îÄ ferramentas/                 # Ferramentas de an√°lise (opcional)
    ‚îú‚îÄ‚îÄ big-key-analyzer.py
    ‚îú‚îÄ‚îÄ hot-key-detector.sh
    ‚îî‚îÄ‚îÄ data-pattern-report.py
```

**IMPORTANTE:** Este laborat√≥rio foca na an√°lise manual via Redis CLI e ferramentas espec√≠ficas. Os scripts s√£o apenas para refer√™ncia e simula√ß√£o de cen√°rios.

## üöÄ Pr√©-requisitos

- Conta AWS ativa configurada para regi√£o **us-east-2**
- AWS CLI configurado para regi√£o us-east-2
- Acesso √† inst√¢ncia EC2 fornecida pelo instrutor (Bastion Host)
- Redis CLI instalado e funcional
- Conhecimento b√°sico de estruturas de dados Redis
- **ID do Aluno:** Voc√™ deve usar seu ID √∫nico (ex: aluno01, aluno02, etc.)
- **Labs anteriores:** VPC, Subnet Group e Security Group j√° criados

## üè∑Ô∏è Conven√ß√£o de Nomenclatura

Todos os recursos criados devem seguir o padr√£o:
- **Cluster de Dados:** `lab-data-$ID`
- **Security Groups:** Reutilizar `elasticache-lab-sg-$ID` dos labs anteriores

**Exemplo para aluno01:**
- Cluster: `lab-data-aluno01`
- Security Group: `elasticache-lab-sg-aluno01` (j√° existente)

## üìö Exerc√≠cios

### Exerc√≠cio 1: Preparar Ambiente com Dados Diversos (15 minutos)

**Objetivo:** Criar cluster e popular com diferentes tipos e tamanhos de dados

#### Passo 1: Verificar Pr√©-requisitos

```bash
# Verificar Security Group dos labs anteriores
aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$ID" --region us-east-2
```

#### Passo 2: Criar Cluster de Dados via Console Web

1. Acesse **ElastiCache** no Console AWS
2. Na p√°gina inicial, selecione **"Caches do Redis OSS"** ‚Üê **IMPORTANTE**
3. Selecione **"Cache de cluster"** (n√£o serverless)
4. Selecione **"Cache de cluster"** (configura√ß√£o manual, n√£o cria√ß√£o f√°cil)
5. Configure:
   - **Cluster mode:** Disabled
   - **Cluster info:**
     - **Name:** `lab-data-$ID`
     - **Description:** `Lab data troubleshooting cluster for $ID`
   - **Location:**
     - **AWS Cloud**
     - **Multi-AZ:** Disabled (para este lab)
     - **Failover autom√°tico:** Desabilitado (n√£o aplic√°vel sem r√©plicas)
   - **Cluster settings:**
     - **Engine version:** 7.0
     - **Port:** 6379
     - **Node type:** **cache.t3.micro** (para demonstrar limita√ß√µes)
     - **Number of replicas:** 0
   - **Connectivity:**
     - **Network type:** IPv4
     - **Subnet group:** `elasticache-lab-subnet-group`
     - **Security groups:** Selecione seu SG `elasticache-lab-sg-$ID`
   - **Security (Seguran√ßa):**
     - **Criptografia em repouso:** Habilitada (recomendado)
     - **Chave de criptografia:** Chave padr√£o (AWS managed)
     - **Criptografia em tr√¢nsito:** Habilitada (recomendado)
     - **Controle de acesso:** Nenhum controle de acesso (para simplicidade do lab)
   - **Backup:**
     - **Enable automatic backups:** Enabled
   - **Maintenance:**
     - **Auto minor version upgrade:** Enabled
   - **Advanced settings:**
     - **Tags (Recomendado):**
       - **Key:** `Name` **Value:** `Lab Data - $ID`
       - **Key:** `Lab` **Value:** `Lab04`
       - **Key:** `Purpose` **Value:** `Data-Analysis`

6. Clique em **Create**

> **üìö Para saber mais sobre seguran√ßa:**
> - [Criptografia no ElastiCache](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html)
> - [Configura√ß√µes de seguran√ßa](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth.html)

#### Alternativa: Cria√ß√£o R√°pida via CLI

Para acelerar o processo, voc√™ pode criar o cluster via CLI:

```bash
# Obter IDs necess√°rios
VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=ElastiCache-Lab-VPC" --query 'Vpcs[0].VpcId' --output text --region us-east-2)
SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$ID" --query 'SecurityGroups[0].GroupId' --output text --region us-east-2)

# Criar cluster com todas as configura√ß√µes
aws elasticache create-cache-cluster \
    --cache-cluster-id "lab-data-$ID" \
    --cache-node-type cache.t3.micro \
    --engine redis \
    --engine-version 7.0 \
    --port 6379 \
    --num-cache-nodes 1 \
    --cache-subnet-group-name elasticache-lab-subnet-group \
    --security-group-ids $SG_ID \
    --auto-minor-version-upgrade \
    --tags Key=Name,Value="Lab Data - $ID" Key=Lab,Value=Lab04 Key=Purpose,Value=Data-Analysis \
    --region us-east-2

echo "‚úÖ Cluster criado via CLI! Aguarde ~10-15 minutos para ficar dispon√≠vel."
echo "‚ö†Ô∏è  Nota: Para criptografia em clusters simples, configure via Parameter Groups ou use Replication Groups."
```

#### Passo 3: Aguardar Cria√ß√£o e Obter Endpoint

```bash
# Monitorar cria√ß√£o
watch -n 30 "aws elasticache describe-cache-clusters --cache-cluster-id lab-data-$ID --query 'CacheClusters[0].CacheClusterStatus' --output text --region us-east-2"

# Quando dispon√≠vel, obter endpoint
DATA_ENDPOINT=$(aws elasticache describe-cache-clusters --cache-cluster-id lab-data-$ID --show-cache-node-info --query 'CacheClusters[0].CacheNodes[0].Endpoint.Address' --output text --region us-east-2)
echo "Data Cluster Endpoint: $DATA_ENDPOINT"
```

#### Passo 4: Popular com Dados Diversos

```bash
# Testar conectividade
redis-cli -h $DATA_ENDPOINT -p 6379 ping

# Se houver erro de conex√£o devido √† criptografia, tente com TLS:
redis-cli -h $DATA_ENDPOINT -p 6379 --tls ping

# Popular com diferentes tipos de dados
echo "üìä Populando cluster com dados diversos..."

redis-cli -h $DATA_ENDPOINT -p 6379 << EOF
# Limpar dados existentes
FLUSHALL

# === DADOS PEQUENOS (baseline) ===
$(for i in {1..1000}; do echo "SET small:$ID:$i value$i"; done)

# === STRINGS GRANDES (big keys potenciais) ===
SET big_string:$ID:1mb "$(printf 'A%.0s' {1..1048576})"
SET big_string:$ID:500kb "$(printf 'B%.0s' {1..512000})"
SET big_string:$ID:100kb "$(printf 'C%.0s' {1..102400})"

# === LISTAS GRANDES ===
$(for i in {1..10000}; do echo "LPUSH big_list:$ID item$i"; done)

# === HASHES GRANDES ===
$(for i in {1..5000}; do echo "HSET big_hash:$ID field$i value$i"; done)

# === SETS GRANDES ===
$(for i in {1..3000}; do echo "SADD big_set:$ID member$i"; done)

# === SORTED SETS GRANDES ===
$(for i in {1..2000}; do echo "ZADD big_zset:$ID $i member$i"; done)

# === DADOS COM TTL VARIADO ===
SET ttl_short:$ID:1 "expires in 60s" EX 60
SET ttl_medium:$ID:1 "expires in 300s" EX 300
SET ttl_long:$ID:1 "expires in 3600s" EX 3600
SET no_ttl:$ID:1 "never expires"

# === DADOS PARA HOT KEYS ===
$(for i in {1..100}; do echo "SET hot_candidate:$ID:$i hotvalue$i"; done)

# === ESTRUTURAS ANINHADAS (JSON-like) ===
SET json_data:$ID:user1 '{"id":1,"name":"Jo√£o Silva","email":"joao@example.com","preferences":{"theme":"dark","notifications":true},"history":[1,2,3,4,5]}'
SET json_data:$ID:user2 '{"id":2,"name":"Maria Santos","email":"maria@example.com","preferences":{"theme":"light","notifications":false},"history":[6,7,8,9,10]}'

# === DADOS DE SESS√ÉO ===
$(for i in {1..200}; do echo "HSET session:$ID:$i user_id $i login_time $(date +%s) ip 192.168.1.$((i%255))"; done)

EOF

echo "‚úÖ Dados diversos inseridos no cluster"
```

**‚úÖ Checkpoint:** Cluster deve estar populado com dados de diferentes tipos e tamanhos.

---

### Exerc√≠cio 2: Identificar Big Keys (15 minutos)

**Objetivo:** Usar ferramentas Redis para identificar chaves que consomem muita mem√≥ria

#### Passo 1: An√°lise B√°sica de Mem√≥ria

```bash
# Verificar uso total de mem√≥ria
echo "üîç Analisando uso de mem√≥ria..."
redis-cli -h $DATA_ENDPOINT -p 6379 info memory | grep -E "(used_memory|used_memory_human|used_memory_peak)"

# Contar total de chaves
TOTAL_KEYS=$(redis-cli -h $DATA_ENDPOINT -p 6379 dbsize)
echo "Total de chaves: $TOTAL_KEYS"
```

#### Passo 2: Usar --bigkeys para Identificar Big Keys

```bash
# Executar an√°lise de big keys (pode demorar alguns minutos)
echo "üîç Executando an√°lise de big keys..."
redis-cli -h $DATA_ENDPOINT -p 6379 --bigkeys

# Salvar resultado em arquivo para an√°lise
redis-cli -h $DATA_ENDPOINT -p 6379 --bigkeys > /tmp/bigkeys_analysis_$ID.txt
echo "üìÑ Resultado salvo em /tmp/bigkeys_analysis_$ID.txt"
```

#### Passo 3: An√°lise Manual de Chaves Espec√≠ficas

```bash
# Analisar uso de mem√≥ria de chaves espec√≠ficas
echo "üîç Analisando chaves espec√≠ficas..."

# Verificar tamanho das big strings
echo "=== Big Strings ==="
redis-cli -h $DATA_ENDPOINT -p 6379 memory usage big_string:$ID:1mb
redis-cli -h $DATA_ENDPOINT -p 6379 memory usage big_string:$ID:500kb
redis-cli -h $DATA_ENDPOINT -p 6379 memory usage big_string:$ID:100kb

# Verificar tamanho das estruturas grandes
echo "=== Big Structures ==="
redis-cli -h $DATA_ENDPOINT -p 6379 memory usage big_list:$ID
redis-cli -h $DATA_ENDPOINT -p 6379 memory usage big_hash:$ID
redis-cli -h $DATA_ENDPOINT -p 6379 memory usage big_set:$ID
redis-cli -h $DATA_ENDPOINT -p 6379 memory usage big_zset:$ID

# Verificar n√∫mero de elementos
echo "=== Contagem de Elementos ==="
echo "Lista: $(redis-cli -h $DATA_ENDPOINT -p 6379 llen big_list:$ID) elementos"
echo "Hash: $(redis-cli -h $DATA_ENDPOINT -p 6379 hlen big_hash:$ID) campos"
echo "Set: $(redis-cli -h $DATA_ENDPOINT -p 6379 scard big_set:$ID) membros"
echo "Sorted Set: $(redis-cli -h $DATA_ENDPOINT -p 6379 zcard big_zset:$ID) membros"
```

#### Passo 4: Impacto de Big Keys na Performance

```bash
# Testar impacto de opera√ß√µes em big keys
echo "üß™ Testando impacto de big keys na performance..."

# Opera√ß√£o custosa: obter lista completa (MUITO CUSTOSO)
echo "Testando LRANGE em big_list..."
START_TIME=$(date +%s%N)
redis-cli -h $DATA_ENDPOINT -p 6379 lrange big_list:$ID 0 -1 > /dev/null
END_TIME=$(date +%s%N)
LRANGE_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "LRANGE completo: ${LRANGE_TIME}ms"

# Opera√ß√£o custosa: obter hash completo
echo "Testando HGETALL em big_hash..."
START_TIME=$(date +%s%N)
redis-cli -h $DATA_ENDPOINT -p 6379 hgetall big_hash:$ID > /dev/null
END_TIME=$(date +%s%N)
HGETALL_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "HGETALL completo: ${HGETALL_TIME}ms"

# Comparar com opera√ß√£o simples
echo "Testando GET em chave pequena..."
START_TIME=$(date +%s%N)
redis-cli -h $DATA_ENDPOINT -p 6379 get small:$ID:1 > /dev/null
END_TIME=$(date +%s%N)
GET_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
echo "GET simples: ${GET_TIME}ms"

echo ""
echo "üìä Compara√ß√£o de Performance:"
echo "GET simples: ${GET_TIME}ms"
echo "LRANGE big_list: ${LRANGE_TIME}ms ($(( LRANGE_TIME / GET_TIME ))x mais lento)"
echo "HGETALL big_hash: ${HGETALL_TIME}ms ($(( HGETALL_TIME / GET_TIME ))x mais lento)"
```

**Sinais de Big Keys Problem√°ticos:**
- ‚úÖ Chaves > 100KB (strings) ou > 1000 elementos (estruturas)
- ‚úÖ Opera√ß√µes que demoram > 10ms
- ‚úÖ Uso desproporcional de mem√≥ria
- ‚úÖ Bloqueio de outras opera√ß√µes

**‚úÖ Checkpoint:** Identificar quais s√£o as maiores chaves e seu impacto.

---

### Exerc√≠cio 3: Detectar Hot Keys (15 minutos)

**Objetivo:** Identificar chaves acessadas com alta frequ√™ncia

#### Passo 1: Configurar Monitoramento de Hot Keys

```bash
# Verificar se hot key tracking est√° habilitado
echo "üîç Verificando configura√ß√£o de hot key tracking..."
redis-cli -h $DATA_ENDPOINT -p 6379 config get "*hotkeys*"

# Habilitar tracking de hot keys (se n√£o estiver habilitado)
redis-cli -h $DATA_ENDPOINT -p 6379 config set latency-tracking yes
```

#### Passo 2: Simular Acesso a Hot Keys

```bash
# Simular padr√£o de hot keys
echo "üß™ Simulando padr√£o de acesso a hot keys..."

# Fun√ß√£o para simular carga concentrada
simulate_hot_keys() {
    local endpoint=$1
    local student_id=$2
    local duration=60  # 1 minuto de simula√ß√£o
    local end_time=$(($(date +%s) + duration))
    
    echo "Simulando hot keys por $duration segundos..."
    
    while [ $(date +%s) -lt $end_time ]; do
        # 80% dos acessos v√£o para apenas 3 chaves (hot keys)
        for i in {1..8}; do
            redis-cli -h $endpoint -p 6379 get hot_candidate:$student_id:1 > /dev/null &
            redis-cli -h $endpoint -p 6379 get hot_candidate:$student_id:2 > /dev/null &
            redis-cli -h $endpoint -p 6379 get hot_candidate:$student_id:3 > /dev/null &
        done
        
        # 20% dos acessos distribu√≠dos entre outras chaves
        for i in {1..2}; do
            RANDOM_KEY=$((RANDOM % 100 + 4))
            redis-cli -h $endpoint -p 6379 get hot_candidate:$student_id:$RANDOM_KEY > /dev/null &
        done
        
        sleep 0.1
        wait  # Aguardar todos os processos background
    done
}

# Executar simula√ß√£o em background
simulate_hot_keys $DATA_ENDPOINT $ID &
SIMULATION_PID=$!

echo "üîç Simula√ß√£o iniciada (PID: $SIMULATION_PID)"
echo "Aguarde 60 segundos para coleta de dados..."
```

#### Passo 3: Monitorar Hot Keys em Tempo Real

```bash
# Usar MONITOR para observar comandos (cuidado: muito verboso)
echo "üîç Iniciando monitoramento de comandos por 30 segundos..."
timeout 30 redis-cli -h $DATA_ENDPOINT -p 6379 monitor | grep "hot_candidate:$ID" > /tmp/monitor_output_$ID.txt &

# Aguardar coleta de dados
sleep 35

# Parar simula√ß√£o
kill $SIMULATION_PID 2>/dev/null || true
wait $SIMULATION_PID 2>/dev/null || true

echo "‚úÖ Simula√ß√£o conclu√≠da"
```

#### Passo 4: Analisar Padr√µes de Acesso

```bash
# Analisar dados coletados
echo "üìä Analisando padr√µes de acesso..."

if [ -f /tmp/monitor_output_$ID.txt ]; then
    echo "=== Top 10 Chaves Mais Acessadas ==="
    grep -o "hot_candidate:$ID:[0-9]*" /tmp/monitor_output_$ID.txt | sort | uniq -c | sort -nr | head -10
    
    echo ""
    echo "=== Estat√≠sticas de Acesso ==="
    TOTAL_ACCESSES=$(wc -l < /tmp/monitor_output_$ID.txt)
    TOP_3_ACCESSES=$(grep -o "hot_candidate:$ID:[1-3]" /tmp/monitor_output_$ID.txt | wc -l)
    HOT_PERCENTAGE=$(( TOP_3_ACCESSES * 100 / TOTAL_ACCESSES ))
    
    echo "Total de acessos: $TOTAL_ACCESSES"
    echo "Acessos √†s top 3 chaves: $TOP_3_ACCESSES"
    echo "Percentual de hot keys: ${HOT_PERCENTAGE}%"
else
    echo "‚ö†Ô∏è  Arquivo de monitoramento n√£o encontrado"
fi
```

#### Passo 5: Usar Ferramentas de An√°lise de Lat√™ncia

```bash
# Verificar lat√™ncia de comandos
echo "üìà Analisando lat√™ncia de comandos..."

# Verificar slow log
echo "=== Slow Log ==="
redis-cli -h $DATA_ENDPOINT -p 6379 slowlog get 10

# Verificar estat√≠sticas de comandos
echo "=== Command Stats ==="
redis-cli -h $DATA_ENDPOINT -p 6379 info commandstats | head -10

# Testar lat√™ncia espec√≠fica das hot keys
echo "=== Lat√™ncia das Hot Keys ==="
for key in 1 2 3; do
    echo "Testando hot_candidate:$ID:$key"
    redis-cli -h $DATA_ENDPOINT -p 6379 --latency-history -i 1 get hot_candidate:$ID:$key | head -5 &
    sleep 2
    kill $! 2>/dev/null || true
done
```

**Sinais de Hot Keys Problem√°ticos:**
- ‚úÖ Poucas chaves recebem > 80% dos acessos
- ‚úÖ Lat√™ncia aumenta durante picos de acesso
- ‚úÖ CPU alta sem distribui√ß√£o uniforme de carga
- ‚úÖ Gargalo em single-threaded operations

**‚úÖ Checkpoint:** Identificar padr√µes de hot keys e seu impacto na performance.

---

### Exerc√≠cio 4: Analisar Padr√µes de TTL e Expira√ß√£o (15 minutos)

**Objetivo:** Identificar problemas relacionados a TTL e gerenciamento de expira√ß√£o

#### Passo 1: Analisar TTL das Chaves Existentes

```bash
# Verificar TTL de diferentes tipos de chaves
echo "üîç Analisando TTL das chaves..."

echo "=== TTL das Chaves de Teste ==="
redis-cli -h $DATA_ENDPOINT -p 6379 ttl ttl_short:$ID:1
redis-cli -h $DATA_ENDPOINT -p 6379 ttl ttl_medium:$ID:1
redis-cli -h $DATA_ENDPOINT -p 6379 ttl ttl_long:$ID:1
redis-cli -h $DATA_ENDPOINT -p 6379 ttl no_ttl:$ID:1

echo ""
echo "=== TTL das Big Keys ==="
redis-cli -h $DATA_ENDPOINT -p 6379 ttl big_string:$ID:1mb
redis-cli -h $DATA_ENDPOINT -p 6379 ttl big_list:$ID
redis-cli -h $DATA_ENDPOINT -p 6379 ttl big_hash:$ID
```

#### Passo 2: Identificar Chaves sem TTL

```bash
# Encontrar chaves sem TTL (TTL = -1)
echo "üîç Identificando chaves sem TTL..."

# Fun√ß√£o para verificar TTL de m√∫ltiplas chaves
check_ttl_patterns() {
    local pattern=$1
    echo "Verificando padr√£o: $pattern"
    
    # Usar SCAN para evitar KEYS (mais seguro)
    redis-cli -h $DATA_ENDPOINT -p 6379 --scan --pattern "$pattern" | while read key; do
        TTL=$(redis-cli -h $DATA_ENDPOINT -p 6379 ttl "$key")
        if [ "$TTL" = "-1" ]; then
            SIZE=$(redis-cli -h $DATA_ENDPOINT -p 6379 memory usage "$key" 2>/dev/null || echo "N/A")
            echo "  $key: sem TTL, tamanho: $SIZE bytes"
        fi
    done
}

# Verificar diferentes padr√µes
check_ttl_patterns "big_*:$ID*"
check_ttl_patterns "session:$ID:*"
check_ttl_patterns "small:$ID:*"
```

#### Passo 3: Simular Problema de Expira√ß√£o

```bash
# Criar chaves com TTL muito baixo para demonstrar problema
echo "üß™ Simulando problema de expira√ß√£o..."

# Criar muitas chaves com TTL baixo
redis-cli -h $DATA_ENDPOINT -p 6379 << EOF
$(for i in {1..1000}; do echo "SET expire_test:$ID:$i value$i EX 30"; done)
EOF

echo "‚úÖ Criadas 1000 chaves com TTL de 30 segundos"

# Monitorar estat√≠sticas de expira√ß√£o
echo "üìä Monitorando estat√≠sticas de expira√ß√£o..."
for i in {1..6}; do
    echo "=== Verifica√ß√£o $i ($(date '+%H:%M:%S')) ==="
    
    # Estat√≠sticas de expira√ß√£o
    redis-cli -h $DATA_ENDPOINT -p 6379 info stats | grep -E "(expired_keys|evicted_keys)"
    
    # Contar chaves restantes
    REMAINING=$(redis-cli -h $DATA_ENDPOINT -p 6379 eval "return #redis.call('keys', 'expire_test:$ID:*')" 0)
    echo "Chaves restantes: $REMAINING"
    
    sleep 10
done
```

#### Passo 4: Analisar Impacto de Expira√ß√£o na Performance

```bash
# Verificar configura√ß√£o de expira√ß√£o
echo "üîç Analisando configura√ß√£o de expira√ß√£o..."

redis-cli -h $DATA_ENDPOINT -p 6379 config get "*expire*"
redis-cli -h $DATA_ENDPOINT -p 6379 config get "*hz*"

# Verificar estat√≠sticas detalhadas
echo "üìà Estat√≠sticas de expira√ß√£o e eviction:"
redis-cli -h $DATA_ENDPOINT -p 6379 info stats | grep -E "(expired_keys|evicted_keys|keyspace_hits|keyspace_misses)"

# Calcular hit rate
HITS=$(redis-cli -h $DATA_ENDPOINT -p 6379 info stats | grep keyspace_hits | cut -d: -f2 | tr -d '\r')
MISSES=$(redis-cli -h $DATA_ENDPOINT -p 6379 info stats | grep keyspace_misses | cut -d: -f2 | tr -d '\r')
TOTAL=$((HITS + MISSES))
if [ $TOTAL -gt 0 ]; then
    HIT_RATE=$(( HITS * 100 / TOTAL ))
    echo "Hit Rate: ${HIT_RATE}% ($HITS hits, $MISSES misses)"
else
    echo "Hit Rate: N/A (sem estat√≠sticas suficientes)"
fi
```

**Problemas Comuns de TTL:**
- ‚úÖ Big keys sem TTL (consomem mem√≥ria indefinidamente)
- ‚úÖ TTL muito baixo (overhead de expira√ß√£o)
- ‚úÖ TTL inconsistente (alguns dados expiram, outros n√£o)
- ‚úÖ Falta de estrat√©gia de eviction

**‚úÖ Checkpoint:** Identificar problemas de TTL e estrat√©gias de expira√ß√£o.

---

## üîç An√°lise Avan√ßada de Padr√µes de Dados

### Identifica√ß√£o de Padr√µes Problem√°ticos

#### 1. Big Keys Problem√°ticos
```bash
# Identificar big keys por tipo
echo "üìä An√°lise de Big Keys por Tipo:"

# Strings grandes
redis-cli -h $DATA_ENDPOINT -p 6379 --scan --pattern "*" | while read key; do
    TYPE=$(redis-cli -h $DATA_ENDPOINT -p 6379 type "$key")
    if [ "$TYPE" = "string" ]; then
        SIZE=$(redis-cli -h $DATA_ENDPOINT -p 6379 memory usage "$key" 2>/dev/null)
        if [ "$SIZE" -gt 10240 ]; then  # > 10KB
            echo "Big String: $key ($SIZE bytes)"
        fi
    fi
done | head -10
```

#### 2. Estruturas Ineficientes
```bash
# Analisar efici√™ncia de estruturas
echo "üìä An√°lise de Efici√™ncia de Estruturas:"

# Hash vs m√∫ltiplas strings
echo "=== Compara√ß√£o Hash vs Strings ==="
# Criar dados equivalentes
redis-cli -h $DATA_ENDPOINT -p 6379 << EOF
# Usando Hash (eficiente)
HSET user_hash:$ID:1 name "Jo√£o" email "joao@test.com" age "30"

# Usando m√∫ltiplas strings (ineficiente)
SET user_string:$ID:1:name "Jo√£o"
SET user_string:$ID:1:email "joao@test.com"
SET user_string:$ID:1:age "30"
EOF

# Comparar uso de mem√≥ria
HASH_SIZE=$(redis-cli -h $DATA_ENDPOINT -p 6379 memory usage user_hash:$ID:1)
STRING1_SIZE=$(redis-cli -h $DATA_ENDPOINT -p 6379 memory usage user_string:$ID:1:name)
STRING2_SIZE=$(redis-cli -h $DATA_ENDPOINT -p 6379 memory usage user_string:$ID:1:email)
STRING3_SIZE=$(redis-cli -h $DATA_ENDPOINT -p 6379 memory usage user_string:$ID:1:age)
STRINGS_TOTAL=$((STRING1_SIZE + STRING2_SIZE + STRING3_SIZE))

echo "Hash: $HASH_SIZE bytes"
echo "Strings: $STRINGS_TOTAL bytes"
echo "Economia com Hash: $((STRINGS_TOTAL - HASH_SIZE)) bytes ($(( (STRINGS_TOTAL - HASH_SIZE) * 100 / STRINGS_TOTAL ))%)"
```

#### 3. An√°lise de Fragmenta√ß√£o

```bash
# Verificar fragmenta√ß√£o de mem√≥ria
echo "üìä An√°lise de Fragmenta√ß√£o:"
redis-cli -h $DATA_ENDPOINT -p 6379 info memory | grep -E "(mem_fragmentation|mem_allocator)"

# Verificar estat√≠sticas de aloca√ß√£o
redis-cli -h $DATA_ENDPOINT -p 6379 memory stats
```

## üõ†Ô∏è Estrat√©gias de Otimiza√ß√£o

### 1. Otimiza√ß√£o de Big Keys

```bash
# Demonstrar estrat√©gias para big keys
echo "üîß Estrat√©gias de Otimiza√ß√£o para Big Keys:"

# Estrat√©gia 1: Pagina√ß√£o de listas grandes
echo "=== Pagina√ß√£o de Lista Grande ==="
# Em vez de LRANGE 0 -1 (custoso), usar pagina√ß√£o
redis-cli -h $DATA_ENDPOINT -p 6379 lrange big_list:$ID 0 99  # Primeira p√°gina
redis-cli -h $DATA_ENDPOINT -p 6379 lrange big_list:$ID 100 199  # Segunda p√°gina

# Estrat√©gia 2: Usar HSCAN em vez de HGETALL
echo "=== Scan de Hash Grande ==="
redis-cli -h $DATA_ENDPOINT -p 6379 hscan big_hash:$ID 0 COUNT 100
```

### 2. Otimiza√ß√£o de Hot Keys

```bash
# Estrat√©gias para hot keys
echo "üîß Estrat√©gias de Otimiza√ß√£o para Hot Keys:"

# Estrat√©gia 1: Replica√ß√£o de hot keys (simula√ß√£o)
redis-cli -h $DATA_ENDPOINT -p 6379 << EOF
# Replicar hot key em m√∫ltiplas chaves
SET hot_replica:$ID:1:shard1 "$(redis-cli -h $DATA_ENDPOINT -p 6379 get hot_candidate:$ID:1)"
SET hot_replica:$ID:1:shard2 "$(redis-cli -h $DATA_ENDPOINT -p 6379 get hot_candidate:$ID:1)"
SET hot_replica:$ID:1:shard3 "$(redis-cli -h $DATA_ENDPOINT -p 6379 get hot_candidate:$ID:1)"
EOF

echo "‚úÖ Hot key replicada em 3 shards para distribuir carga"
```

### 3. Configura√ß√£o de TTL Inteligente

```bash
# Configurar TTL baseado no tipo de dados
echo "üîß Configura√ß√£o de TTL Inteligente:"

redis-cli -h $DATA_ENDPOINT -p 6379 << EOF
# TTL baseado no tipo de dados
SET cache:$ID:user:1 "user data" EX 3600        # Cache de usu√°rio: 1h
SET session:$ID:abc123 "session data" EX 1800   # Sess√£o: 30min
SET temp:$ID:calc "temp result" EX 300          # Resultado tempor√°rio: 5min
EOF

echo "‚úÖ TTL configurado baseado no tipo de dados"
```

## üí∞ Aten√ß√£o aos Custos

‚ö†Ô∏è **IMPORTANTE:** Este laborat√≥rio cria recursos AWS que geram custos na regi√£o us-east-2:

- Cache cluster: ~$0.017/hora (cache.t3.micro)
- Data transfer: M√≠nimo para este lab
- CloudWatch m√©tricas: Inclu√≠das no Free Tier

**Custo estimado por aluno:** ~$0.05 para completar o laborat√≥rio

## üßπ Limpeza de Recursos

**CR√çTICO:** Ao final do laborat√≥rio, delete seus recursos para evitar custos:

### Via Console Web:
1. **ElastiCache** > **"Caches do Redis OSS"**
   - Selecione `lab-data-$ID`
   - **Actions** > **Delete**
   - Confirme a dele√ß√£o

### Via CLI:
```bash
# Deletar cluster de dados
aws elasticache delete-cache-cluster --cache-cluster-id lab-data-$ID --region us-east-2

# Monitorar dele√ß√£o
watch -n 30 "aws elasticache describe-cache-clusters --cache-cluster-id lab-data-$ID --region us-east-2 2>/dev/null || echo 'Cluster deletado com sucesso'"

# Limpar arquivos tempor√°rios
rm -f /tmp/bigkeys_analysis_$ID.txt
rm -f /tmp/monitor_output_$ID.txt
```

**NOTA:** Mantenha o Security Group para uso no pr√≥ximo laborat√≥rio.

## üìñ Recursos Adicionais

- [Redis Memory Optimization](https://redis.io/topics/memory-optimization)
- [Redis Data Types](https://redis.io/topics/data-types)
- [Redis Best Practices](https://redis.io/topics/memory-optimization)
- [ElastiCache Best Practices](https://docs.aws.amazon.com/elasticache/latest/red-ug/BestPractices.html)

## üÜò Troubleshooting

### Problemas Comuns

1. **Erro de conex√£o com redis-cli**
   - **Criptografia em tr√¢nsito habilitada:** Use `redis-cli` com `--tls`
   - **Exemplo:** `redis-cli -h $DATA_ENDPOINT -p 6379 --tls ping`
   - **Documenta√ß√£o:** [ElastiCache Encryption](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html)

2. **Big keys causando lat√™ncia**
   - Use pagina√ß√£o em vez de opera√ß√µes completas
   - Considere quebrar big keys em estruturas menores
   - Implemente TTL apropriado

3. **Hot keys sobrecarregando cluster**
   - Replique hot keys em m√∫ltiplas chaves
   - Use cache local na aplica√ß√£o
   - Considere cluster mode enabled

4. **Mem√≥ria crescendo indefinidamente**
   - Implemente TTL em todas as chaves
   - Configure pol√≠tica de eviction
   - Monitore padr√µes de crescimento

5. **Performance degradada**
   - Evite comandos KEYS em produ√ß√£o
   - Use SCAN em vez de opera√ß√µes completas
   - Otimize estruturas de dados

6. **Hit rate baixo**
   - Revise estrat√©gia de TTL
   - Analise padr√µes de acesso
   - Ajuste tamanho do cache

## üéØ Objetivos de Aprendizado Alcan√ßados

Ao final deste laborat√≥rio, voc√™ deve conseguir:

- ‚úÖ Identificar big keys usando ferramentas Redis
- ‚úÖ Detectar hot keys atrav√©s de monitoramento
- ‚úÖ Analisar padr√µes de TTL e expira√ß√£o
- ‚úÖ Correlacionar problemas de dados com performance
- ‚úÖ Implementar estrat√©gias de otimiza√ß√£o de dados
- ‚úÖ Configurar estruturas de dados eficientes
- ‚úÖ Monitorar e alertar sobre problemas de dados

## üìù Notas Importantes

- **Big keys** (>100KB ou >1000 elementos) podem bloquear opera√ß√µes
- **Hot keys** concentram carga e criam gargalos
- **TTL inadequado** causa crescimento descontrolado de mem√≥ria
- **Estruturas ineficientes** desperdi√ßam recursos
- **Comandos KEYS** devem ser evitados em produ√ß√£o
- **Pagina√ß√£o** √© essencial para big keys
- **Monitoramento cont√≠nuo** previne problemas de dados

## ‚û°Ô∏è Pr√≥ximo Laborat√≥rio

Agora que voc√™ domina troubleshooting de dados, v√° para:

**[Lab 05: RedisInsight](../lab05-redisinsight/README.md)**

---

**Parab√©ns! Voc√™ completou o Lab 04! üéâ**

*Voc√™ agora possui habilidades avan√ßadas para identificar, analisar e resolver problemas relacionados a dados no ElastiCache.*