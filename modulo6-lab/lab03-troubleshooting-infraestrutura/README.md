# Lab 03 - Troubleshooting de Infraestrutura

Laborat√≥rio focado no diagn√≥stico estruturado de problemas de infraestrutura no ElastiCache na regi√£o **us-east-2**, desenvolvendo habilidades para identificar, analisar e resolver problemas de conectividade, CPU, mem√≥ria e rede antes que impactem a aplica√ß√£o.

## üìã Objetivos do Laborat√≥rio

- Diagnosticar problemas de conectividade (Security Groups, rede, DNS)
- Analisar m√©tricas de CPU e identificar gargalos de processamento
- Identificar press√£o de mem√≥ria e uso inadequado de swap
- Correlacionar m√©tricas CloudWatch com sintomas da aplica√ß√£o
- Desenvolver metodologia estruturada de troubleshooting
- Simular cen√°rios reais de problemas de infraestrutura

## ‚è±Ô∏è Dura√ß√£o Estimada: 60 minutos

## üåç Regi√£o AWS: us-east-2 (Ohio)

**IMPORTANTE:** Todos os recursos devem ser criados na regi√£o **us-east-2**. Verifique sempre a regi√£o no canto superior direito do Console AWS.

## üèóÔ∏è Estrutura do Laborat√≥rio

```
lab03-troubleshooting-infraestrutura/
‚îú‚îÄ‚îÄ README.md                    # Este guia (foco principal)
‚îú‚îÄ‚îÄ scripts/                     # Scripts de refer√™ncia (opcional)
‚îÇ   ‚îú‚îÄ‚îÄ create-test-cluster.sh
‚îÇ   ‚îú‚îÄ‚îÄ simulate-cpu-load.sh
‚îÇ   ‚îú‚îÄ‚îÄ simulate-memory-pressure.sh
‚îÇ   ‚îú‚îÄ‚îÄ test-connectivity.sh
‚îÇ   ‚îî‚îÄ‚îÄ cleanup-lab03.sh
‚îî‚îÄ‚îÄ metricas/                    # Dashboards e queries (opcional)
    ‚îú‚îÄ‚îÄ cloudwatch-dashboard.json
    ‚îî‚îÄ‚îÄ useful-queries.md
```

**IMPORTANTE:** Este laborat√≥rio foca na an√°lise manual via Console Web e CLI. Os scripts s√£o apenas para refer√™ncia e simula√ß√£o de problemas.

## üöÄ Pr√©-requisitos

- Conta AWS ativa configurada para regi√£o **us-east-2**
- AWS CLI configurado para regi√£o us-east-2
- Acesso √† inst√¢ncia EC2 fornecida pelo instrutor (Bastion Host)
- Redis CLI instalado e funcional
- Conhecimento b√°sico de m√©tricas CloudWatch
- **ID do Aluno:** Voc√™ deve usar seu ID √∫nico (ex: aluno01, aluno02, etc.)
- **Labs anteriores:** VPC, Subnet Group e Security Group j√° criados

## üè∑Ô∏è Conven√ß√£o de Nomenclatura

Todos os recursos criados devem seguir o padr√£o:
- **Cluster de Teste:** `lab-troubleshoot-$ID`
- **Security Groups:** Reutilizar `elasticache-lab-sg-$ID` dos labs anteriores

**Exemplo para aluno01:**
- Cluster: `lab-troubleshoot-aluno01`
- Security Group: `elasticache-lab-sg-aluno01` (j√° existente)

## üìö Exerc√≠cios

### Exerc√≠cio 1: Preparar Ambiente de Teste (15 minutos)

**Objetivo:** Criar cluster para simular problemas de infraestrutura

#### Passo 1: Verificar Pr√©-requisitos

```bash
# Verificar Security Group dos labs anteriores
aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$ID" --region us-east-2
```

#### Passo 2: Criar Cluster de Teste via Console Web

1. Acesse **ElastiCache** no Console AWS
2. Na p√°gina inicial, selecione **"Caches do Redis OSS"** ‚Üê **IMPORTANTE**
3. Selecione **"Cache de cluster"** (n√£o serverless)
4. Selecione **"Cache de cluster"** (configura√ß√£o manual, n√£o cria√ß√£o f√°cil)
5. Configure:
   - **Cluster mode:** Disabled (para simplicidade)
   - **Cluster info:**
     - **Name:** `lab-troubleshoot-$ID`
     - **Description:** `Lab troubleshooting cluster for $ID`
   - **Location:**
     - **AWS Cloud**
     - **Multi-AZ:** Disabled (para este lab)
     - **Failover autom√°tico:** Desabilitado (n√£o aplic√°vel sem r√©plicas)
   - **Cluster settings:**
     - **Engine version:** 7.0
     - **Port:** 6379
     - **Node type:** **cache.t3.micro** (importante para simular limita√ß√µes)
     - **Number of replicas:** 0
   - **Connectivity:**
     - **Network type:** IPv4
     - **Subnet group:** `elasticache-lab-subnet-group`
     - **Security groups:** Selecione seu SG `elasticache-lab-sg-$ID`
   - **Security (Seguran√ßa):**
     - **Criptografia em repouso:** Habilitada (recomendado)
     - **Chave de criptografia:** Chave padr√£o (AWS managed)
     - **Criptografia em tr√¢nsito:** Habilitada (recomendado)
     - **Controle de acesso:** Nenhum controle de acesso (para simplicidade do lab)
   - **Backup:**
     - **Enable automatic backups:** Enabled
   - **Maintenance:**
     - **Auto minor version upgrade:** Enabled
   - **Advanced settings:**
     - **Parameter group:** default.redis7.x
     - **Log delivery:** Disabled (para este lab)
     - **Tags (Recomendado):**
       - **Key:** `Name` **Value:** `Lab Troubleshoot - $ID`
       - **Key:** `Lab` **Value:** `Lab03`
       - **Key:** `Purpose` **Value:** `Infrastructure-Testing`

6. Clique em **Create**

> **üìö Para saber mais sobre seguran√ßa:**
> - [Criptografia no ElastiCache](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html)
> - [Configura√ß√µes de seguran√ßa](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth.html)

#### Alternativa: Cria√ß√£o R√°pida via CLI

Para acelerar o processo, voc√™ pode criar o cluster via CLI:

```bash
# Obter IDs necess√°rios
VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=ElastiCache-Lab-VPC" --query 'Vpcs[0].VpcId' --output text --region us-east-2)
SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$ID" --query 'SecurityGroups[0].GroupId' --output text --region us-east-2)

# IMPORTANTE: Para ter criptografia via CLI, devemos usar Replication Group (mesmo com 1 n√≥)
# create-cache-cluster N√ÉO suporta par√¢metros de criptografia
aws elasticache create-replication-group \
    --replication-group-id "lab-troubleshoot-$ID" \
    --replication-group-description "Troubleshooting with encryption" \
    --num-cache-clusters 1 \
    --cache-node-type cache.t3.micro \
    --engine redis \
    --engine-version 7.0 \
    --port 6379 \
    --cache-subnet-group-name elasticache-lab-subnet-group \
    --security-group-ids $SG_ID \
    --at-rest-encryption-enabled \
    --transit-encryption-enabled \
    --auto-minor-version-upgrade \
    --tags Key=Name,Value="Lab Troubleshoot - $ID" Key=Lab,Value=Lab03 Key=Purpose,Value=Infrastructure-Testing \
    --region us-east-2

echo "‚úÖ Replication Group criado via CLI! Aguarde ~10-15 minutos para ficar dispon√≠vel."
```

> **üèóÔ∏è PONTO ARQUITETURAL IMPORTANTE:**
> 
> **Por que usar `create-replication-group` em vez de `create-cache-cluster`?**
> 
> - **`create-cache-cluster`:** Comando legado, N√ÉO suporta criptografia
> - **`create-replication-group`:** Comando moderno, suporta todas as funcionalidades
> 
> **Mesmo para 1 n√≥ √∫nico**, use `create-replication-group` se precisar de:
> - ‚úÖ Criptografia (at-rest e in-transit)
> - ‚úÖ Backups autom√°ticos
> - ‚úÖ Multi-AZ (futuro)
> - ‚úÖ Failover autom√°tico (futuro)
> 
> **Regra pr√°tica:** Sempre use `create-replication-group` em produ√ß√£o!


#### Passo 3: Monitorar Cria√ß√£o e Obter Informa√ß√µes

```bash
# Monitorar status do replication group
watch -n 30 "aws elasticache describe-replication-groups --replication-group-id lab-troubleshoot-$ID --query 'ReplicationGroups[0].Status' --output text --region us-east-2"

# Quando dispon√≠vel, obter endpoint
CLUSTER_ENDPOINT=$(aws elasticache describe-replication-groups --replication-group-id lab-troubleshoot-$ID --query 'ReplicationGroups[0].NodeGroups[0].PrimaryEndpoint.Address' --output text --region us-east-2)
echo "Cluster Endpoint: $CLUSTER_ENDPOINT"

# Obter informa√ß√µes detalhadas
aws elasticache describe-replication-groups --replication-group-id lab-troubleshoot-$ID --region us-east-2
```

**‚úÖ Checkpoint:** Cluster deve estar "available" e endpoint acess√≠vel.

---

### Exerc√≠cio 2: Troubleshooting de Conectividade (15 minutos)

**Objetivo:** Diagnosticar e resolver problemas de conectividade de rede

#### Passo 1: Teste de Conectividade B√°sica

```bash
# Teste b√°sico de conectividade
echo "üîç Testando conectividade b√°sica..."
redis-cli -h $CLUSTER_ENDPOINT -p 6379 --tls ping

# Se falhar, vamos diagnosticar passo a passo
if [ $? -ne 0 ]; then
    echo "‚ùå Conectividade falhou - iniciando diagn√≥stico"
else
    echo "‚úÖ Conectividade OK"
fi
```

#### Passo 2: Diagn√≥stico de DNS

```bash
# Teste de resolu√ß√£o DNS
echo "üîç Testando resolu√ß√£o DNS..."
nslookup $CLUSTER_ENDPOINT

# Teste de conectividade de rede (sem Redis)
echo "üîç Testando conectividade de rede..."
nc -zv $CLUSTER_ENDPOINT 6379
```

#### Passo 3: An√°lise de Security Groups

**Via Console Web:**
1. Acesse **EC2** > **Security Groups**
2. Encontre seu SG `elasticache-lab-sg-$ID`
3. Verifique **Inbound rules**:
   - Deve ter regra para porta 6379
   - Source deve permitir acesso do Bastion Host

**Via CLI:**
```bash
# Obter ID do Security Group
SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$ID" --query 'SecurityGroups[0].GroupId' --output text --region us-east-2)

# Analisar regras de entrada
echo "üîç Analisando regras do Security Group..."
aws ec2 describe-security-groups --group-ids $SG_ID --query 'SecurityGroups[0].IpPermissions' --region us-east-2

# Verificar se porta 6379 est√° aberta
aws ec2 describe-security-groups --group-ids $SG_ID --query 'SecurityGroups[0].IpPermissions[?FromPort==`6379`]' --region us-east-2
```

**‚úÖ Checkpoint:** Compreender como Security Groups afetam conectividade.

---

### Exerc√≠cio 3: An√°lise de CPU e Performance (15 minutos)

**Objetivo:** Identificar e diagnosticar problemas de CPU no ElastiCache

#### Passo 1: Estabelecer Baseline de CPU

```bash
# Popular dados iniciais para estabelecer baseline
echo "üìä Estabelecendo baseline de performance..."

# Testar conectividade primeiro
if redis-cli -h $CLUSTER_ENDPOINT -p 6379 --tls ping > /dev/null 2>&1; then
    echo "‚úÖ Conectividade OK "
    REDIS_CMD="redis-cli -h $CLUSTER_ENDPOINT -p 6379 --tls"
else
    echo "‚ùå Erro de conectividade"
    exit 1
fi

# Limpar dados existentes
$REDIS_CMD FLUSHALL

# Inserir dados de baseline
echo "Inserindo dados de baseline..."
for i in {1..1000}; do
    $REDIS_CMD SET "baseline:$ID:key$i" "value$i" > /dev/null
done

# Criar algumas estruturas mais complexas
$REDIS_CMD HSET "user:$ID:profile" name "Jo√£o Silva" email "joao@example.com" age 30

# Criar lista de eventos
for i in {1..100}; do
    $REDIS_CMD LPUSH "events:$ID" "event$i" > /dev/null
done

# Criar set de tags
for i in {1..50}; do
    $REDIS_CMD SADD "tags:$ID" "tag$i" > /dev/null
done

echo "‚úÖ Dados de baseline inseridos"
```

#### Passo 2: Monitorar M√©tricas de CPU via CloudWatch

**Via Console Web:**
1. Acesse **CloudWatch** > **Metrics**
2. Navegue para **AWS/ElastiCache**
3. Selecione **CacheClusterId**
4. Encontre seu replication group `lab-troubleshoot-$ID`
5. Selecione m√©tricas:
   - `CPUUtilization`
   - `EngineCPUUtilization`
   - `NetworkBytesIn`
   - `NetworkBytesOut`
   - `CurrConnections`

**Via CLI:**
```bash
# Obter m√©tricas de CPU dos √∫ltimos 30 minutos
echo "üìà Obtendo m√©tricas de CPU..."

aws cloudwatch get-metric-statistics \
    --namespace AWS/ElastiCache \
    --metric-name CPUUtilization \
    --dimensions Name=CacheClusterId,Value=lab-troubleshoot-$ID-001 \
    --start-time $(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Average Maximum \
    --region us-east-2

# M√©tricas espec√≠ficas do Redis Engine
aws cloudwatch get-metric-statistics \
    --namespace AWS/ElastiCache \
    --metric-name EngineCPUUtilization \
    --dimensions Name=CacheClusterId,Value=lab-troubleshoot-$ID-001 \
    --start-time $(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Average Maximum \
    --region us-east-2
```

#### Passo 3: Simular Carga de CPU

```bash
# Script para simular alta utiliza√ß√£o de CPU
echo "üß™ SIMULA√á√ÉO: Gerando carga de CPU..."

#**üí° NOTA IMPORTANTE:**
#
#**Por que a simula√ß√£o anterior gerava apenas 5% de CPU?**
#- Opera√ß√µes individuais s√£o muito r√°pidas
#- cache.t3.micro tem recursos limitados mas ainda assim eficiente
#- Comandos sequenciais n√£o saturam o processador
#
#**Nova abordagem mais efetiva:**
#- M√∫ltiplos processos paralelos (3 geradores)
#- Opera√ß√µes custosas em loop cont√≠nuo
#- Comandos KEYS, SORT, LRANGE que consomem mais CPU
#- Execu√ß√£o simult√¢nea para saturar recursos

# Fun√ß√£o para gerar carga intensiva
generate_cpu_load() {
    local duration=$1
    local end_time=$(($(date +%s) + duration))
    
    echo "Gerando carga intensiva por $duration segundos..."
    
    while [ $(date +%s) -lt $end_time ]; do
        # Executar m√∫ltiplas opera√ß√µes custosas em paralelo
        for j in {1..5}; do
            (
                # Opera√ß√µes que consomem muito CPU
                $REDIS_CMD KEYS "*$ID*" > /dev/null 2>&1
                $REDIS_CMD SORT "events:$ID" ALPHA > /dev/null 2>&1
                $REDIS_CMD SORT "events:$ID" DESC > /dev/null 2>&1
                
                # Opera√ß√µes de interse√ß√£o custosas
                $REDIS_CMD SINTER "tags:$ID" "tags:$ID" > /dev/null 2>&1
                $REDIS_CMD SUNION "tags:$ID" "tags:$ID" > /dev/null 2>&1
                
                # Opera√ß√µes de contagem
                $REDIS_CMD SCARD "tags:$ID" > /dev/null 2>&1
                $REDIS_CMD LLEN "events:$ID" > /dev/null 2>&1
                $REDIS_CMD HLEN "user:$ID:profile" > /dev/null 2>&1
                
                # Opera√ß√µes de busca custosas
                $REDIS_CMD LRANGE "events:$ID" 0 -1 > /dev/null 2>&1
                $REDIS_CMD HGETALL "user:$ID:profile" > /dev/null 2>&1
                
                # Opera√ß√µes matem√°ticas custosas
                for k in {1..10}; do
                    $REDIS_CMD INCR "temp:counter:$j:$k" > /dev/null 2>&1
                    $REDIS_CMD DECR "temp:counter:$j:$k" > /dev/null 2>&1
                done
            ) &
        done
        
        # Aguardar um pouco antes da pr√≥xima rodada
        sleep 0.1
        
        # Limitar n√∫mero de processos background
        wait
    done
}

# Executar m√∫ltiplas inst√¢ncias de carga em paralelo
echo "Iniciando m√∫ltiplos geradores de carga..."
for i in {1..3}; do
    generate_cpu_load 180 &
    LOAD_PIDS[$i]=$!
done

echo "üîç Monitorando CPU durante carga intensiva..."
for i in {1..6}; do
    echo "=== Verifica√ß√£o $i ($(date)) ==="
    
    # Testar lat√™ncia com comando correto
    START_TIME=$(date +%s%N)
    $REDIS_CMD ping > /dev/null
    END_TIME=$(date +%s%N)
    LATENCY=$(( (END_TIME - START_TIME) / 1000000 ))
    echo "Lat√™ncia PING: ${LATENCY}ms"
    
    # Testar opera√ß√£o simples
    START_TIME=$(date +%s%N)
    $REDIS_CMD GET "baseline:$ID:key1" > /dev/null
    END_TIME=$(date +%s%N)
    LATENCY=$(( (END_TIME - START_TIME) / 1000000 ))
    echo "Lat√™ncia GET: ${LATENCY}ms"
    
    sleep 30
done

# Parar todos os geradores de carga
echo "Parando geradores de carga..."
for i in {1..3}; do
    kill ${LOAD_PIDS[$i]} 2>/dev/null || true
done
wait 2>/dev/null || true

# Limpar chaves tempor√°rias criadas durante o teste
echo "Limpando dados tempor√°rios..."
$REDIS_CMD DEL $(for i in {1..5}; do for k in {1..10}; do echo "temp:counter:$i:$k"; done; done) > /dev/null 2>&1

echo "‚úÖ Simula√ß√£o de carga intensiva conclu√≠da"
```

> **üîß ALTERNATIVA PARA CARGA MAIS ALTA:**
> 
> Se ainda assim a CPU n√£o subir significativamente, use esta vers√£o mais agressiva:
> 
> ```bash
> # Vers√£o MUITO mais agressiva (use com cuidado)
> echo "üö® CARGA EXTREMA: Gerando carga m√°xima de CPU..."
> 
> # Fun√ß√£o para carga extrema
> extreme_cpu_load() {
>     while true; do
>         # Opera√ß√µes extremamente custosas
>         $REDIS_CMD KEYS "*" > /dev/null 2>&1  # MUITO custoso
>         $REDIS_CMD SORT "events:$ID" ALPHA LIMIT 0 1000 > /dev/null 2>&1
>         $REDIS_CMD LRANGE "events:$ID" 0 -1 > /dev/null 2>&1
>         
>         # Criar e deletar dados rapidamente
>         for x in {1..100}; do
>             $REDIS_CMD SET "stress:$x" "$(date +%s%N)" > /dev/null 2>&1
>             $REDIS_CMD GET "stress:$x" > /dev/null 2>&1
>             $REDIS_CMD DEL "stress:$x" > /dev/null 2>&1
>         done
>     done
> }
> 
> # Executar 5 processos de carga extrema
> for i in {1..5}; do
>     extreme_cpu_load &
>     EXTREME_PIDS[$i]=$!
> done
> 
> echo "‚ö†Ô∏è  CARGA EXTREMA ATIVA - Monitore por 2-3 minutos e pare:"
> echo "kill ${EXTREME_PIDS[@]}"
> ```
> 
> **‚ö†Ô∏è CUIDADO:** Esta vers√£o pode impactar significativamente o cluster!

#### Passo 4: Analisar Impacto da Alta CPU

```bash
# Verificar m√©tricas ap√≥s carga
echo "üìä Analisando m√©tricas p√≥s-carga..."

# Aguardar propaga√ß√£o das m√©tricas
sleep 60

# Obter m√©tricas recentes
aws cloudwatch get-metric-statistics \
    --namespace AWS/ElastiCache \
    --metric-name CPUUtilization \
    --dimensions Name=CacheClusterId,Value=lab-troubleshoot-$ID-001 \
    --start-time $(date -u -d '10 minutes ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 60 \
    --statistics Average Maximum \
    --region us-east-2
```

**Sinais de Problema de CPU:**
- ‚úÖ CPUUtilization > 80% consistentemente
- ‚úÖ EngineCPUUtilization > 90%
- ‚úÖ Aumento na lat√™ncia de opera√ß√µes simples
- ‚úÖ Timeout em opera√ß√µes complexas

> **üìä ENTENDENDO CPU EM cache.t3.micro:**
> 
> **Por que √© dif√≠cil saturar CPU em t3.micro?**
> - **Burstable Performance:** t3.micro pode usar cr√©ditos de CPU
> - **Redis √© eficiente:** Opera√ß√µes simples s√£o muito r√°pidas
> - **Single-threaded:** Redis usa principalmente 1 core
> - **Mem√≥ria limitada:** 0.5GB limita o dataset antes da CPU
> 
> **Cen√°rios reais de alta CPU:**
> - Comandos KEYS em datasets grandes (>100k chaves)
> - Opera√ß√µes SORT em listas grandes (>10k elementos)
> - SUNION/SINTER em sets grandes
> - M√∫ltiplas conex√µes simult√¢neas
> - Scripts Lua complexos
> 
> **Em produ√ß√£o, use inst√¢ncias maiores** (m6g.large+) para demonstra√ß√µes mais realistas.

**‚úÖ Checkpoint:** Correlacionar alta CPU com degrada√ß√£o de performance.

---

### Exerc√≠cio 4: Diagn√≥stico de Mem√≥ria (15 minutos)

**Objetivo:** Identificar problemas de mem√≥ria e uso de swap

#### Passo 1: Analisar Uso de Mem√≥ria Atual

```bash
# Obter informa√ß√µes de mem√≥ria do Redis
echo "üîç Analisando uso de mem√≥ria..."

$REDIS_CMD info memory

# M√©tricas espec√≠ficas de interesse
$REDIS_CMD INFO memory | grep -E "(used_memory|used_memory_human|used_memory_peak|maxmemory)"
```

#### Passo 2: Monitorar M√©tricas de Mem√≥ria via CloudWatch

**Via Console Web:**
1. No CloudWatch, adicione m√©tricas:
   - `DatabaseMemoryUsagePercentage`
   - `SwapUsage`
   - `FreeableMemory`
   - `BytesUsedForCache`

**Via CLI:**
```bash
# M√©tricas de uso de mem√≥ria
aws cloudwatch get-metric-statistics \
    --namespace AWS/ElastiCache \
    --metric-name DatabaseMemoryUsagePercentage \
    --dimensions Name=CacheClusterId,Value=lab-troubleshoot-$ID-001 \
    --start-time $(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Average Maximum \
    --region us-east-2

# M√©tricas de swap
aws cloudwatch get-metric-statistics \
    --namespace AWS/ElastiCache \
    --metric-name SwapUsage \
    --dimensions Name=CacheClusterId,Value=lab-troubleshoot-$ID-001 \
    --start-time $(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Average Maximum \
    --region us-east-2
```

#### Passo 3: Simular Press√£o de Mem√≥ria

```bash
# Simular uso intensivo de mem√≥ria
echo "üß™ SIMULA√á√ÉO: Gerando press√£o de mem√≥ria..."

# Fun√ß√£o para consumir mem√≥ria
consume_memory() {
    local target_mb=$1
    local key_size=1024  # 1KB por chave
    local num_keys=$((target_mb * 1024))
    
    echo "Inserindo ~${target_mb}MB de dados..."
    
    for i in $(seq 1 $num_keys); do
        # Criar string de 1KB
        local value=$(printf 'A%.0s' {1..1024})
        redis-cli -h $CLUSTER_ENDPOINT -p 6379 --tls SET "memory_test:$ID:$i" "$value" > /dev/null
        
        # Mostrar progresso a cada 1000 chaves
        if [ $((i % 1000)) -eq 0 ]; then
            echo "Inseridas $i chaves..."
        fi
    done
}

# Consumir mem√≥ria gradualmente
consume_memory 10  # 10MB

# Monitorar uso de mem√≥ria
echo "üìä Monitorando uso de mem√≥ria..."
for i in {1..5}; do
    echo "=== Verifica√ß√£o $i ($(date)) ==="
    
    # Informa√ß√µes de mem√≥ria do Redis
    USED_MEMORY=$(redis-cli -h $CLUSTER_ENDPOINT -p 6379 --tls info memory | grep "used_memory_human" | cut -d: -f2 | tr -d '\r')
    USED_MEMORY_PEAK=$(redis-cli -h $CLUSTER_ENDPOINT -p 6379 --tls info memory | grep "used_memory_peak_human" | cut -d: -f2 | tr -d '\r')
    
    echo "Mem√≥ria Usada: $USED_MEMORY"
    echo "Pico de Mem√≥ria: $USED_MEMORY_PEAK"
    
    # Testar performance com alta utiliza√ß√£o de mem√≥ria
    START_TIME=$(date +%s%N)
    redis-cli -h $CLUSTER_ENDPOINT -p 6379 --tls GET baseline:$ID:key1 > /dev/null
    END_TIME=$(date +%s%N)
    LATENCY=$(( (END_TIME - START_TIME) / 1000000 ))
    echo "Lat√™ncia GET: ${LATENCY}ms"
    
    sleep 30
done

# Limpar dados de teste de mem√≥ria
echo "üßπ Limpando dados de teste..."
redis-cli -h $CLUSTER_ENDPOINT -p 6379 --tls eval "
    local keys = redis.call('keys', 'memory_test:$ID:*')
    for i=1,#keys do
        redis.call('del', keys[i])
    end
    return #keys
" 0

echo "‚úÖ Simula√ß√£o de press√£o de mem√≥ria conclu√≠da"
```

#### Passo 4: Identificar Padr√µes Problem√°ticos

```bash
# Analisar padr√µes de uso de mem√≥ria
echo "üîç Analisando padr√µes de uso de mem√≥ria..."

# Verificar fragmenta√ß√£o de mem√≥ria
redis-cli -h $CLUSTER_ENDPOINT -p 6379 --tls info memory | grep -E "(mem_fragmentation|mem_allocator)"

# Verificar estat√≠sticas de eviction (se configurado)
redis-cli -h $CLUSTER_ENDPOINT -p 6379 --tls info stats | grep -E "(evicted_keys|expired_keys)"

# Verificar configura√ß√£o de maxmemory
redis-cli -h $CLUSTER_ENDPOINT -p 6379 --tls INFO memory | grep -E "(maxmemory|maxmemory_policy|used_memory|used_memory_rss|used_memory_peak)"
```

**Sinais de Problema de Mem√≥ria:**
- ‚úÖ DatabaseMemoryUsagePercentage > 80%
- ‚úÖ SwapUsage > 0 (uso de swap √© sempre problem√°tico)
- ‚úÖ Fragmenta√ß√£o de mem√≥ria > 1.5
- ‚úÖ Evictions frequentes de chaves

**‚úÖ Checkpoint:** Identificar quando mem√≥ria se torna gargalo.

---

## üîç Metodologia de Troubleshooting

### Abordagem Estruturada

1. **Identificar Sintomas**
   - Lat√™ncia alta
   - Timeouts
   - Erros de conex√£o
   - Performance degradada

2. **Coletar Dados**
   - M√©tricas CloudWatch
   - Logs de aplica√ß√£o
   - Informa√ß√µes do Redis (INFO)
   - Testes de conectividade

3. **Analisar Padr√µes**
   - Correlacionar m√©tricas com sintomas
   - Identificar picos e anomalias
   - Verificar configura√ß√µes

4. **Hip√≥teses e Testes**
   - Formular hip√≥teses baseadas em dados
   - Testar uma vari√°vel por vez
   - Documentar resultados

5. **Implementar Solu√ß√£o**
   - Aplicar corre√ß√£o espec√≠fica
   - Monitorar impacto
   - Validar resolu√ß√£o

### Checklist de Troubleshooting

#### Conectividade
- [ ] DNS resolve corretamente?
- [ ] Security Groups permitem porta 6379?
- [ ] Rede permite conectividade?
- [ ] Endpoint est√° correto?
- [ ] Cluster est√° no status "available"?

#### CPU
- [ ] CPUUtilization < 80%?
- [ ] EngineCPUUtilization < 90%?
- [ ] Opera√ß√µes complexas otimizadas?
- [ ] Comandos KEYS evitados?
- [ ] √çndices apropriados?

#### Mem√≥ria
- [ ] DatabaseMemoryUsagePercentage < 80%?
- [ ] SwapUsage = 0?
- [ ] Fragmenta√ß√£o < 1.5?
- [ ] TTL configurado adequadamente?
- [ ] Pol√≠tica de eviction apropriada?

## üìä Dashboards e Alertas Recomendados

### M√©tricas Cr√≠ticas para Monitoramento

| M√©trica | Threshold Cr√≠tico | A√ß√£o |
|---------|------------------|------|
| CPUUtilization | > 80% | Investigar opera√ß√µes custosas |
| EngineCPUUtilization | > 90% | Otimizar queries, considerar upgrade |
| DatabaseMemoryUsagePercentage | > 80% | Revisar TTL, considerar eviction |
| SwapUsage | > 0 | Investigar imediatamente |
| CurrConnections | > 80% do m√°ximo | Revisar connection pooling |
| NetworkBytesIn/Out | Spikes an√¥malos | Investigar transfer√™ncia de dados |

### Alertas CloudWatch Sugeridos

```bash
# Exemplo de cria√ß√£o de alarme via CLI
aws cloudwatch put-metric-alarm \
    --alarm-name "ElastiCache-HighCPU-$ID" \
    --alarm-description "High CPU utilization on ElastiCache cluster" \
    --metric-name CPUUtilization \
    --namespace AWS/ElastiCache \
    --statistic Average \
    --period 300 \
    --threshold 80 \
    --comparison-operator GreaterThanThreshold \
    --evaluation-periods 2 \
    --dimensions Name=CacheClusterId,Value=lab-troubleshoot-$ID-001 \
    --region us-east-2
```

## üí∞ Aten√ß√£o aos Custos

‚ö†Ô∏è **IMPORTANTE:** Este laborat√≥rio cria recursos AWS que geram custos na regi√£o us-east-2:

- Cache cluster: ~$0.017/hora (cache.t3.micro)
- CloudWatch m√©tricas: Inclu√≠das no Free Tier
- Data transfer: M√≠nimo para este lab

**Custo estimado por aluno:** ~$0.05 para completar o laborat√≥rio

## üßπ Limpeza de Recursos

**CR√çTICO:** Ao final do laborat√≥rio, delete seus recursos para evitar custos:

### Via Console Web:
1. **ElastiCache** > **"Caches do Redis OSS"**
   - Selecione `lab-troubleshoot-$ID`
   - **Actions** > **Delete**
   - Confirme a dele√ß√£o

### Via CLI:
```bash
# Deletar replication group de troubleshooting
aws elasticache delete-replication-group --replication-group-id lab-troubleshoot-$ID --region us-east-2

# Monitorar dele√ß√£o
watch -n 30 "aws elasticache describe-replication-groups --replication-group-id lab-troubleshoot-$ID --region us-east-2 2>/dev/null || echo 'Replication Group deletado com sucesso'"

# Deletar alarmes criados (opcional)
aws cloudwatch delete-alarms --alarm-names "ElastiCache-HighCPU-$ID" --region us-east-2
```

**NOTA:** Mantenha o Security Group para uso nos pr√≥ximos laborat√≥rios.

## üìñ Recursos Adicionais

- [ElastiCache Monitoring](https://docs.aws.amazon.com/elasticache/latest/red-ug/monitoring-cloudwatch.html)
- [Redis INFO Command](https://redis.io/commands/info)
- [CloudWatch Metrics](https://docs.aws.amazon.com/elasticache/latest/red-ug/CacheMetrics.html)
- [Performance Tuning](https://docs.aws.amazon.com/elasticache/latest/red-ug/BestPractices.html)

## üÜò Troubleshooting

### Problemas Comuns

1. **M√©tricas n√£o aparecem no CloudWatch**
   - Aguarde 5-15 minutos para propaga√ß√£o
   - Verifique regi√£o selecionada
   - Confirme que cluster est√° ativo

2. **Erro de conex√£o com redis-cli**
   - **Criptografia em tr√¢nsito habilitada:** Use `redis-cli` com `--tls`
   - **Exemplo:** `redis-cli -h $CLUSTER_ENDPOINT -p 6379 --tls ping`
   - **Documenta√ß√£o:** [ElastiCache Encryption](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html)

3. **Comando CLI create-replication-group falha**
   - **Verifique IDs:** Confirme que VPC_ID e SG_ID foram obtidos corretamente
   - **Permiss√µes:** Verifique se tem permiss√µes ElastiCache completas
   - **Subnet Group:** Confirme que `elasticache-lab-subnet-group` existe
   - **Nome √∫nico:** Replication group ID deve ser √∫nico na regi√£o

4. **Alta lat√™ncia persistente**
   - Verifique CPU e mem√≥ria
   - Analise comandos executados
   - Considere otimiza√ß√£o de queries

5. **Uso de swap detectado**
   - **CR√çTICO:** Investigar imediatamente
   - Verificar configura√ß√£o de mem√≥ria
   - Considerar upgrade de inst√¢ncia

6. **Conectividade intermitente**
   - Verificar Security Groups
   - Analisar logs de rede
   - Testar de diferentes origens

7. **CPU alta sem carga aparente**
   - Verificar comandos KEYS
   - Analisar opera√ß√µes de background
   - Revisar configura√ß√£o de persistence

## üéØ Objetivos de Aprendizado Alcan√ßados

Ao final deste laborat√≥rio, voc√™ deve conseguir:

- ‚úÖ Diagnosticar problemas de conectividade de forma estruturada
- ‚úÖ Interpretar m√©tricas de CPU e identificar gargalos
- ‚úÖ Analisar uso de mem√≥ria e detectar problemas de swap
- ‚úÖ Correlacionar m√©tricas CloudWatch com sintomas da aplica√ß√£o
- ‚úÖ Aplicar metodologia estruturada de troubleshooting
- ‚úÖ Configurar alertas proativos para problemas de infraestrutura
- ‚úÖ Simular e resolver cen√°rios reais de problemas

## üìù Notas Importantes

- **Metodologia estruturada** √© essencial para troubleshooting eficaz
- **M√©tricas CloudWatch** s√£o fundamentais para diagn√≥stico
- **Uso de swap** √© sempre problem√°tico e deve ser investigado imediatamente
- **CPU > 80%** consistentemente indica necessidade de otimiza√ß√£o
- **Conectividade** deve ser testada em m√∫ltiplas camadas (DNS, rede, aplica√ß√£o)
- **Alertas proativos** previnem problemas antes que afetem usu√°rios
- **Documenta√ß√£o** de problemas e solu√ß√µes acelera troubleshooting futuro

## ‚û°Ô∏è Pr√≥ximo Laborat√≥rio

Agora que voc√™ domina troubleshooting de infraestrutura, v√° para:

**[Lab 04: Troubleshooting de Dados](../lab04-troubleshooting-dados/README.md)**

---

**Parab√©ns! Voc√™ completou o Lab 03! üéâ**

*Voc√™ agora possui habilidades estruturadas para diagnosticar e resolver problemas de infraestrutura no ElastiCache.*