# Lab 03 - Troubleshooting de Infraestrutura

Laborat√≥rio focado no diagn√≥stico estruturado de problemas de infraestrutura no ElastiCache na regi√£o **us-east-2**, desenvolvendo habilidades para identificar, analisar e resolver problemas de conectividade, CPU, mem√≥ria e rede antes que impactem a aplica√ß√£o.

## üìã Objetivos do Laborat√≥rio

- Diagnosticar problemas de conectividade (Security Groups, rede, DNS)
- Analisar m√©tricas de CPU e identificar gargalos de processamento
- Identificar press√£o de mem√≥ria e uso inadequado de swap
- Correlacionar m√©tricas CloudWatch com sintomas da aplica√ß√£o
- Desenvolver metodologia estruturada de troubleshooting
- Simular cen√°rios reais de problemas de infraestrutura

## ‚è±Ô∏è Dura√ß√£o Estimada: 60 minutos

## üåç Regi√£o AWS: us-east-2 (Ohio)

**IMPORTANTE:** Todos os recursos devem ser criados na regi√£o **us-east-2**. Verifique sempre a regi√£o no canto superior direito do Console AWS.

## üèóÔ∏è Estrutura do Laborat√≥rio

```
lab03-troubleshooting-infraestrutura/
‚îú‚îÄ‚îÄ README.md                    # Este guia (foco principal)
‚îú‚îÄ‚îÄ scripts/                     # Scripts de refer√™ncia (opcional)
‚îÇ   ‚îú‚îÄ‚îÄ create-test-cluster.sh
‚îÇ   ‚îú‚îÄ‚îÄ simulate-cpu-load.sh
‚îÇ   ‚îú‚îÄ‚îÄ simulate-memory-pressure.sh
‚îÇ   ‚îú‚îÄ‚îÄ test-connectivity.sh
‚îÇ   ‚îî‚îÄ‚îÄ cleanup-lab03.sh
‚îî‚îÄ‚îÄ metricas/                    # Dashboards e queries (opcional)
    ‚îú‚îÄ‚îÄ cloudwatch-dashboard.json
    ‚îî‚îÄ‚îÄ useful-queries.md
```

**IMPORTANTE:** Este laborat√≥rio foca na an√°lise manual via Console Web e CLI. Os scripts s√£o apenas para refer√™ncia e simula√ß√£o de problemas.

## üöÄ Pr√©-requisitos

- Conta AWS ativa configurada para regi√£o **us-east-2**
- AWS CLI configurado para regi√£o us-east-2
- Acesso √† inst√¢ncia EC2 fornecida pelo instrutor (Bastion Host)
- Redis CLI instalado e funcional
- Conhecimento b√°sico de m√©tricas CloudWatch
- **ID do Aluno:** Voc√™ deve usar seu ID √∫nico (ex: aluno01, aluno02, etc.)
- **Labs anteriores:** VPC, Subnet Group e Security Group j√° criados

## üè∑Ô∏è Conven√ß√£o de Nomenclatura

Todos os recursos criados devem seguir o padr√£o:
- **Cluster de Teste:** `lab-troubleshoot-{SEU_ID}`
- **Security Groups:** Reutilizar `elasticache-lab-sg-{SEU_ID}` dos labs anteriores

**Exemplo para aluno01:**
- Cluster: `lab-troubleshoot-aluno01`
- Security Group: `elasticache-lab-sg-aluno01` (j√° existente)

## üìö Exerc√≠cios

### Exerc√≠cio 1: Preparar Ambiente de Teste (15 minutos)

**Objetivo:** Criar cluster para simular problemas de infraestrutura

#### Passo 1: Verificar Pr√©-requisitos

```bash
# Definir seu ID (ALTERE AQUI)
SEU_ID="aluno01"

# Verificar regi√£o
aws configure get region
# Deve retornar: us-east-2

# Verificar Security Group dos labs anteriores
aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$SEU_ID" --region us-east-2
```

#### Passo 2: Criar Cluster de Teste via Console Web

1. Acesse **ElastiCache** > **Redis clusters**
2. Clique em **Create Redis cluster**
3. Configure:
   - **Cluster mode:** Disabled (para simplicidade)
   - **Cluster info:**
     - **Name:** `lab-troubleshoot-{SEU_ID}`
     - **Description:** `Lab troubleshooting cluster for {SEU_ID}`
   - **Location:**
     - **AWS Cloud**
     - **Multi-AZ:** Disabled (para este lab)
   - **Cluster settings:**
     - **Engine version:** 7.0
     - **Port:** 6379
     - **Node type:** **cache.t3.micro** (importante para simular limita√ß√µes)
     - **Number of replicas:** 0
   - **Connectivity:**
     - **Network type:** IPv4
     - **Subnet group:** `elasticache-lab-subnet-group`
     - **Security groups:** Selecione seu SG `elasticache-lab-sg-{SEU_ID}`
   - **Advanced settings:**
     - **Parameter group:** default.redis7.x
     - **Log delivery:** Disabled (para este lab)

4. Clique em **Create**

#### Passo 3: Monitorar Cria√ß√£o e Obter Informa√ß√µes

```bash
# Monitorar status do cluster
watch -n 30 "aws elasticache describe-cache-clusters --cache-cluster-id lab-troubleshoot-$SEU_ID --query 'CacheClusters[0].CacheClusterStatus' --output text --region us-east-2"

# Quando dispon√≠vel, obter endpoint
CLUSTER_ENDPOINT=$(aws elasticache describe-cache-clusters --cache-cluster-id lab-troubleshoot-$SEU_ID --show-cache-node-info --query 'CacheClusters[0].CacheNodes[0].Endpoint.Address' --output text --region us-east-2)
echo "Cluster Endpoint: $CLUSTER_ENDPOINT"

# Obter informa√ß√µes detalhadas
aws elasticache describe-cache-clusters --cache-cluster-id lab-troubleshoot-$SEU_ID --show-cache-node-info --region us-east-2
```

**‚úÖ Checkpoint:** Cluster deve estar "available" e endpoint acess√≠vel.

---

### Exerc√≠cio 2: Troubleshooting de Conectividade (15 minutos)

**Objetivo:** Diagnosticar e resolver problemas de conectividade de rede

#### Passo 1: Teste de Conectividade B√°sica

```bash
# Teste b√°sico de conectividade
echo "üîç Testando conectividade b√°sica..."
redis-cli -h $CLUSTER_ENDPOINT -p 6379 ping

# Se falhar, vamos diagnosticar passo a passo
if [ $? -ne 0 ]; then
    echo "‚ùå Conectividade falhou - iniciando diagn√≥stico"
else
    echo "‚úÖ Conectividade OK"
fi
```

#### Passo 2: Diagn√≥stico de DNS

```bash
# Teste de resolu√ß√£o DNS
echo "üîç Testando resolu√ß√£o DNS..."
nslookup $CLUSTER_ENDPOINT

# Teste de conectividade de rede (sem Redis)
echo "üîç Testando conectividade de rede..."
nc -zv $CLUSTER_ENDPOINT 6379

# Teste de lat√™ncia de rede
echo "üîç Testando lat√™ncia de rede..."
ping -c 4 $CLUSTER_ENDPOINT
```

#### Passo 3: An√°lise de Security Groups

**Via Console Web:**
1. Acesse **EC2** > **Security Groups**
2. Encontre seu SG `elasticache-lab-sg-{SEU_ID}`
3. Verifique **Inbound rules**:
   - Deve ter regra para porta 6379
   - Source deve permitir acesso do Bastion Host

**Via CLI:**
```bash
# Obter ID do Security Group
SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=elasticache-lab-sg-$SEU_ID" --query 'SecurityGroups[0].GroupId' --output text --region us-east-2)

# Analisar regras de entrada
echo "üîç Analisando regras do Security Group..."
aws ec2 describe-security-groups --group-ids $SG_ID --query 'SecurityGroups[0].IpPermissions' --region us-east-2

# Verificar se porta 6379 est√° aberta
aws ec2 describe-security-groups --group-ids $SG_ID --query 'SecurityGroups[0].IpPermissions[?FromPort==`6379`]' --region us-east-2
```

#### Passo 4: Simular Problema de Security Group

```bash
# SIMULA√á√ÉO: Remover regra de entrada temporariamente
echo "üß™ SIMULA√á√ÉO: Removendo regra de entrada para demonstrar problema..."

# Obter regra atual (salvar para restaurar depois)
CURRENT_RULE=$(aws ec2 describe-security-groups --group-ids $SG_ID --query 'SecurityGroups[0].IpPermissions[?FromPort==`6379`]' --region us-east-2)

# Remover regra (CUIDADO: isso vai quebrar a conectividade)
echo "‚ö†Ô∏è  Removendo regra temporariamente..."
# (Comando seria executado aqui, mas vamos apenas simular)

# Testar conectividade (deve falhar)
echo "üîç Testando conectividade ap√≥s remo√ß√£o da regra..."
timeout 10 redis-cli -h $CLUSTER_ENDPOINT -p 6379 ping || echo "‚ùå Conectividade falhou como esperado"

# Restaurar regra
echo "üîß Restaurando regra de Security Group..."
# (Comando de restaura√ß√£o seria executado aqui)

echo "‚úÖ Regra restaurada - conectividade deve voltar ao normal"
```

**‚úÖ Checkpoint:** Compreender como Security Groups afetam conectividade.

---

### Exerc√≠cio 3: An√°lise de CPU e Performance (15 minutos)

**Objetivo:** Identificar e diagnosticar problemas de CPU no ElastiCache

#### Passo 1: Estabelecer Baseline de CPU

```bash
# Popular dados iniciais para estabelecer baseline
echo "üìä Estabelecendo baseline de performance..."

redis-cli -h $CLUSTER_ENDPOINT -p 6379 << EOF
# Limpar dados existentes
FLUSHALL

# Inserir dados de baseline
$(for i in {1..1000}; do echo "SET baseline:$SEU_ID:key$i value$i"; done)

# Criar algumas estruturas mais complexas
HSET user:$SEU_ID:profile name "Jo√£o Silva" email "joao@example.com" age 30
LPUSH events:$SEU_ID $(for i in {1..100}; do echo "event$i"; done)
SADD tags:$SEU_ID $(for i in {1..50}; do echo "tag$i"; done)
EOF

echo "‚úÖ Dados de baseline inseridos"
```

#### Passo 2: Monitorar M√©tricas de CPU via CloudWatch

**Via Console Web:**
1. Acesse **CloudWatch** > **Metrics**
2. Navegue para **AWS/ElastiCache**
3. Selecione **CacheClusterId**
4. Encontre seu cluster `lab-troubleshoot-{SEU_ID}`
5. Selecione m√©tricas:
   - `CPUUtilization`
   - `EngineCPUUtilization`
   - `NetworkBytesIn`
   - `NetworkBytesOut`
   - `CurrConnections`

**Via CLI:**
```bash
# Obter m√©tricas de CPU dos √∫ltimos 30 minutos
echo "üìà Obtendo m√©tricas de CPU..."

aws cloudwatch get-metric-statistics \
    --namespace AWS/ElastiCache \
    --metric-name CPUUtilization \
    --dimensions Name=CacheClusterId,Value=lab-troubleshoot-$SEU_ID \
    --start-time $(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Average,Maximum \
    --region us-east-2

# M√©tricas espec√≠ficas do Redis Engine
aws cloudwatch get-metric-statistics \
    --namespace AWS/ElastiCache \
    --metric-name EngineCPUUtilization \
    --dimensions Name=CacheClusterId,Value=lab-troubleshoot-$SEU_ID \
    --start-time $(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Average,Maximum \
    --region us-east-2
```

#### Passo 3: Simular Carga de CPU

```bash
# Script para simular alta utiliza√ß√£o de CPU
echo "üß™ SIMULA√á√ÉO: Gerando carga de CPU..."

# Fun√ß√£o para gerar carga
generate_cpu_load() {
    local duration=$1
    local end_time=$(($(date +%s) + duration))
    
    echo "Gerando carga por $duration segundos..."
    
    while [ $(date +%s) -lt $end_time ]; do
        # Opera√ß√µes que consomem CPU
        redis-cli -h $CLUSTER_ENDPOINT -p 6379 << EOF > /dev/null
        # Opera√ß√µes de busca complexas
        KEYS *$SEU_ID*
        
        # Opera√ß√µes de ordena√ß√£o
        SORT events:$SEU_ID ALPHA
        
        # Opera√ß√µes de interse√ß√£o de conjuntos
        SINTER tags:$SEU_ID tags:$SEU_ID
        
        # Opera√ß√µes de contagem
        SCARD tags:$SEU_ID
        LLEN events:$SEU_ID
        HLEN user:$SEU_ID:profile
EOF
    done
}

# Executar carga em background
generate_cpu_load 180 &
LOAD_PID=$!

echo "üîç Monitorando CPU durante carga..."
for i in {1..6}; do
    echo "=== Verifica√ß√£o $i ($(date)) ==="
    
    # Testar lat√™ncia
    START_TIME=$(date +%s%N)
    redis-cli -h $CLUSTER_ENDPOINT -p 6379 ping > /dev/null
    END_TIME=$(date +%s%N)
    LATENCY=$(( (END_TIME - START_TIME) / 1000000 ))
    echo "Lat√™ncia PING: ${LATENCY}ms"
    
    # Testar opera√ß√£o simples
    START_TIME=$(date +%s%N)
    redis-cli -h $CLUSTER_ENDPOINT -p 6379 GET baseline:$SEU_ID:key1 > /dev/null
    END_TIME=$(date +%s%N)
    LATENCY=$(( (END_TIME - START_TIME) / 1000000 ))
    echo "Lat√™ncia GET: ${LATENCY}ms"
    
    sleep 30
done

# Parar gera√ß√£o de carga
kill $LOAD_PID 2>/dev/null || true
echo "‚úÖ Simula√ß√£o de carga conclu√≠da"
```

#### Passo 4: Analisar Impacto da Alta CPU

```bash
# Verificar m√©tricas ap√≥s carga
echo "üìä Analisando m√©tricas p√≥s-carga..."

# Aguardar propaga√ß√£o das m√©tricas
sleep 60

# Obter m√©tricas recentes
aws cloudwatch get-metric-statistics \
    --namespace AWS/ElastiCache \
    --metric-name CPUUtilization \
    --dimensions Name=CacheClusterId,Value=lab-troubleshoot-$SEU_ID \
    --start-time $(date -u -d '10 minutes ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 60 \
    --statistics Average,Maximum \
    --region us-east-2
```

**Sinais de Problema de CPU:**
- ‚úÖ CPUUtilization > 80% consistentemente
- ‚úÖ EngineCPUUtilization > 90%
- ‚úÖ Aumento na lat√™ncia de opera√ß√µes simples
- ‚úÖ Timeout em opera√ß√µes complexas

**‚úÖ Checkpoint:** Correlacionar alta CPU com degrada√ß√£o de performance.

---

### Exerc√≠cio 4: Diagn√≥stico de Mem√≥ria (15 minutos)

**Objetivo:** Identificar problemas de mem√≥ria e uso de swap

#### Passo 1: Analisar Uso de Mem√≥ria Atual

```bash
# Obter informa√ß√µes de mem√≥ria do Redis
echo "üîç Analisando uso de mem√≥ria..."

redis-cli -h $CLUSTER_ENDPOINT -p 6379 info memory

# M√©tricas espec√≠ficas de interesse
redis-cli -h $CLUSTER_ENDPOINT -p 6379 << EOF
INFO memory | grep -E "(used_memory|used_memory_human|used_memory_peak|maxmemory)"
EOF
```

#### Passo 2: Monitorar M√©tricas de Mem√≥ria via CloudWatch

**Via Console Web:**
1. No CloudWatch, adicione m√©tricas:
   - `DatabaseMemoryUsagePercentage`
   - `SwapUsage`
   - `FreeableMemory`
   - `BytesUsedForCache`

**Via CLI:**
```bash
# M√©tricas de uso de mem√≥ria
aws cloudwatch get-metric-statistics \
    --namespace AWS/ElastiCache \
    --metric-name DatabaseMemoryUsagePercentage \
    --dimensions Name=CacheClusterId,Value=lab-troubleshoot-$SEU_ID \
    --start-time $(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Average,Maximum \
    --region us-east-2

# M√©tricas de swap
aws cloudwatch get-metric-statistics \
    --namespace AWS/ElastiCache \
    --metric-name SwapUsage \
    --dimensions Name=CacheClusterId,Value=lab-troubleshoot-$SEU_ID \
    --start-time $(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 \
    --statistics Average,Maximum \
    --region us-east-2
```

#### Passo 3: Simular Press√£o de Mem√≥ria

```bash
# Simular uso intensivo de mem√≥ria
echo "üß™ SIMULA√á√ÉO: Gerando press√£o de mem√≥ria..."

# Fun√ß√£o para consumir mem√≥ria
consume_memory() {
    local target_mb=$1
    local key_size=1024  # 1KB por chave
    local num_keys=$((target_mb * 1024))
    
    echo "Inserindo ~${target_mb}MB de dados..."
    
    for i in $(seq 1 $num_keys); do
        # Criar string de 1KB
        local value=$(printf 'A%.0s' {1..1024})
        redis-cli -h $CLUSTER_ENDPOINT -p 6379 SET "memory_test:$SEU_ID:$i" "$value" > /dev/null
        
        # Mostrar progresso a cada 1000 chaves
        if [ $((i % 1000)) -eq 0 ]; then
            echo "Inseridas $i chaves..."
        fi
    done
}

# Consumir mem√≥ria gradualmente
consume_memory 10  # 10MB

# Monitorar uso de mem√≥ria
echo "üìä Monitorando uso de mem√≥ria..."
for i in {1..5}; do
    echo "=== Verifica√ß√£o $i ($(date)) ==="
    
    # Informa√ß√µes de mem√≥ria do Redis
    USED_MEMORY=$(redis-cli -h $CLUSTER_ENDPOINT -p 6379 info memory | grep "used_memory_human" | cut -d: -f2 | tr -d '\r')
    USED_MEMORY_PEAK=$(redis-cli -h $CLUSTER_ENDPOINT -p 6379 info memory | grep "used_memory_peak_human" | cut -d: -f2 | tr -d '\r')
    
    echo "Mem√≥ria Usada: $USED_MEMORY"
    echo "Pico de Mem√≥ria: $USED_MEMORY_PEAK"
    
    # Testar performance com alta utiliza√ß√£o de mem√≥ria
    START_TIME=$(date +%s%N)
    redis-cli -h $CLUSTER_ENDPOINT -p 6379 GET baseline:$SEU_ID:key1 > /dev/null
    END_TIME=$(date +%s%N)
    LATENCY=$(( (END_TIME - START_TIME) / 1000000 ))
    echo "Lat√™ncia GET: ${LATENCY}ms"
    
    sleep 30
done

# Limpar dados de teste de mem√≥ria
echo "üßπ Limpando dados de teste..."
redis-cli -h $CLUSTER_ENDPOINT -p 6379 eval "
    local keys = redis.call('keys', 'memory_test:$SEU_ID:*')
    for i=1,#keys do
        redis.call('del', keys[i])
    end
    return #keys
" 0

echo "‚úÖ Simula√ß√£o de press√£o de mem√≥ria conclu√≠da"
```

#### Passo 4: Identificar Padr√µes Problem√°ticos

```bash
# Analisar padr√µes de uso de mem√≥ria
echo "üîç Analisando padr√µes de uso de mem√≥ria..."

# Verificar fragmenta√ß√£o de mem√≥ria
redis-cli -h $CLUSTER_ENDPOINT -p 6379 info memory | grep -E "(mem_fragmentation|mem_allocator)"

# Verificar estat√≠sticas de eviction (se configurado)
redis-cli -h $CLUSTER_ENDPOINT -p 6379 info stats | grep -E "(evicted_keys|expired_keys)"

# Verificar configura√ß√£o de maxmemory
redis-cli -h $CLUSTER_ENDPOINT -p 6379 config get maxmemory*
```

**Sinais de Problema de Mem√≥ria:**
- ‚úÖ DatabaseMemoryUsagePercentage > 80%
- ‚úÖ SwapUsage > 0 (uso de swap √© sempre problem√°tico)
- ‚úÖ Fragmenta√ß√£o de mem√≥ria > 1.5
- ‚úÖ Evictions frequentes de chaves

**‚úÖ Checkpoint:** Identificar quando mem√≥ria se torna gargalo.

---

## üîç Metodologia de Troubleshooting

### Abordagem Estruturada

1. **Identificar Sintomas**
   - Lat√™ncia alta
   - Timeouts
   - Erros de conex√£o
   - Performance degradada

2. **Coletar Dados**
   - M√©tricas CloudWatch
   - Logs de aplica√ß√£o
   - Informa√ß√µes do Redis (INFO)
   - Testes de conectividade

3. **Analisar Padr√µes**
   - Correlacionar m√©tricas com sintomas
   - Identificar picos e anomalias
   - Verificar configura√ß√µes

4. **Hip√≥teses e Testes**
   - Formular hip√≥teses baseadas em dados
   - Testar uma vari√°vel por vez
   - Documentar resultados

5. **Implementar Solu√ß√£o**
   - Aplicar corre√ß√£o espec√≠fica
   - Monitorar impacto
   - Validar resolu√ß√£o

### Checklist de Troubleshooting

#### Conectividade
- [ ] DNS resolve corretamente?
- [ ] Security Groups permitem porta 6379?
- [ ] Rede permite conectividade?
- [ ] Endpoint est√° correto?
- [ ] Cluster est√° no status "available"?

#### CPU
- [ ] CPUUtilization < 80%?
- [ ] EngineCPUUtilization < 90%?
- [ ] Opera√ß√µes complexas otimizadas?
- [ ] Comandos KEYS evitados?
- [ ] √çndices apropriados?

#### Mem√≥ria
- [ ] DatabaseMemoryUsagePercentage < 80%?
- [ ] SwapUsage = 0?
- [ ] Fragmenta√ß√£o < 1.5?
- [ ] TTL configurado adequadamente?
- [ ] Pol√≠tica de eviction apropriada?

## üìä Dashboards e Alertas Recomendados

### M√©tricas Cr√≠ticas para Monitoramento

| M√©trica | Threshold Cr√≠tico | A√ß√£o |
|---------|------------------|------|
| CPUUtilization | > 80% | Investigar opera√ß√µes custosas |
| EngineCPUUtilization | > 90% | Otimizar queries, considerar upgrade |
| DatabaseMemoryUsagePercentage | > 80% | Revisar TTL, considerar eviction |
| SwapUsage | > 0 | Investigar imediatamente |
| CurrConnections | > 80% do m√°ximo | Revisar connection pooling |
| NetworkBytesIn/Out | Spikes an√¥malos | Investigar transfer√™ncia de dados |

### Alertas CloudWatch Sugeridos

```bash
# Exemplo de cria√ß√£o de alarme via CLI
aws cloudwatch put-metric-alarm \
    --alarm-name "ElastiCache-HighCPU-$SEU_ID" \
    --alarm-description "High CPU utilization on ElastiCache cluster" \
    --metric-name CPUUtilization \
    --namespace AWS/ElastiCache \
    --statistic Average \
    --period 300 \
    --threshold 80 \
    --comparison-operator GreaterThanThreshold \
    --evaluation-periods 2 \
    --dimensions Name=CacheClusterId,Value=lab-troubleshoot-$SEU_ID \
    --region us-east-2
```

## üí∞ Aten√ß√£o aos Custos

‚ö†Ô∏è **IMPORTANTE:** Este laborat√≥rio cria recursos AWS que geram custos na regi√£o us-east-2:

- Cache cluster: ~$0.017/hora (cache.t3.micro)
- CloudWatch m√©tricas: Inclu√≠das no Free Tier
- Data transfer: M√≠nimo para este lab

**Custo estimado por aluno:** ~$0.05 para completar o laborat√≥rio

## üßπ Limpeza de Recursos

**CR√çTICO:** Ao final do laborat√≥rio, delete seus recursos para evitar custos:

### Via Console Web:
1. **ElastiCache** > **Redis clusters**
   - Selecione `lab-troubleshoot-{SEU_ID}`
   - **Actions** > **Delete**
   - Confirme a dele√ß√£o

### Via CLI:
```bash
# Deletar cluster de troubleshooting
aws elasticache delete-cache-cluster --cache-cluster-id lab-troubleshoot-$SEU_ID --region us-east-2

# Monitorar dele√ß√£o
watch -n 30 "aws elasticache describe-cache-clusters --cache-cluster-id lab-troubleshoot-$SEU_ID --region us-east-2 2>/dev/null || echo 'Cluster deletado com sucesso'"

# Deletar alarmes criados (opcional)
aws cloudwatch delete-alarms --alarm-names "ElastiCache-HighCPU-$SEU_ID" --region us-east-2
```

**NOTA:** Mantenha o Security Group para uso nos pr√≥ximos laborat√≥rios.

## üìñ Recursos Adicionais

- [ElastiCache Monitoring](https://docs.aws.amazon.com/elasticache/latest/red-ug/monitoring-cloudwatch.html)
- [Redis INFO Command](https://redis.io/commands/info)
- [CloudWatch Metrics](https://docs.aws.amazon.com/elasticache/latest/red-ug/CacheMetrics.html)
- [Performance Tuning](https://docs.aws.amazon.com/elasticache/latest/red-ug/BestPractices.html)

## üÜò Troubleshooting

### Problemas Comuns

1. **M√©tricas n√£o aparecem no CloudWatch**
   - Aguarde 5-15 minutos para propaga√ß√£o
   - Verifique regi√£o selecionada
   - Confirme que cluster est√° ativo

2. **Alta lat√™ncia persistente**
   - Verifique CPU e mem√≥ria
   - Analise comandos executados
   - Considere otimiza√ß√£o de queries

3. **Uso de swap detectado**
   - **CR√çTICO:** Investigar imediatamente
   - Verificar configura√ß√£o de mem√≥ria
   - Considerar upgrade de inst√¢ncia

4. **Conectividade intermitente**
   - Verificar Security Groups
   - Analisar logs de rede
   - Testar de diferentes origens

5. **CPU alta sem carga aparente**
   - Verificar comandos KEYS
   - Analisar opera√ß√µes de background
   - Revisar configura√ß√£o de persistence

## üéØ Objetivos de Aprendizado Alcan√ßados

Ao final deste laborat√≥rio, voc√™ deve conseguir:

- ‚úÖ Diagnosticar problemas de conectividade de forma estruturada
- ‚úÖ Interpretar m√©tricas de CPU e identificar gargalos
- ‚úÖ Analisar uso de mem√≥ria e detectar problemas de swap
- ‚úÖ Correlacionar m√©tricas CloudWatch com sintomas da aplica√ß√£o
- ‚úÖ Aplicar metodologia estruturada de troubleshooting
- ‚úÖ Configurar alertas proativos para problemas de infraestrutura
- ‚úÖ Simular e resolver cen√°rios reais de problemas

## üìù Notas Importantes

- **Metodologia estruturada** √© essencial para troubleshooting eficaz
- **M√©tricas CloudWatch** s√£o fundamentais para diagn√≥stico
- **Uso de swap** √© sempre problem√°tico e deve ser investigado imediatamente
- **CPU > 80%** consistentemente indica necessidade de otimiza√ß√£o
- **Conectividade** deve ser testada em m√∫ltiplas camadas (DNS, rede, aplica√ß√£o)
- **Alertas proativos** previnem problemas antes que afetem usu√°rios
- **Documenta√ß√£o** de problemas e solu√ß√µes acelera troubleshooting futuro

## ‚û°Ô∏è Pr√≥ximo Laborat√≥rio

Agora que voc√™ domina troubleshooting de infraestrutura, v√° para:

**[Lab 04: Troubleshooting de Dados](../lab04-troubleshooting-dados/README.md)**

---

**Parab√©ns! Voc√™ completou o Lab 03! üéâ**

*Voc√™ agora possui habilidades estruturadas para diagnosticar e resolver problemas de infraestrutura no ElastiCache.*